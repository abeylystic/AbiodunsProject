{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e1b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fde0a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datapungibea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0b5797d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datapungibea.api.data at 0x112b78c4688>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install datapungibea\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas\n",
    "\n",
    "import datapungibea as dpb\n",
    "key = '1FD5DC35-4854-4CE8-8D43-B36065C37041'\n",
    "data = dpb.data(key) \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1718a216",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\python37\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mjson\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    970\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 971\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    972\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mJSONDecodeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python37\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python37\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python37\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20844\\1836653044.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m               \u001b[0mLineCode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m               \u001b[0mTableName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"CAGDP9\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m               Year = \"2010\")\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mfor_county_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python37\\lib\\site-packages\\datapungibea\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lastCalledDriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdelegate_object\u001b[0m \u001b[1;31m#NOTE: could use this to track all loaded data etc.  For now, will only use\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate_object\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcalled_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python37\\lib\\site-packages\\datapungibea\\drivers.py\u001b[0m in \u001b[0;36mRegional\u001b[1;34m(self, GeoFips, LineCode, TableName, Year, payload, verbose)\u001b[0m\n\u001b[0;32m   1233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m         \u001b[0mretrivedData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m         \u001b[0moutput\u001b[0m       \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cleanOutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mretrivedData\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#a dict of a df or df and meta (tablePretty)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python37\\lib\\site-packages\\datapungibea\\drivers.py\u001b[0m in \u001b[0;36m_cleanOutput\u001b[1;34m(self, query, retrivedData)\u001b[0m\n\u001b[0;32m   1247\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ResultFormat'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'JSON'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cleanCode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"df_output =  pd.DataFrame(retrivedData.json()['BEAAPI']['Results']['Data'])\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1249\u001b[1;33m             \u001b[0mdf_output\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretrivedData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'BEAAPI'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Results'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1250\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cleanCode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"df_output =  pd.DataFrame(retrivedData.json()['BEAAPI']['Results']['Data'])\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python37\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mjson\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    973\u001b[0m             \u001b[1;31m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m             \u001b[1;31m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRequestsJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    976\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# Collect county level variables\n",
    "for_county_index = data.Regional(GeoFips = \"COUNTY\",\n",
    "              LineCode = \"1\",\n",
    "              TableName = \"CAGDP9\", \n",
    "              Year = \"2010\")\n",
    "for_county_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb17c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = for_county_index[\"GeoFips\"]\n",
    "counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ec3ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_GDP_components = data.Regional(GeoFips = \"01001\",\n",
    "              LineCode = \"ALL\",\n",
    "              TableName = \"CAGDP9\", \n",
    "              Year = \"2010\")\n",
    "for_GDP_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ada85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP_components = for_GDP_components[[\"Code\", \"Description\"]]\n",
    "GDP_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20deb8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import random\n",
    "\n",
    "# for row in GDP_components.iterrows():\n",
    "#     full_code, description = row[1]\n",
    "#     table_name, code = full_code.split(\"-\")\n",
    "   \n",
    "#     try:\n",
    "#         GDP_data_dct[description] = data.Regional(GeoFips = \"COUNTY\",\n",
    "#               LineCode = code,\n",
    "#               TableName = table_name, \n",
    "#               Year = \"ALL\")\n",
    "#         print(full_code +\": \" + description + \" downloaded\")\n",
    "#     except:\n",
    "#         print(full_code +\": Error downloading \" + description)\n",
    "#     time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83916592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GDP_data_dct = {}\n",
    "folder1 = \"Data\"\n",
    "folder2 = \"CountyGDP\"\n",
    "try:\n",
    "    os.mkdir(folder1)\n",
    "    os.mkdir(folder1 + \"/\" + folder2)\n",
    "except:\n",
    "    try: \n",
    "        os.mkdir(folder1 + \"/\" + folder2)\n",
    "    except:\n",
    "        pass\n",
    "# for key, val in GDP_data_dct.items():\n",
    "#     val.to_csv(folder1 + \"/\" + folder2 + \"/\" + key.replace(\"/\",\"\") + \".csv\")\n",
    "\n",
    "for row in GDP_components.iterrows():\n",
    "    full_code, description = row\n",
    "    description = description[1]\n",
    "    # somehow, space added in very last character of description\n",
    "    GDP_data_dct[description] = pd.read_csv(\"Data/CountyGDP/\" + description[:-1].replace(\"/\",\"\") + \".csv\")\n",
    "GDP_data_dct\n",
    "# GDP_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0aa25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "\n",
    "# for a,b,c in os.walk(\".\"):\n",
    "#     print(a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc043ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.DataFrame({key[:-1]: val.set_index([\"GeoFips\", \"TimePeriod\"])[\"DataValue\"] for key, val in GDP_data_dct.items()})\n",
    "for key, val in full_df.items():\n",
    "    try:\n",
    "        full_df[key] = val.str.replace(\n",
    "            \",\",\"\").replace(\"(NA)\",np.NaN).replace(\"(D)\", np.NaN).astype(float)\n",
    "    except:\n",
    "        continue\n",
    "            \n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cced0096",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[\"All industry total\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45e47ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01859f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dac6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_df[[\"Private industries \", \"Utilities \"]]\n",
    "list (full_df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d96ac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ['All industry total',\"Utilities\", \"Mining, quarrying, and oil and gas extraction\", 'Agriculture, forestry, fishing and hunting']\n",
    "for key in inputs:\n",
    "    full_df[key + \" 3YMA\"] = full_df.reset_index().set_index([\"TimePeriod\"], drop = False).groupby(\"GeoFips\")[key].rolling(3).mean().shift()\n",
    "log_df = np.log(full_df)#.groupby(\"GeoFips\").diff()\n",
    "for key in inputs:\n",
    "    log_df[key + \" Volatility\"] = (log_df[key].sub(log_df[key + \" 3YMA\"])).pow(2).pow(.5)\n",
    "# for key in inputs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7b7789",
   "metadata": {},
   "source": [
    "- GDP \n",
    "-- layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1c03d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6650210",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = \"\"\"All industry total\n",
    "1 Private industries\n",
    "1.1 Agriculture, forestry, fishing and hunting\n",
    "1.2 Mining, quarrying, and oil and gas extraction\n",
    "1.3 Utilities\n",
    "1.4 Construction\n",
    "1.5 Manufacturing\n",
    "1.5.1 Durable goods manufacturing\n",
    "1.5.2 Nondurable goods manufacturing\n",
    "1.6 Wholesale trade\n",
    "1.7 Retail trade\n",
    "1.8 Transportation and warehousing\n",
    "1.9 Information\n",
    "1.10 Finance, insurance, real estate, rental, and leasing\n",
    "1.11 Finance and insurance\n",
    "1.12 Real estate and rental and leasing\n",
    "1.13 Professional and business services\n",
    "1.14 Professional, scientific, and technical services\n",
    "1.15 Management of companies and enterprises\n",
    "1.16 Administrative and support and waste management and remediation services\n",
    "1.17 Educational services, health care, and social assistance\n",
    "1.18 Educational services\n",
    "1.19 Health care and social assistance\n",
    "1.20 Arts, entertainment, recreation, accommodation, and food services\n",
    "1.21 Arts, entertainment, and recreation\n",
    "1.22 Accommodation and food services\n",
    "1.23 Other services (except government and government enterprises)\n",
    "1.24 Government and government enterprises\n",
    "1.25 Natural resources and mining\n",
    "1.26 Trade\n",
    "1.27 Transportation and utilities\n",
    "1.28 Manufacturing and information\n",
    "1.29 Private goods-producing industries 2/\n",
    "1.30 Private services-providing industries 3/\n",
    "2 \"\"\"\n",
    "\n",
    "myfile = 'GDP'\n",
    "\n",
    "data = {myfile:{}}\n",
    "for line in toc.splitlines():\n",
    "    levels, title = line.split(' ', maxsplit=1)\n",
    "    levels = levels.rstrip('.').split('.')\n",
    "    if len(levels) == 1:\n",
    "        heading = title\n",
    "        data[myfile][heading] = {}\n",
    "    elif len(levels) == 2:\n",
    "        sub_heading = title\n",
    "        data[myfile][heading][sub_heading] = []\n",
    "#     if len(levels) == 3:\n",
    "#         data[myfile][heading][sub_heading].append(title)\n",
    "\n",
    "print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f2267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = data[\"GDP\"]\n",
    "layer1 = list(dct.keys())\n",
    "layer1.pop()\n",
    "layer2 = []\n",
    "for key in layer1:\n",
    "    layer2 = layer2 + list(dct[key].keys())\n",
    "layers = {0:layer1,\n",
    "         1:layer2}\n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bb776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f1a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys = ['Agriculture, forestry, fishing and hunting',\n",
    "#  'Mining, quarrying, and oil and gas extraction',\n",
    "#  'Utilities',\n",
    "#  'Construction',\n",
    "#  'Manufacturing',\n",
    "#  'Wholesale trade',\n",
    "#  'Retail trade',\n",
    "#  'Transportation and warehousing',\n",
    "#  'Information',\n",
    "#  'Finance, insurance, real estate, rental, and leasing',\n",
    "#  'Finance and insurance',\n",
    "#  'Professional and business services',\n",
    "#  'Educational services, health care, and social assistance',\n",
    "#  'Arts, entertainment, recreation, accommodation, and food services',\n",
    "#  'Other services (except government and government enterprises)',\n",
    "#  'Government and government enterprises']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d25cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2 = log_df[layer2].groupby(\"GeoFips\").diff()\n",
    "# # list(log_df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7601d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data2\n",
    "\n",
    "# list(data2)\n",
    "# log_df\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34954632",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dct_ips = {}\n",
    "data_dct_ips['Log_Data'] = np.log(full_df)\n",
    "data_dct_ips['Diff1'] = data_dct_ips['Log_Data'].groupby('GeoFips').diff()\n",
    "data_dct_ips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582c388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dct = {}\n",
    "data_dct[\"Log Data\"] = np.log(full_df).replace([np.inf, -np.inf], np.nan)\n",
    "data_dct[\"Diff\"] = data_dct[\"Log Data\"].groupby(\"GeoFips\").diff()#.dropna()\n",
    "data_dct[\"2Diff\"] = data_dct[\"Diff\"].groupby(\"GeoFips\").diff()\n",
    "data_dct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e2bd93",
   "metadata": {},
   "source": [
    "write if the variables are sub-components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b413fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate first index column\n",
    "def reset_index(df):\n",
    "    name1,name2 = list(df.index.names)[1:]\n",
    "    ix1, ix2 =df.index.get_level_values(1), df.index.get_level_values(2) \n",
    "    df[name1] = ix1\n",
    "    df[name2] = ix2\n",
    "    df.reset_index(drop=True, inplace = True)\n",
    "    df.set_index([\"GeoFips\", \"TimePeriod\"], inplace = True)\n",
    "    \n",
    "ips_keys = ['Agriculture, forestry, fishing and hunting',\n",
    " 'Mining, quarrying, and oil and gas extraction',\n",
    " 'Utilities',\n",
    " \"All industry total\"]\n",
    "ips_df = data_dct[\"Diff\"][ips_keys]\n",
    "ips_df = ips_df[ips_df.index.get_level_values(\"TimePeriod\")>2001]\n",
    "ips_df = ips_df.groupby(\"GeoFips\").apply(lambda x: x.dropna(axis = 1)).dropna()\n",
    "ips_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c30b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ips_df2 = ips_df.groupby(\"GeoFips\").apply(lambda x: x.iloc[x.isnull().values.argmin():])\n",
    "# reset_index(ips_df2)\n",
    "# ips_df2 = ips_df2.groupby(\"GeoFips\").apply(lambda x: x.iloc[:x.isnull().values.argmax()])\n",
    "# reset_index(ips_df2)\n",
    "# for i in range(3):\n",
    "#     ips_df2 = ips_df2.groupby(\"GeoFips\").apply(lambda x: x.iloc[x.isnull().values.argmin()+1:])\n",
    "#     reset_index(ips_df2)\n",
    "# # .values.argmin()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7a55e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ips_df.iloc[\n",
    "# data.iloc[:data.A.isnull().values.argmax()]\n",
    "# ips_df2 = ips_df.groupby(\"GeoFips\").apply(lambda x: x.iloc[x.isnull().values.argmin()+1:])\n",
    "# ips_df2.groupby(\"GeoFips\").apply(lambda x: x.iloc[:x.isnull().values.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9992e70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def adfuller_table(df):\n",
    "    df_results = {}\n",
    "    for key, vector in df.items():\n",
    "        dftest = adfuller(vector, maxlag = 4, regression = 'c')\n",
    "        df_results[key] = pd.Series(dftest[0:4], index = ['t-stat', 'p-value', \n",
    "                                                         '#Lags Used', 'Number of Observations Used'])\n",
    "    return pd.DataFrame(df_results).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e989b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adfuller_table(data_dct['Diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d88c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import math\n",
    "data = data_dct_ips['Diff1'].replace([np.inf, -np.inf]).fillna(0)\n",
    "data\n",
    "data_ips = {}\n",
    "# data_ips = data.reset_index()\n",
    "data_ips['Diff']= data\n",
    "data_ips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9ccddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data_ips_var = ['GeoFips', 'TimePeriod', 'All industry total']\n",
    "# data_ips_t = data_ips[data_ips_var]\n",
    "# data_ips_t\n",
    "# data_ips_t['All industry total'].replace(to_replace = 0, value = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72ab042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test = pd.read_csv('ips.csv')\n",
    "# data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1e379d",
   "metadata": {},
   "source": [
    "# IPS Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c783c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ips_test(data, Firm, Time):\n",
    "    df = data.set_index([Firm, Time])\n",
    "    df2 = data.set_index([Time, Firm])\n",
    "    firms = list(data[Firm].unique())\n",
    "    times = list(data[Time].unique())\n",
    "    data = data.set_index(Firm)\n",
    "    N = len(firms)\n",
    "    dict_temp = {}\n",
    "\n",
    "    for firm in firms:\n",
    "        lag_val = []\n",
    "        val_diff = []\n",
    "        lag_val_diff = []\n",
    "        for i in data[Time].loc[firm]:\n",
    "            cur_val = i\n",
    "            if lag_val == []:\n",
    "                pass\n",
    "            else:\n",
    "                val_diff = cur_val - lag_val\n",
    "            if lag_val_diff == []:\n",
    "                pass\n",
    "            else:\n",
    "                if val_diff != lag_val_diff:\n",
    "                    raise ValueError(\"The data does not have constant time variation\")\n",
    "            lag_val = i\n",
    "            lag_val_diff = val_diff\n",
    "\n",
    "        for key in df:\n",
    "            total_temp_stat = 0\n",
    "            for firm in firms:\n",
    "                temp_df = data[[key]].loc[firm]\n",
    "                temp_stat = adfuller(temp_df, maxlag = 0, regression = 'ct')[0]\n",
    "                total_temp_stat += temp_stat\n",
    "                t_bar = (1/N)*total_temp_stat\n",
    "                dict_temp[key] = t_bar\n",
    "\n",
    "    df_temp = pd.DataFrame([dict_temp]).T\n",
    "    df_temp.columns = ['Test Stat']\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1e8013",
   "metadata": {},
   "source": [
    "Download interest rate data (divisia), and average it annually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aed6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "divisia = pd.read_excel(\"https://centerforfinancialstability.org/amfm/Divisia.xlsx\", \n",
    "                        sheet_name = \"Broad\", header  =1, index_col = \"Date\")\n",
    "\n",
    "index = divisia.index\n",
    "keys = divisia.keys()\n",
    "divisia = divisia.resample(\"A\").mean().rename(columns={keys[0]: \"M4\",\n",
    "                                                       keys[2]:\"M4 Interest Rate\"})\n",
    "year_lst = [i for i in range(1966, 2023)]\n",
    "divisia = divisia[[\"M4\", \"M4 Interest Rate\"]].reset_index()\n",
    "divisia[\"TimePeriod\"] = year_lst\n",
    "divisia = divisia.set_index(\"TimePeriod\").drop(columns = \"Date\")\n",
    "divisia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38049b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"Level\"][\"$r_{M4}$\"] = divisia[\"M4 Interest Rate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfc41ba",
   "metadata": {},
   "source": [
    "Add/join the interest rates to the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f561e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = full_df.copy().reset_index().set_index(\"TimePeriod\")\n",
    "data_df = data_df.join(divisia).reset_index()     \n",
    "data_df = data_df.set_index([\"GeoFips\", \"TimePeriod\"])    \n",
    "data_df = data_df.sort_index()\n",
    "data_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659f9465",
   "metadata": {},
   "source": [
    "Convert variables to rates and differenced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8567670",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dct1 = {}\n",
    "data_dct1[\"Log Data\"] = np.log(data_df).replace([np.inf, -np.inf], np.nan)\n",
    "data_dct1[\"Diff\"] = data_dct1[\"Log Data\"].groupby(\"GeoFips\").diff()#.dropna()\n",
    "#data_dct1[\"2Diff\"] = data_dct1[\"Diff\"].groupby(\"GeoFips\").diff()\n",
    "data_dct1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a59da2",
   "metadata": {},
   "source": [
    "Remove years with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate first index column\n",
    "def reset_index(df):\n",
    "    name1,name2 = list(df.index.names)[1:]\n",
    "    ix1, ix2 =df.index.get_level_values(1), df.index.get_level_values(2) \n",
    "    df[name1] = ix1\n",
    "    df[name2] = ix2\n",
    "    df.reset_index(drop=True, inplace = True)\n",
    "    df.set_index([\"GeoFips\", \"TimePeriod\"], inplace = True)\n",
    "    \n",
    "ips_keys = ['Agriculture, forestry, fishing and hunting',\n",
    " 'Mining, quarrying, and oil and gas extraction',\n",
    " 'Utilities',\n",
    " \"All industry total\",\n",
    "           \"M4\",\n",
    "           \"M4 Interest Rate\"]\n",
    "ips_df1 = data_dct1[\"Log Data\"][ips_keys]\n",
    "ips_df1 = ips_df1[ips_df1.index.get_level_values(\"TimePeriod\")>2001]\n",
    "ips_df1 = ips_df1.groupby(\"GeoFips\").apply(lambda x: x.dropna(axis = 1)).dropna()\n",
    "\n",
    "ips_df1[\"M4 Interest Rate\"] = data_df[\"M4 Interest Rate\"]\n",
    "ips_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b5a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# years = ips_df.groupby(\"TimePeriod\").mean().index\n",
    "# entities = ips_df.groupby(\"GeoFips\").mean().index\n",
    "# years, entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bf85a9",
   "metadata": {},
   "source": [
    "enter data that is the same for *every* year entry\n",
    "\n",
    "using year as example for data entry here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4224e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = ips_df.copy()\n",
    "# df[\"New\"] = np.nan\n",
    "# for year in years:\n",
    "#     df[\"New\"][df.index.get_level_values(\"TimePeriod\") == year] = year\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52b31b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ips_dct = {\"Log\":ips_df}\n",
    "ips_dct[\"Rates\"] = ips_dct[\"Log\"].groupby(\"GeoFips\").diff()\n",
    "ips_dct[\"Diff\"] = ips_dct[\"Rates\"].groupby(\"GeoFips\").diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2740ce",
   "metadata": {},
   "source": [
    "Run the IPS test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5923230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels.api as sm \n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def ips_test(data):\n",
    "    index_name, sub_index_name = data.index.names\n",
    "    index = list(data.reset_index()[index_name].unique())\n",
    "    N = len(index)\n",
    "    t_stats = {}\n",
    "    df_index_dict = {}\n",
    "    for ix in index:\n",
    "        slice_df = data.loc[ix]\n",
    "#         print(slice_df)\n",
    "        t_stats[ix] = {}\n",
    "        for key in slice_df.keys():\n",
    "            try:\n",
    "                t_stat = adfuller(slice_df[key], maxlag = 1, regression = 'c')[0]\n",
    "                t_stats[ix][key] = t_stat\n",
    "            except:\n",
    "                print(\"Error:\", key)\n",
    "    t_stats = pd.DataFrame(t_stats).T\n",
    "\n",
    "    return t_stats.mean()\n",
    "   \n",
    "ips_results = {}\n",
    "for key, val in ips_dct.items():\n",
    "    ips_results[key] = ips_test(val.dropna())\n",
    "pd.DataFrame(ips_results).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1d406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ips_dct2 = {\"Log\":ips_df1}\n",
    "ips_dct2[\"Rates\"] = ips_dct2[\"Log\"].groupby(\"GeoFips\").diff()\n",
    "ips_dct2[\"Diff\"] = ips_dct2[\"Rates\"].groupby(\"GeoFips\").diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58898d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels.api as sm \n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def ips_test(data):\n",
    "    index_name, sub_index_name = data.index.names\n",
    "    index = list(data.reset_index()[index_name].unique())\n",
    "    N = len(index)\n",
    "    t_stats = {}\n",
    "    df_index_dict = {}\n",
    "    for ix in index:\n",
    "        slice_df = data.loc[ix]\n",
    "#         print(slice_df)\n",
    "        t_stats[ix] = {}\n",
    "        for key in slice_df.keys():\n",
    "            try:\n",
    "                t_stat = adfuller(slice_df[key], maxlag = 1, regression = 'c')[0]\n",
    "                t_stats[ix][key] = t_stat\n",
    "            except:\n",
    "                print(\"Error:\", key)\n",
    "    t_stats = pd.DataFrame(t_stats).T\n",
    "\n",
    "    return t_stats.mean()\n",
    "   \n",
    "ips_results = {}\n",
    "for key, val in ips_dct2.items():\n",
    "    ips_results[key] = ips_test(val.dropna())\n",
    "pd.DataFrame(ips_results).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b3f68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "plt.rcParams.update({'font.size': 30})\n",
    "plt.rcParams['axes.xmargin'] = .001\n",
    "plt.rcParams['axes.ymargin'] = .005\n",
    "def full_corr_plot(data, color = \"C0\", pcorr = False):\n",
    "    if pcorr == True:\n",
    "        corr_df = data.pcorr()\n",
    "    elif pcorr == False:\n",
    "        corr_df = data.corr()\n",
    "    keys = list(corr_df.keys())\n",
    "    dim = len(keys)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (30, 30))\n",
    "    a = pd.plotting.scatter_matrix(data, c = color, \n",
    "                                   s = 200, alpha = .1, ax=ax)  \n",
    "    for i in range(len(keys)):\n",
    "        x = keys[i]\n",
    "        for j in range(len(keys)):\n",
    "            y = keys[j]\n",
    "            a[i][j].set_xticklabels([])\n",
    "            a[i][j].set_yticklabels([])\n",
    "            a[i][j].set_title(\"$\\\\rho :\" + str(corr_df.round(2)[x][y])+ \"$\", y = .88, x = 0.01, ha = \"left\")        \n",
    "    plt.suptitle(\"Correlation\\n(Color: y)\",y = .96, fontsize = 80)\n",
    "plot_df = ips_dct2['Diff'].dropna()\n",
    "plot_df.rename(columns = {key:key.replace(\" \", \"\\n\") for key in plot_df.keys()}, inplace = True)\n",
    "plot_keys = list(plot_df.keys())\n",
    "full_corr_plot(plot_df, color = plot_df[plot_keys[0]], pcorr = True)\n",
    "# y_var = ['Agriculture, forestry, fishing and hunting']\n",
    "# x_vars = ['Mining, quarrying, and oil and gas extraction', 'Utilities', 'Construction', 'Manufacturing']\n",
    "# corr_var = y_var + x_vars\n",
    "# corr_data = log_df[corr_var]\n",
    "# corr_data.corr().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdad26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# . . .\n",
    "def corr_matrix_heatmap(data, pp = False):  \n",
    "    #Create a figure to visualize a corr matrix  \n",
    "    fig, ax = plt.subplots(figsize=(20,20))  \n",
    "    # use ax.imshow() to create a heatmap of correlation values  \n",
    "    # seismic mapping shows negative values as blue and positive values as red  \n",
    "    im = ax.imshow(data, norm = plt.cm.colors.Normalize(-1,1), cmap = \"seismic\")  \n",
    "    # create a list of labels, stacking each word in a label by replacing \" \"  \n",
    "    # with \"\\n\"  \n",
    "    labels = data.keys()  \n",
    "    num_vars = len(labels)  \n",
    "    tick_labels = [lab.replace(\" \", \"\\n\") for lab in labels]  \n",
    "    # adjust font size according to the number of variables visualized  \n",
    "    tick_font_size = 120 / num_vars  \n",
    "    val_font_size = 200 / num_vars  \n",
    "    plt.rcParams.update({'font.size': tick_font_size}) \n",
    "    # prepare space for label of each column  \n",
    "    x_ticks = np.arange(num_vars)  \n",
    "    # select labels and rotate them 90 degrees so that they are vertical  \n",
    "    plt.xticks(x_ticks, tick_labels, fontsize = tick_font_size, rotation = 90)  \n",
    "    # prepare space for label of each row  \n",
    "    y_ticks = np.arange(len(labels))  \n",
    "    # select labels  \n",
    "    plt.yticks(y_ticks, tick_labels, fontsize = tick_font_size)  \n",
    "    # show values in each tile of the heatmap  \n",
    "    for i in range(len(labels)):  \n",
    "        for j in range(len(labels)):  \n",
    "            text = ax.text(i, j, str(round(data.values[i][j],2)),  \n",
    "                           fontsize= val_font_size, ha=\"center\",   \n",
    "                           va=\"center\", color = \"w\")  \n",
    "    #Create title with Times New Roman Font  \n",
    "    title_font = {\"fontname\":\"Times New Roman\"}  \n",
    "    plt.title(\"Correlation\", fontsize = 50, **title_font)  \n",
    "    #Call scale to show value of colors \n",
    "    cbar = fig.colorbar(im)\n",
    "    plt.show()\n",
    "    if pp != False:\n",
    "        pp.savefig(fig, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "#. . . \n",
    "# . . .\n",
    "corr_matrix_heatmap(plot_df.corr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d144f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(plot_df)\n",
    "# ips_df\n",
    "plot_df.rename(columns = {key:key[:4].replace(\"\\n\", \"\") for key in plot_df.keys()}, inplace = True)\n",
    "list(plot_df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae812e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import ArrowStyle\n",
    "import copy\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "undirected_graph = {key:[] for key in plot_df.keys()}\n",
    "for x in undirected_graph:\n",
    "    remaining_vars = [y for y in plot_df.keys() if y != x]\n",
    "    for y in remaining_vars:\n",
    "        undirected_graph[x].append(y)\n",
    "\n",
    "p_value = .01\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from pgmpy.estimators import PC\n",
    "c = PC(plot_df)\n",
    "max_cond_vars = len(plot_df.keys()) - 2\n",
    "\n",
    "model = c.estimate(return_type = 'pdag', variant= 'parallel', significance_level = p_value,\n",
    "                  max_cond_vars = max_cond_vars, ci_test = 'pearsonr')\n",
    "edges = model.edges\n",
    "\n",
    "pp = PdfPages(\"DAGOutputs1.pdf\")\n",
    "\n",
    "def graph_DAG(edges, df, title = \"\"):\n",
    "    graph = nx.Graph()\n",
    "    edge_labels = {}\n",
    "    for edge in edges:\n",
    "        controls = [key for key in df.keys() if key not in edge]\n",
    "        controls = list(set(controls))\n",
    "        keep_controls = []\n",
    "        for control in controls:\n",
    "            control_edges = [ctrl_edge for ctrl_edge in edges if control == ctrl_edge[0]]\n",
    "            if (control, edge[1]) in control_edges:\n",
    "                print('keep control:', control)\n",
    "                keep_controls.append(control)\n",
    "        print(edge, keep_controls)\n",
    "        pcorr = df[[edge[0], edge[1]]+keep_controls].pcorr()\n",
    "        edge_labels[edge] = str(round(pcorr[edge[0]].loc[edge[1]],2))\n",
    "    graph.add_edges_from(edges)\n",
    "    color_map = ['C0' for g in graph]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (20, 12))\n",
    "    graph.nodes()\n",
    "    plt.tight_layout()\n",
    "    pos = nx.spring_layout(graph)\n",
    "    \n",
    "    plt.title(title, fontsize = 30)\n",
    "    nx.draw_networkx(graph, pos, node_color=color_map, node_size=1200, with_labels=True,\n",
    "                    arrows=True, font_color ='k', font_size=26, alpha=1, width = 1,\n",
    "                    edge_color = 'C1',\n",
    "                     arrowstyle=ArrowStyle('Fancy, head_length=3, head_width=1.5, tail_width=.1'), ax = ax)\n",
    "    nx.draw_networkx_edge_labels(graph, pos, edge_labels=edge_labels, font_color='green', font_size=20)\n",
    "    pp.savefig(fig, bbox_inches = \"tight\")\n",
    "\n",
    "graph_DAG(edges, plot_df, title = 'Directed Acyclic Graph')\n",
    "\n",
    "\n",
    "pp.close()                                                            \n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe9c1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fae6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722c5bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80886034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counties = gpd.read_file(\"C:/Users/abiodun.idowu/OneDrive - North Dakota University System/Desktop/PhD/BEA project/notebook_to_start/tl_2022_us_county.shp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f372a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(counties.head())\n",
    "\n",
    "# # Rename the county name column to 'county_name'\n",
    "# counties = counties.rename(columns={'NAME': 'county_name'})\n",
    "\n",
    "# # Create a GeoDataFrame with just the county name and geometry columns\n",
    "# counties_gdf = counties[['county_name', 'geometry']]\n",
    "\n",
    "\n",
    "# county_gdf = counties.rename(columns={'GEOID': 'GeoFips'})\n",
    "\n",
    "# # Check the new structure of the data\n",
    "\n",
    "# # print(counties_gdf.head())\n",
    "\n",
    "# # Merge the geometry column from the GeoDataFrame with the 'plot_df' DataFrame\n",
    "# # merged_df = plot_df.merge(county_gdf[['GeoFips', 'geometry']], on='GeoFips')\n",
    "\n",
    "# # 'merged_df' now contains both the attribute data from 'plot_df' and th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba99107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# county_gdf['GeoFips'] = county_gdf['GeoFips'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7756de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_df = pd.concat([plot_df, county_gdf]).groupby('GeoFips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6047ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621dd28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# county_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(plot_df.dtypes)\n",
    "# print(county_gdf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604bb865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# county_gdf['GeoFips'] = county_gdf['GeoFips'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0133788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_df = pd.merge(plot_df.reset_index(), county_gdf, left_on='GeoFips', right_on='GeoFips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f465d633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_df = merge_df.set_index('GeoFips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664ee26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf = merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cbf234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf = gdf.dropna(subset=['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4310493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbff30f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c4c9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4354e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf = gpd.GeoDataFrame(gdf, geometry='geometry')\n",
    "\n",
    "# # Check if a geometry intersects another geometry in the GeoDataFrame\n",
    "# intersects = gdf.iloc[0].geometry.intersects(gdf.iloc[1].geometry)\n",
    "# print(intersects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ca12ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, GeoFips in gdf.iterrows():\n",
    "#     neighbors = gdf[~gdf.geometry.disjoint(GeoFips.geometry)].county_name.tolist()\n",
    "#     neighbor = [name for name in neighbors if GeoFips.county_name != name]\n",
    "#     gdf.at[index, \"NEIGHBORS\"] = \", \".join(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafe01c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8189fb01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c9b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_geo_data(filename, index_col = \"Date\", FIPS_name = \"FIPS\"):\n",
    "    # import county level shapefile\n",
    "    map_data = geopandas.read_file(filename = filename,                                   \n",
    "                                   index_col = index_col)\n",
    "    # rename fips code to match variable name in COVID-19 data\n",
    "    map_data.rename(columns={\"State\":\"state\"},\n",
    "                    inplace = True)\n",
    "    # Combine statefips and county fips to create a single fips value\n",
    "    # that identifies each particular county without referencing the \n",
    "    # state separately\n",
    "    map_data[FIPS_name] = map_data[\"STATEFP\"].astype(str) + \\\n",
    "        map_data[\"COUNTYFP\"].astype(str)\n",
    "    map_data[FIPS_name] = map_data[FIPS_name].astype(np.int64)\n",
    "    # set FIPS as index\n",
    "    map_data.set_index(FIPS_name, inplace=True)\n",
    "    \n",
    "    return map_data\n",
    "fips_name = \"fips_code\"\n",
    "map_data = import_geo_data(\n",
    "    filename = \"countiesWithStatesAndPopulation.shp\",\n",
    "    index_col = \"Date\", FIPS_name= fips_name)\n",
    "map_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35633a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4901ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, fips_code in map_data.iterrows():\n",
    "#     neighbors = map_data[~map_data.geometry.disjoint(fips_code.geometry)].index.tolist()\n",
    "#     neighbors = [name for name in neighbors if name not in fips_code.index]\n",
    "#     print(neighbors)\n",
    "# map_data.at[index, \"NEIGHBORS\"] = neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ba9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, fips_code in map_data.iterrows():\n",
    "#     neighbors = map_data[~map_data.geometry.disjoint(fips_code.geometry)].index.tolist()\n",
    "#     neighbors = [name for name in neighbors if name != index]\n",
    "#     print(index, neighbors)\n",
    "# map_data.at[index, \"NEIGHBORS\"] = neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a726beb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, fips_code in map_data.iterrows():\n",
    "#     neighbors = map_data[~map_data.geometry.disjoint(fips_code.geometry)].index.tolist()\n",
    "#     neighbors = [int(name) for name in neighbors if name != index]\n",
    "#     print(index, neighbors)\n",
    "# map_data.at[index, \"NEIGHBORS\"] = neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fe2eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f52da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_neighbors(year_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0008998a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b938cd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for year in range (2004, 2020):\n",
    "#     year_data = full_df.loc[year]\n",
    "#     year_data = map_data.join(year_data).dropna(subset = [\"All industry total\"])\n",
    "#     find_neighbors(year_data)    \n",
    "# #     year_data = year_data.join(map_data[\"NEIGHBORS\"])\n",
    "# #     year_data[\"NeighborGDP\"]\n",
    "# #     print( year_data[\"All industry total\"].loc[year_data.loc[1001][\"NEIGHBORS\"]].sum())\n",
    "# #     full_df.loc[year, \"All industry total\"] = year_data.apply(lambda row: year_data[\"All industry total\"].loc[row[\"NEIGHBORS\"]].sum() if row[\"NEIGHBORS\"] != np.nan else np.nan, \n",
    "# #                           axis = 1)\n",
    "#     full_df.loc[year, \"All industry total\"] = year_data.apply(lambda row: year_data[\"All industry total\"].loc[row[\"NEIGHBORS\"]].sum() if row[\"NEIGHBORS\"] != np.nan else np.nan, \n",
    "#                           axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ba18aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_neighbors(df):\n",
    "    for index, fips_code in df.iterrows():\n",
    "\n",
    "        neighbors = df[~df.geometry.disjoint(fips_code.geometry)].index.tolist()\n",
    "#         neighbors = [int(name) for name in neighbors if name != index]\n",
    "        print(index, neighbors)\n",
    "        df.at[index, \"NEIGHBORS\"] = neighbors\n",
    "map_data[\"NEIGHBORS\"] = \"\"\n",
    "find_neighbors(map_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd0e6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c12b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.reset_index()\n",
    "full_df[\"FIPS\"] = full_df[\"GeoFips\"]\n",
    "full_df = full_df.set_index([\"TimePeriod\",\"GeoFips\"])\n",
    "full_df.dropna(subset = [\"All industry total\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b3d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_df[\"NeighborGDP\"] = np.NaN\n",
    "# year_df_dict =[] \n",
    "# for year in full_df.index.get_level_values(\"TimePeriod\").unique():# range (2001, 2020):\n",
    "#     year_data = full_df.loc[year]\n",
    "#     year_data = map_data.join(year_data).dropna(subset = [\"All industry total\"])\n",
    "#     find_neighbors(year_data)    \n",
    "# #     year_data = year_data.join(map_data[\"NEIGHBORS\"])\n",
    "# #     year_data[\"NeighborGDP\"]\n",
    "# #     print( year_data[\"All industry total\"].loc[year_data.loc[1001][\"NEIGHBORS\"]].sum())\n",
    "# #     full_df.loc[year, \"All industry total\"] = year_data.apply(lambda row: year_data[\"All industry total\"].loc[row[\"NEIGHBORS\"]].sum() if row[\"NEIGHBORS\"] != np.nan else np.nan, \n",
    "# #                           axis = 1)\n",
    "#     full_df[\"NeighborGDP\"].loc[year,year_data.index] = year_data.apply(lambda row: year_data[\"All industry total\"].loc[row[\"NEIGHBORS\"]].sum() if row[\"NEIGHBORS\"] != np.nan else np.nan, \n",
    "#                           axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425099ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5835ed91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1089f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # full_df.dropna(subset = [\"NeighborGDP\"])#.index.get_level_values(\"TimePeriod\").unique()\n",
    "# full_df.loc[year, \"NeighborGDP\"].loc[year_data.index] = year_data.apply(\n",
    "#     lambda row: year_data[\"All industry total\"].loc[row[\"NEIGHBORS\"]].sum() if row[\"NEIGHBORS\"] != np.nan else np.nan, \n",
    "#                           axis = 1)\n",
    "# full_df.loc[year, \"NeighborGDP\"].loc[year_data.index]\n",
    "# # full_df.loc[year]\n",
    "# # full_df.loc[year].loc[year_data.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c9d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# full_df[\"NeighborGDP\"][full_df.index.get_level_values(\"GeoFips\").isin(year_data[\"FIPS\"])].loc[year]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107696f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try_df = full_df.reset_index()\n",
    "try_df.set_index([\"GeoFips\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fffad33",
   "metadata": {},
   "source": [
    "Create neighbors and sum of their GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205f3a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "years_list = try_df[\"TimePeriod\"].unique()\n",
    "full_df[\"NeighborGDP\"] = np.NaN\n",
    "year_df_dict ={}\n",
    "for year in years_list:    \n",
    "    year_data = full_df.loc[year]\n",
    "    year_data = map_data.join(year_data).dropna(subset = [\"All industry total\"])\n",
    "    find_neighbors(year_data)    \n",
    "#     year_data = year_data.join(map_data[\"NEIGHBORS\"])\n",
    "#     year_data[\"NeighborGDP\"]\n",
    "#     print( year_data[\"All industry total\"].loc[year_data.loc[1001][\"NEIGHBORS\"]].sum())\n",
    "#     full_df.loc[year, \"All industry total\"] = year_data.apply(lambda row: year_data[\"All industry total\"].loc[row[\"NEIGHBORS\"]].sum() if row[\"NEIGHBORS\"] != np.nan else np.nan, \n",
    "#                           axis = 1)\n",
    "    full_df[\"NeighborGDP\"].loc[year,year_data.index] = year_data.apply(lambda row: year_data[\"All industry total\"].loc[row[\"NEIGHBORS\"]].sum() if row[\"NEIGHBORS\"] != np.nan else np.nan, \n",
    "                          axis = 1)    \n",
    "    \n",
    "    \n",
    "##############################################################################3    \n",
    "    \n",
    "    \n",
    "    year_data[\"NeighborGDP\"] = year_data.apply(\n",
    "        lambda row: year_data[\"All industry total\"].loc[row[\"NEIGHBORS\"]].sum() if row[\"NEIGHBORS\"] != np.nan else np.nan, \n",
    "                              axis = 1)\n",
    "    year_data[\"Year\"] = datetime.datetime(year,1,1)\n",
    "    trial = year_data    \n",
    "    try_df = full_df.reset_index().set_index([\"GeoFips\"])\n",
    "    year_df_dict[year] = pd.merge(try_df.loc[try_df[\"TimePeriod\"]==year], trial.loc[trial[\"Year\"].dt.year==year],\n",
    "                       left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbf4199",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_df_dict[2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b286731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = (year_df_dict.values())\n",
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b144047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "df = pd.concat([d for d in df_list], axis=0, join='inner').set_index([\"Year\", \"FIPS_y\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5657154c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3e77a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"GDP_weigh\"] = df[\"NeighborGDP_y\"]/df[\"All industry total_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a0d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0767dd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5763006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum of gdp/self area (use .area)\n",
    "\n",
    "#sum of gdp/self population\n",
    "\n",
    "#build out some maps from these variables, correlation stats of your own gdp against these measures (do initial analytics)\n",
    "\n",
    "#partial correlations betw your gdp and neighbors gdp\n",
    "\n",
    "#create maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcca344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"GDP_area\"] = df[\"NeighborGDP_y\"]/df[\"ALAND\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce57772",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"GDP_area\"] = df[\"NeighborGDP_y\"]/df[\"ALAND\"]\n",
    "df[\"GDP_pop\"] = df[\"NeighborGDP_y\"]/df[\"Population\"]\n",
    "df[\"ownGDP_pop\"] = df[\"All industry total_y\"]/df[\"Population\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0530e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c29068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('path/to/output.csv', index=False)\n",
    "\n",
    "#df.to_csv('stat712.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d7730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy().reset_index().set_index(\"TimePeriod\")\n",
    "df1 = df1.join(divisia).reset_index()     \n",
    "df1 = df1.set_index([\"FIPS_y\", \"TimePeriod\"])    \n",
    "df1 = df1.sort_index()\n",
    "df1\n",
    "df2_key = ['Agriculture, forestry, fishing and hunting_y',\n",
    " 'Mining, quarrying, and oil and gas extraction_y',\n",
    " 'Utilities_y',\n",
    " \"All industry total_y\", 'NeighborGDP_y', 'GDP_weigh', 'M4', 'M4 Interest Rate']\n",
    "df2 = df1[df2_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aee1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0426966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5_key = ['All industry total_y',\n",
    " 'GDP_area',\n",
    " 'GDP_pop', 'NeighborGDP_y']\n",
    "df6 = df[df5_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845cb4c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7933f8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbfb813",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = {}\n",
    "df3[\"Log data\"] = np.log(df2).replace([np.inf, -np.inf], np.nan)\n",
    "df3[\"Diff\"] = df3[\"Log data\"].groupby(\"FIPS_y\").diff().dropna()\n",
    "df3[\"Diff2\"] = df3[\"Diff\"].groupby(\"FIPS_y\").diff() \n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c961cd56",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f3d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 30})\n",
    "plt.rcParams['axes.xmargin'] = .001\n",
    "plt.rcParams['axes.ymargin'] = .005\n",
    "df7 = df6.dropna()\n",
    "df7.rename(columns = {key:key.replace(\" \", \"\\n\") for key in df7.keys()}, inplace = True)\n",
    "df7_keys = list(df7.keys())\n",
    "full_corr_plot(df7, color = df7[df7_keys[0]], pcorr = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1548b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix_heatmap(df7.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6988f0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = {}\n",
    "df8[\"Log\"] = np.log(df6)\n",
    "df8[\"Diff\"] = df8[\"Log\"].groupby(\"FIPS_y\").diff()\n",
    "df8[\"Diff2\"] = df8[\"Diff\"].groupby(\"FIPS_y\").diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f6844d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5115f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 30})\n",
    "plt.rcParams['axes.xmargin'] = .001\n",
    "plt.rcParams['axes.ymargin'] = .005\n",
    "df9 = df8[\"Diff\"].dropna()\n",
    "df7.rename(columns = {key:key.replace(\" \", \"\\n\") for key in df7.keys()}, inplace = True)\n",
    "df9_keys = list(df9.keys())\n",
    "full_corr_plot(df9, color = df9[df9_keys[0]], pcorr = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0d8e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix_heatmap(df9.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88be413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(map_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fc471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrdf = map_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a295f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26d044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df1[(df1['TimePeriod'] >= 2001) & (df1['TimePeriod'] <= 2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c916a08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = df_test.groupby('FIPS_y')['All industry total_y', 'NeighborGDP_y'].corr().iloc[0::2]['NeighborGDP_y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f5d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f397afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_test.groupby('FIPS_y').apply(lambda x: sm.OLS(x['All industry total_y'], sm.add_constant(x['NeighborGDP_y'])).fit().params['NeighborGDP_y'])\n",
    "\n",
    "\n",
    "df_reg2 = df_test.groupby('FIPS_y').apply(lambda x: sm.OLS(x['All industry total_y'], sm.add_constant(x['NeighborGDP_y'])).fit().params['NeighborGDP_y']).reset_index(name='Regression_Coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2761d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1 = df_test.copy()\n",
    "\n",
    "df_test1 = df_test1.set_index([\"FIPS_y\", \"TimePeriod\"])\n",
    "\n",
    "df_test_key = ['All industry total_y', 'NeighborGDP_y']\n",
    "\n",
    "df_test2 = df_test1[df_test_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d65dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889b8d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_reg = {}\n",
    "df_test_reg[\"Log\"] = np.log(df_test2)\n",
    "df_test_reg[\"Diff\"] = df_test_reg[\"Log\"].groupby(\"FIPS_y\").diff().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521ca8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg2 = df_test_reg[\"Diff\"].groupby('FIPS_y').apply(lambda x: sm.OLS(x['All industry total_y'], sm.add_constant(x['NeighborGDP_y'])).fit().params['NeighborGDP_y']).reset_index(name='Regression_Coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ca9f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ae2855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the distribution for regression coefficients\n",
    "plot = plt.hist(df_reg2['Regression_Coefficient'], bins=20, edgecolor='black')\n",
    "plt.axvline(np.mean(df_reg2['Regression_Coefficient']), color='red', linestyle='dashed', linewidth=2)\n",
    "plt.xlabel('Regression Coefficient')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Regression Coefficients')\n",
    "\n",
    "\n",
    "min_value = np.min(df_reg2['Regression_Coefficient'])\n",
    "max_value = np.max(df_reg2['Regression_Coefficient'])\n",
    "plt.xlim(min_value, max_value)\n",
    "\n",
    "\n",
    "plt.savefig('C:\\\\Users\\\\abiodun.idowu\\\\OneDrive - North Dakota University System\\\\Desktop\\\\PhD\\\\BEA project\\\\notebook_to_start\\\\plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d951e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d738809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of the regression coefficients\n",
    "import seaborn as sns\n",
    "sns.displot(data=df_reg2, x='Regression_Coefficient', kde=True, color='blue')\n",
    "plt.xlabel('Regression Coefficient')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Regression Coefficients')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90800414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = {}\n",
    "df8[\"Log\"] = np.log(df6)\n",
    "df8[\"Diff\"] = df8[\"Log\"].groupby(\"FIPS_y\").diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f4d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge regression coefficients with map data and plot\n",
    "\n",
    "df_reg2 = df_reg2.rename(columns={'FIPS_y':'fips_code'})\n",
    "\n",
    "df_reg2['fips_code'] = df_reg2['fips_code'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab32cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg2 = df_reg2.set_index('fips_code')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b75290",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data.reset_index().set_index('fips_code', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6114a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg3 = pd.merge(map_data, df_reg2, left_index=True, right_on='fips_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44a0b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg3.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859e0be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_reg3 = df_reg3.rename(columns={'fips_code':'index', 'index': 'col'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1881e2eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9be9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c7995c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.choropleth(df_reg3, geojson=df_reg3.geometry.__geo_interface__, locations=df_reg3.index, color='Regression_Coefficient')\n",
    "fig.update_geos(fitbounds='locations', visible=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd398f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html('fig.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8466f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg2.to_csv('stat_712.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861e193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = {}\n",
    "df_corr['corr_gdp'] = correlation\n",
    "df_corr['corr_gdp_pop'] = df_test.groupby('FIPS_y')['GDP_pop', 'ownGDP_pop'].corr().iloc[0::2]['ownGDP_pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c9f9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pd.DataFrame(correlation)\n",
    "\n",
    "corr_pop = pd.DataFrame(df_corr['corr_gdp_pop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd7fa36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5670a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ed6ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77294636",
   "metadata": {},
   "source": [
    "Sum of neighbor energy sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05204bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "years_list = try_df[\"TimePeriod\"].unique()\n",
    "full_df[\"Neighborenergy\"] = np.NaN\n",
    "year_df_dict ={} \n",
    "for year in years_list:    \n",
    "    year_data = full_df.loc[year]\n",
    "    year_data = map_data.join(year_data).dropna(subset = [\"Mining, quarrying, and oil and gas extraction\"])\n",
    "    find_neighbors(year_data)    \n",
    "#     year_data = year_data.join(map_data[\"NEIGHBORS\"])\n",
    "#     year_data[\"NeighborGDP\"]\n",
    "#     print( year_data[\"All industry total\"].loc[year_data.loc[1001][\"NEIGHBORS\"]].sum())\n",
    "#     full_df.loc[year, \"All industry total\"] = year_data.apply(lambda row: year_data[\"All industry total\"].loc[row[\"NEIGHBORS\"]].sum() if row[\"NEIGHBORS\"] != np.nan else np.nan, \n",
    "#                           axis = 1)\n",
    "    full_df[\"Neighborenergy\"].loc[year,year_data.index] = year_data.apply(lambda row: year_data[\"Mining, quarrying, and oil and gas extraction\"].loc[row[\"NEIGHBORS\"]].sum() if row[\"NEIGHBORS\"] != np.nan else np.nan, \n",
    "                          axis = 1)    \n",
    "    \n",
    "    \n",
    "##############################################################################3    \n",
    "    \n",
    "    \n",
    "    year_data[\"Neighborenergy\"] = year_data.apply(\n",
    "        lambda row: year_data[\"Mining, quarrying, and oil and gas extraction\"].loc[row[\"NEIGHBORS\"]].sum() if row[\"NEIGHBORS\"] != np.nan else np.nan, \n",
    "                              axis = 1)\n",
    "    year_data[\"Year\"] = datetime.datetime(year,1,1)\n",
    "    trial = year_data    \n",
    "    try_df = full_df.reset_index().set_index([\"GeoFips\"])\n",
    "    year_df_dict[year] = pd.merge(try_df.loc[try_df[\"TimePeriod\"]==year], trial.loc[trial[\"Year\"].dt.year==year],\n",
    "                       left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba96fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_energy = (year_df_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc3bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_energy = pd.concat([d for d in df_list_energy], axis=0, join='inner').set_index([\"Year\", \"FIPS_y\"])\n",
    "df_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84077cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_energy = df_energy.merge(df['NeighborGDP_y'], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdec569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_energy\n",
    "\n",
    "df_energy = df_energy.rename(columns={'Neighborenergy_y': 'Neighborenergy', 'NeighborGDP_y_y':'NeighborGDP'})\n",
    "\n",
    "df_energy = df_energy.drop('NeighborGDP_y_x', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b9e2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_energy = df_energy.copy()\n",
    "gdp_energy_key = ['All industry total_y','Mining, quarrying, and oil and gas extraction_y', 'NeighborGDP', 'Neighborenergy']\n",
    "gdp_energy1 = gdp_energy[gdp_energy_key]\n",
    "gdp_energy1 = gdp_energy1.rename(columns={'Mining, quarrying, and oil and gas extraction_y' : 'energy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0bdf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_df[\"Diff\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93295a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary for logged data and rates data\n",
    "energy_df = {}\n",
    "energy_df[\"Log\"] = np.log(gdp_energy1).replace([np.inf, -np.inf], np.nan)\n",
    "energy_df[\"Diff\"] = energy_df[\"Log\"].groupby(\"FIPS_y\").diff().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f01a0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary of all the regression coefficients for various combinations\n",
    "reg_coeff ={}\n",
    "\n",
    "reg_coeff[\"gdp_neighborgdp_coeff\"] = energy_df[\"Diff\"].groupby('FIPS_y').apply(lambda x: sm.OLS(x['All industry total_y'], sm.add_constant(x['NeighborGDP'])).fit().params['NeighborGDP']).reset_index(name='gdp_neighborgdp_coeff').set_index('FIPS_y')\n",
    "\n",
    "reg_coeff[\"gdp_neighborenergy_coeff\"] = energy_df[\"Diff\"].groupby('FIPS_y').apply(lambda x: sm.OLS(x['All industry total_y'], sm.add_constant(x['Neighborenergy'])).fit().params['Neighborenergy']).reset_index(name='gdp_neighborenergy_coeff').set_index('FIPS_y')\n",
    "\n",
    "reg_coeff[\"energy_neighborenergy_coeff\"] = energy_df[\"Diff\"].groupby('FIPS_y').apply(lambda x: sm.OLS(x['energy'], sm.add_constant(x['Neighborenergy'])).fit().params['Neighborenergy']).reset_index(name='energy_neighborenergy_coeff').set_index('FIPS_y')\n",
    "\n",
    "#df_reg2 = df_test_reg[\"Diff\"].groupby('FIPS_y').apply(lambda x: sm.OLS(x['All industry total_y'], sm.add_constant(x['NeighborGDP_y'])).fit().params['NeighborGDP_y']).reset_index(name='Regression_Coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4c1a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_coeff[\"gdp_neighborgdp_coeff\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30374048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all the regression coefficients to one dataframe\n",
    "\n",
    "reg_coeff_map = pd.merge(reg_coeff[\"gdp_neighborgdp_coeff\"] , reg_coeff[\"gdp_neighborenergy_coeff\"], \n",
    "                         left_index=True, right_on='FIPS_y')\n",
    "\n",
    "reg_coeff_map = pd.merge(reg_coeff_map, reg_coeff[\"energy_neighborenergy_coeff\"], \n",
    "                         left_index=True, right_on='FIPS_y')\n",
    "\n",
    "# reg_coeff_map = reg_coeff_map.rename(columns={'gdp_neighborenergy_coeff_x':'gdp_neighborenergy_coeff',\n",
    "#                                              'gdp_neighborenergy_coeff_y':'gdp_neighborenergy_coeff'})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771916fc",
   "metadata": {},
   "source": [
    "Energy vs Neighbor energy sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b203e839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge data with location dataframe\n",
    "reg_energy = reg_coeff[\"energy_neighborenergy_coeff\"]\n",
    "reg_energy = reg_energy.reset_index()\n",
    "reg_energy = reg_energy.rename(columns={'FIPS_y':'fips_code'})\n",
    "reg_energy = reg_energy.set_index('fips_code')\n",
    "map_data.reset_index().set_index('fips_code', inplace=True)\n",
    "map_energy = pd.merge(map_data, reg_energy, left_index=True, right_on='fips_code')\n",
    "\n",
    "#Plot the dynamic map\n",
    "# Get the maximum absolute value in the DataFrame\n",
    "# Filter out rows for Alaska and Hawaii using their FIPS codes \n",
    "map_energy = map_energy[~map_energy['state'].isin(['Alaska', 'Hawaii'])]\n",
    "\n",
    "max_value = max(abs(map_energy['energy_neighborenergy_coeff'].max()), abs(map_energy['energy_neighborenergy_coeff'].min()))\n",
    "\n",
    "# Create the choropleth map\n",
    "fig_energy = px.choropleth(map_energy, geojson=map_energy['geometry'], locations=map_energy.index, color='energy_neighborenergy_coeff',\n",
    "                    color_continuous_scale='RdBu', color_continuous_midpoint=0, range_color=[-max_value, max_value])\n",
    "fig_energy.update_geos(fitbounds='locations', resolution=110, scope=\"usa\",\n",
    "    showsubunits=True, subunitcolor=\"Black\", subunitwidth=0.5)\n",
    "fig_energy.update_traces(marker_line_width=0.5)\n",
    "fig_energy.show()\n",
    "\n",
    "fig_energy.write_html('fig_energy.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the choropleth map with a specific color range\n",
    "fig_energy1 = px.choropleth(map_energy, geojson=map_energy['geometry'], locations=map_energy.index, color='energy_neighborenergy_coeff',\n",
    "                    color_continuous_scale='RdBu', color_continuous_midpoint=0, range_color=[-5, 5])\n",
    "fig_energy1.update_geos(fitbounds='locations', resolution=110, scope=\"usa\",\n",
    "    showsubunits=True, subunitcolor=\"Black\", subunitwidth=0.5)\n",
    "fig_energy1.update_traces(marker_line_width=0.5)\n",
    "\n",
    "fig_energy1.show()\n",
    "\n",
    "fig_energy1.write_html('fig_energy1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b85427a",
   "metadata": {},
   "source": [
    "GDP vs neighbor energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd915d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge data with location data\n",
    "reg_gdpenergy = reg_coeff[\"gdp_neighborenergy_coeff\"]\n",
    "reg_gdpenergy = reg_gdpenergy.reset_index()\n",
    "reg_gdpenergy = reg_gdpenergy.rename(columns={'FIPS_y':'fips_code'})\n",
    "reg_gdpenergy = reg_gdpenergy.set_index('fips_code')\n",
    "map_data.reset_index().set_index('fips_code', inplace=True)\n",
    "map_gdpenergy = pd.merge(map_data, reg_gdpenergy, left_index=True, right_on='fips_code')\n",
    "\n",
    "\n",
    "#Plot the map\n",
    "# Get the maximum absolute value in the DataFrame\n",
    "map_gdpenergy = map_gdpenergy[~map_gdpenergy['state'].isin(['Alaska', 'Hawaii'])]\n",
    "max_value = max(abs(map_gdpenergy['gdp_neighborenergy_coeff'].max()), abs(map_gdpenergy['gdp_neighborenergy_coeff'].min()))\n",
    "\n",
    "# Create the choropleth map\n",
    "fig_gdp_e = px.choropleth(map_gdpenergy, geojson=map_gdpenergy['geometry'], locations=map_gdpenergy.index, color='gdp_neighborenergy_coeff',\n",
    "                    color_continuous_scale='RdBu', color_continuous_midpoint=0, range_color=[-5, 5]) #range_color=[-max_value, max_value])\n",
    "fig_gdp_e.update_geos(fitbounds='locations', resolution=110, scope=\"usa\",\n",
    "    showsubunits=True, subunitcolor=\"Black\", subunitwidth=0.5)\n",
    "fig_gdp_e.update_traces(marker_line_width=0.5)\n",
    "fig_gdp_e.show()\n",
    "\n",
    "fig_gdp_e.write_html('fig_gdpVSenergy.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b32db75",
   "metadata": {},
   "source": [
    "GDP vs Neighbor GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894f1f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge data with location data\n",
    "reg_gdpgdp = reg_coeff[\"gdp_neighborgdp_coeff\"]\n",
    "reg_gdpgdp = reg_gdpgdp.reset_index()\n",
    "reg_gdpgdp = reg_gdpgdp.rename(columns={'FIPS_y':'fips_code'})\n",
    "reg_gdpgdp = reg_gdpgdp.set_index('fips_code')\n",
    "map_data.reset_index().set_index('fips_code', inplace=True)\n",
    "map_gdpgdp = pd.merge(map_data, reg_gdpgdp, left_index=True, right_on='fips_code')\n",
    "\n",
    "\n",
    "#Plot dynamic map\n",
    "# Get the maximum absolute value in the DataFrame\n",
    "map_gdpgdp = map_gdpgdp[~map_gdpgdp['state'].isin(['Alaska', 'Hawaii'])]\n",
    "max_value = max(abs(map_gdpgdp[\"gdp_neighborgdp_coeff\"].max()), abs(map_gdpgdp[\"gdp_neighborgdp_coeff\"].min()))\n",
    "\n",
    "# Create the choropleth map\n",
    "fig_gdp = px.choropleth(map_gdpgdp, geojson=map_gdpgdp['geometry'], locations=map_gdpgdp.index, \n",
    "                    color='gdp_neighborgdp_coeff', color_continuous_scale='RdBu', \n",
    "                    color_continuous_midpoint=0, range_color=[-max_value, max_value])\n",
    "fig_gdp.update_geos(visible=False, resolution=110, scope=\"usa\",\n",
    "    showsubunits=True, subunitcolor=\"Black\", subunitwidth=0.5)\n",
    "fig_gdp.update_geos(fitbounds='locations')\n",
    "fig_gdp.update_traces(marker_line_width=0.5)\n",
    "fig_gdp.show()\n",
    "\n",
    "fig_gdp.write_html('fig_gdpVSgdp.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac5dac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfmp = map_gdpenergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37344ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfmp = dfmp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071c7be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# north_dakota = dfmp[dfmp['state'] == 'North Dakota']#['fips_code']\n",
    "# north_dakota.to_csv('stat_713.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc0a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfaisus_energy = map_energy\n",
    "\n",
    "dfaisus_gdpenergy = reg_gdpenergy\n",
    "\n",
    "dfaisus_gdpgdp = reg_gdpgdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873c72dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd501c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfaisus1 = pd.merge(dfaisus_energy, dfaisus_gdpenergy, left_index=True, right_on='fips_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811462e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfaisus1 = pd.merge(dfaisus1, dfaisus_gdpgdp, left_index=True, right_on='fips_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0945b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfaisus1 = dfaisus1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6818e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba49590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfaisus_energy=dfaisus_energy.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af1e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfaisus_energy = map_energy.reset_index()\n",
    "\n",
    "# map_gdpenergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66c836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate whether the coefficients are positive or negative\n",
    "dfaisus1['sign_energy'] = np.where(dfaisus1['energy_neighborenergy_coeff'] > 0, 'Positive', 'Negative')\n",
    "\n",
    "# Count the occurrences of positive and negative coefficients\n",
    "coeff_counts = dfaisus1['sign_energy'].value_counts()\n",
    "\n",
    "# Create a pie chart\n",
    "plt.figure(figsize=(12, 12))\n",
    "colors = ['green', 'red']\n",
    "plt.pie(coeff_counts, labels=coeff_counts.index, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Distribution of Coefficients')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ccb811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate positive and negative coefficients\n",
    "positive_coeffsenergy = dfaisus1[dfaisus1['energy_neighborenergy_coeff'] > 0]\n",
    "negative_coeffsenergy = dfaisus1[dfaisus1['energy_neighborenergy_coeff'] < 0]\n",
    "\n",
    "# Calculate the range of coefficients within some standard deviations\n",
    "num_std_devs = 2  # Change this value as needed\n",
    "\n",
    "# Create scatter plots\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(positive_coeffsenergy['fips_code'], positive_coeffsenergy['energy_neighborenergy_coeff'], \n",
    "            color='green', label='Positive Coefficients')\n",
    "plt.scatter(negative_coeffsenergy['fips_code'], negative_coeffsenergy['energy_neighborenergy_coeff'], \n",
    "            color='red', label='Negative Coefficients')\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='dashed')\n",
    "plt.title('Scatter Plot of Positive and Negative Coefficients by County')\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Plot positive coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(positive_coeffsenergy['fips_code'], positive_coeffsenergy['energy_neighborenergy_coeff'], \n",
    "            color='green', label='Positive Coefficients')\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='dashed')\n",
    "plt.title('Positive Regression Coefficients by County')\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Plot negative coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(negative_coeffsenergy['fips_code'], negative_coeffsenergy['energy_neighborenergy_coeff'], \n",
    "            color='red', label='Negative Coefficients')\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='dashed')\n",
    "plt.title('Negative Regression Coefficients by County')\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the choropleth map of counties within positive coefficients\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "positive_coeffsenergy.plot(ax=ax, edgecolor='black', cmap='coolwarm')\n",
    "ax.set_title('Counties with positive regression coefficients'.format(num_std_devs))\n",
    "ax.set_axis_off()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the choropleth map of counties within positive coefficients\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "negative_coeffsenergy.plot(ax=ax, edgecolor='black', cmap='coolwarm')\n",
    "ax.set_title('Counties with negative regression coefficients'.format(num_std_devs))\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925158c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation of coefficients\n",
    "coeff_meanenergy = dfaisus1['energy_neighborenergy_coeff'].mean()\n",
    "coeff_stdenergy = dfaisus1['energy_neighborenergy_coeff'].std()\n",
    "\n",
    "# Calculate the range of coefficients within some standard deviations\n",
    "num_std_devs = 2  # Change this value as needed\n",
    "lower_bound = coeff_meanenergy - num_std_devs * coeff_stdenergy\n",
    "upper_bound = coeff_meanenergy + num_std_devs * coeff_stdenergy\n",
    "\n",
    "# Filter coefficients within the specified range\n",
    "# Filter coefficients within and outside the specified range\n",
    "coefficients_within_range1 = dfaisus1[\n",
    "    (dfaisus1['energy_neighborenergy_coeff'] >= lower_bound) & (dfaisus1['energy_neighborenergy_coeff'] <= upper_bound)\n",
    "]\n",
    "coefficients_outside_range1 = dfaisus1[\n",
    "    (dfaisus1['energy_neighborenergy_coeff'] < lower_bound) | (dfaisus1['energy_neighborenergy_coeff'] > upper_bound)\n",
    "]\n",
    "\n",
    "# Plot coefficients within the specified range\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(coefficients_within_range1['fips_code'], coefficients_within_range1['energy_neighborenergy_coeff'], \n",
    "            color='blue', label='Within {} Std Dev'.format(num_std_devs))\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='dashed')\n",
    "plt.title('Regression Coefficients within {} Standard Deviations from Mean'.format(num_std_devs))\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Plot coefficients outside the specified range\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(coefficients_outside_range1['fips_code'], coefficients_outside_range1['energy_neighborenergy_coeff'], \n",
    "            color='blue', label='Outside {} Std Dev'.format(num_std_devs))\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='dashed')\n",
    "plt.title('Regression Coefficients outside {} Standard Deviations from Mean'.format(num_std_devs))\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e1bb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the choropleth map of counties within the specified range\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "coefficients_within_range1.plot(ax=ax, edgecolor='black', cmap='coolwarm')\n",
    "ax.set_title('Counties within {} Standard Deviations'.format(num_std_devs))\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e0e4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the choropleth map of counties outside the specified range\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "coefficients_outside_range1.plot(ax=ax, edgecolor='black', cmap='coolwarm')\n",
    "ax.set_title('Counties outside {} Standard Deviations'.format(num_std_devs))\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e2cf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean of coefficients\n",
    "coeff_mean1 = dfaisus1['energy_neighborenergy_coeff'].mean()\n",
    "\n",
    "# Plot the distribution of coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(dfaisus1['energy_neighborenergy_coeff'], bins=10, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.axvline(coeff_mean1, color='red', linestyle='dashed', linewidth=2, label='Mean')\n",
    "plt.title('Distribution of Regression Coefficients')\n",
    "plt.xlabel('Coefficient')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# # Plot of the distribution for regression coefficients\n",
    "# plot = plt.hist(dfaisus_energy['energy_neighborenergy_coeff'], bins=20, edgecolor='black')\n",
    "# plt.axvline(np.mean(dfaisus_energy['energy_neighborenergy_coeff']), color='red', linestyle='dashed', linewidth=2)\n",
    "# plt.xlabel('Regression Coefficient')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Distribution of Regression Coefficients')\n",
    "\n",
    "\n",
    "# min_value = np.min(dfaisus_energy['energy_neighborenergy_coeff'])\n",
    "# max_value = np.max(dfaisus_energy['energy_neighborenergy_coeff'])\n",
    "# plt.xlim(min_value, max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfddadf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_data = dfaisus1\n",
    "\n",
    "# Calculate mean and standard deviation of coefficients\n",
    "coeff_mean1 = regression_data['energy_neighborenergy_coeff'].mean()\n",
    "coeff_std1 = regression_data['energy_neighborenergy_coeff'].std()\n",
    "\n",
    "# Define threshold values as 2 standard deviations from the mean\n",
    "large_threshold1 = coeff_mean1 + 2 * coeff_std1\n",
    "small_threshold1 = coeff_mean1 - 2 * coeff_std1\n",
    "\n",
    "# Categorize coefficients\n",
    "regression_data['Category'] = 'Other'\n",
    "regression_data.loc[regression_data['energy_neighborenergy_coeff'] > large_threshold1, 'Category'] = 'Large Positive'\n",
    "regression_data.loc[(regression_data['energy_neighborenergy_coeff'] <= large_threshold1) & (regression_data['energy_neighborenergy_coeff'] > 0), 'Category'] = 'Small Positive'\n",
    "regression_data.loc[regression_data['energy_neighborenergy_coeff'] < small_threshold1, 'Category'] = 'Large Negative'\n",
    "regression_data.loc[(regression_data['energy_neighborenergy_coeff'] >= small_threshold1) & (regression_data['energy_neighborenergy_coeff'] < 0), 'Category'] = 'Small Negative'\n",
    "\n",
    "# Separate the data based on categories\n",
    "large_positive_coeffs1 = regression_data[regression_data['Category'] == 'Large Positive']\n",
    "small_positive_coeffs1 = regression_data[regression_data['Category'] == 'Small Positive']\n",
    "large_negative_coeffs1 = regression_data[regression_data['Category'] == 'Large Negative']\n",
    "small_negative_coeffs1 = regression_data[regression_data['Category'] == 'Small Negative']\n",
    "\n",
    "# Create scatter plots\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(large_positive_coeffs1['fips_code'], large_positive_coeffs1['energy_neighborenergy_coeff'], \n",
    "            color='green', marker='o', label='Large Positive')\n",
    "plt.scatter(small_positive_coeffs1['fips_code'], small_positive_coeffs1['energy_neighborenergy_coeff'], \n",
    "            color='lightgreen', marker='o', label='Small Positive')\n",
    "plt.scatter(large_negative_coeffs1['fips_code'], large_negative_coeffs1['energy_neighborenergy_coeff'], \n",
    "            color='red', marker='x', label='Large Negative')\n",
    "plt.scatter(small_negative_coeffs1['fips_code'], small_negative_coeffs1['energy_neighborenergy_coeff'], \n",
    "            color='salmon', marker='x', label='Small Negative')\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='dashed')\n",
    "plt.title('Scatter Plot of Coefficients by County and Category')\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61be8e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08974907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the count of each category\n",
    "category_counts = regression_data['Category'].value_counts()\n",
    "\n",
    "# Create a pie chart\n",
    "plt.figure(figsize=(12, 12))\n",
    "colors = ['green', 'red', 'lightgreen', 'salmon']\n",
    "plt.pie(category_counts, labels=category_counts.index, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Distribution of Coefficient Categories')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9726d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of coefficient categories\n",
    "plt.figure(figsize=(10, 6))\n",
    "category_order = ['Small Positive', 'Small Negative', 'Large Positive', 'Large Negative']\n",
    "plt.hist(regression_data['Category'], bins=len(category_order), rwidth=0.8, align='left', color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of Coefficient Categories')\n",
    "plt.xlabel('Coefficient Category')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(range(len(category_order)), category_order, rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e1370e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc3fc715",
   "metadata": {},
   "source": [
    "GDP vs Neighbors Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f71a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfaisus_energy = map_gdpenergy.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05375a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfaisus_energy=dfaisus_energy.rename(columns={'gdp_neighborenergy_coeff': 'energy_neighborenergy_coeff'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92a2b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate whether the coefficients are positive or negative\n",
    "dfaisus1['sign_gdpenergy'] = np.where(dfaisus1['gdp_neighborenergy_coeff'] > 0, 'Positive', 'Negative')\n",
    "\n",
    "# Count the occurrences of positive and negative coefficients\n",
    "coeff_counts = dfaisus1['sign_gdpenergy'].value_counts()\n",
    "\n",
    "# Create a pie chart\n",
    "plt.figure(figsize=(12, 12))\n",
    "colors = ['green', 'red']\n",
    "plt.pie(coeff_counts, labels=coeff_counts.index, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "#plt.title('Distribution of Positive and Negative Coefficients')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a703a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate positive and negative coefficients\n",
    "positive_coeffs = dfaisus1[dfaisus1['gdp_neighborenergy_coeff'] > 0]\n",
    "negative_coeffs = dfaisus1[dfaisus1['gdp_neighborenergy_coeff'] < 0]\n",
    "\n",
    "# Create scatter plots\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(positive_coeffs['fips_code'], positive_coeffs['gdp_neighborenergy_coeff'], \n",
    "            color='green', label='Positive Coefficients')\n",
    "plt.scatter(negative_coeffs['fips_code'], negative_coeffs['gdp_neighborenergy_coeff'], \n",
    "            color='red', label='Negative Coefficients')\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='dashed')\n",
    "plt.title('Scatter Plot of Positive and Negative Coefficients by County')\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Plot positive coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(positive_coeffs['fips_code'], positive_coeffs['gdp_neighborenergy_coeff'], \n",
    "            color='green', label='Positive Coefficients')\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='dashed')\n",
    "plt.title('Positive Regression Coefficients by County')\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Plot negative coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(negative_coeffs['fips_code'], negative_coeffs['gdp_neighborenergy_coeff'], \n",
    "            color='red', label='Negative Coefficients')\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='dashed')\n",
    "plt.title('Negative Regression Coefficients by County')\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the choropleth map of counties within positive coefficients\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "positive_coeffs.plot(ax=ax, edgecolor='black', cmap='coolwarm', legend='True')\n",
    "ax.set_title('Counties with positive regression coefficients'.format(num_std_devs))\n",
    "ax.set_axis_off()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the choropleth map of counties within positive coefficients\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "negative_coeffs.plot(ax=ax, edgecolor='black', cmap='coolwarm')\n",
    "ax.set_title('Counties with negative regression coefficients'.format(num_std_devs))\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074ea0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plots with regression coefficients on the x-axis\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot for positive coefficients\n",
    "plt.scatter(positive_coeffs['fips_code'], positive_coeffs['gdp_neighborenergy_coeff'], \n",
    "            color='green', label='Positive Coefficients')\n",
    "\n",
    "# Scatter plot for negative coefficients\n",
    "plt.scatter(negative_coeffs['fips_code'], negative_coeffs['gdp_neighborenergy_coeff'], \n",
    "            color='red', label='Negative Coefficients')\n",
    "\n",
    "# Horizontal lines for the regression coefficients\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='dashed')\n",
    "for index, row in positive_coeffs.iterrows():\n",
    "    plt.plot([row['fips_code'], row['fips_code']], [0, row['gdp_neighborenergy_coeff']], \n",
    "             color='green', linestyle='-', linewidth=1)\n",
    "for index, row in negative_coeffs.iterrows():\n",
    "    plt.plot([row['fips_code'], row['fips_code']], [0, row['gdp_neighborenergy_coeff']], \n",
    "             color='red', linestyle='-', linewidth=1)\n",
    "\n",
    "plt.title('Scatter Plot of Positive and Negative Coefficients by County')\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747bd453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plots with regression coefficients on the x-axis and trend lines\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot for positive coefficients\n",
    "plt.scatter(positive_coeffs['fips_code'], positive_coeffs['gdp_neighborenergy_coeff'], \n",
    "            color='green', label='Positive Coefficients')\n",
    "\n",
    "# Scatter plot for negative coefficients\n",
    "plt.scatter(negative_coeffs['fips_code'], negative_coeffs['gdp_neighborenergy_coeff'], \n",
    "            color='red', label='Negative Coefficients')\n",
    "\n",
    "# Trend line for positive coefficients\n",
    "positive_trend_x = np.linspace(min(positive_coeffs['fips_code']), max(positive_coeffs['fips_code']), 100)\n",
    "positive_trend_y = np.polyval(np.polyfit(positive_coeffs['fips_code'], positive_coeffs['gdp_neighborenergy_coeff'], 1), \n",
    "                              positive_trend_x)\n",
    "plt.plot(positive_trend_x, positive_trend_y, color='green', linestyle='-', linewidth=2)\n",
    "\n",
    "# Trend line for negative coefficients\n",
    "negative_trend_x = np.linspace(min(negative_coeffs['fips_code']), max(negative_coeffs['fips_code']), 100)\n",
    "negative_trend_y = np.polyval(np.polyfit(negative_coeffs['fips_code'], negative_coeffs['gdp_neighborenergy_coeff'], 1), \n",
    "                              negative_trend_x)\n",
    "plt.plot(negative_trend_x, negative_trend_y, color='red', linestyle='-', linewidth=2)\n",
    "\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='dashed')\n",
    "plt.title('Scatter Plot of Positive and Negative Coefficients by County')\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb9520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation of coefficients\n",
    "coeff_mean = dfaisus1['gdp_neighborenergy_coeff'].mean()\n",
    "coeff_std = dfaisus1['gdp_neighborenergy_coeff'].std()\n",
    "\n",
    "# Calculate the range of coefficients within some standard deviations\n",
    "num_std_devs = 2  # Change this value as needed\n",
    "lower_bound = coeff_mean - num_std_devs * coeff_std\n",
    "upper_bound = coeff_mean + num_std_devs * coeff_std\n",
    "\n",
    "# Filter coefficients within the specified range\n",
    "# Filter coefficients within and outside the specified range\n",
    "coefficients_within_range = dfaisus1[\n",
    "    (dfaisus1['gdp_neighborenergy_coeff'] >= lower_bound) & (dfaisus1['gdp_neighborenergy_coeff'] <= upper_bound)\n",
    "]\n",
    "coefficients_outside_range = dfaisus1[\n",
    "    (dfaisus1['gdp_neighborenergy_coeff'] < lower_bound) | (dfaisus1['gdp_neighborenergy_coeff'] > upper_bound)\n",
    "]\n",
    "\n",
    "# Plot coefficients within the specified range\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(coefficients_within_range['fips_code'], coefficients_within_range['gdp_neighborenergy_coeff'], \n",
    "            color='blue', label='Within {} Std Dev'.format(num_std_devs))\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='dashed')\n",
    "plt.title('Regression Coefficients within {} Standard Deviations from Mean'.format(num_std_devs))\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Plot coefficients outside the specified range\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(coefficients_outside_range['fips_code'], coefficients_outside_range['gdp_neighborenergy_coeff'], \n",
    "            color='blue', label='Outside {} Std Dev'.format(num_std_devs))\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='dashed')\n",
    "plt.title('Regression Coefficients outside {} Standard Deviations from Mean'.format(num_std_devs))\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3521f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot with a single trend line for the entire dataframe\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot for all coefficients\n",
    "plt.scatter(dfaisus1['fips_code'], dfaisus1['gdp_neighborenergy_coeff'], color='blue', label='Coefficients')\n",
    "\n",
    "# Trend line for all coefficients\n",
    "trend_x = np.linspace(min(dfaisus1['fips_code']), max(dfaisus1['fips_code']), 100)\n",
    "trend_y = np.polyval(np.polyfit(dfaisus1['fips_code'], dfaisus1['gdp_neighborenergy_coeff'], 1), trend_x)\n",
    "plt.plot(trend_x, trend_y, color='blue', linestyle='-', linewidth=2)\n",
    "\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='dashed')\n",
    "plt.title('Scatter Plot and Trend Line of Coefficients by County')\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc11448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean of coefficients\n",
    "coeff_mean = dfaisus1['gdp_neighborenergy_coeff'].mean()\n",
    "\n",
    "# Plot the distribution of coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(dfaisus1['gdp_neighborenergy_coeff'], bins=10, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.axvline(coeff_mean, color='red', linestyle='dashed', linewidth=2, label='Mean')\n",
    "plt.title('Distribution of Regression Coefficients')\n",
    "plt.xlabel('Coefficient')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# # Plot of the distribution for regression coefficients\n",
    "# plot = plt.hist(dfaisus_energy['energy_neighborenergy_coeff'], bins=20, edgecolor='black')\n",
    "# plt.axvline(np.mean(dfaisus_energy['energy_neighborenergy_coeff']), color='red', linestyle='dashed', linewidth=2)\n",
    "# plt.xlabel('Regression Coefficient')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Distribution of Regression Coefficients')\n",
    "\n",
    "\n",
    "# min_value = np.min(dfaisus_energy['energy_neighborenergy_coeff'])\n",
    "# max_value = np.max(dfaisus_energy['energy_neighborenergy_coeff'])\n",
    "# plt.xlim(min_value, max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2d78f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation of coefficients\n",
    "coeff_mean = regression_data['gdp_neighborenergy_coeff'].mean()\n",
    "coeff_std = regression_data['gdp_neighborenergy_coeff'].std()\n",
    "\n",
    "# Define threshold values as 2 standard deviations from the mean\n",
    "large_threshold = coeff_mean + 2 * coeff_std\n",
    "small_threshold = coeff_mean - 2 * coeff_std\n",
    "\n",
    "# Categorize coefficients\n",
    "regression_data['Category1'] = 'Other'\n",
    "regression_data.loc[regression_data['gdp_neighborenergy_coeff'] > large_threshold, 'Category1'] = 'Large Positive'\n",
    "regression_data.loc[(regression_data['gdp_neighborenergy_coeff'] <= large_threshold) & (regression_data['gdp_neighborenergy_coeff'] > 0), 'Category1'] = 'Small Positive'\n",
    "regression_data.loc[regression_data['gdp_neighborenergy_coeff'] < small_threshold, 'Category1'] = 'Large Negative'\n",
    "regression_data.loc[(regression_data['gdp_neighborenergy_coeff'] >= small_threshold) & (regression_data['gdp_neighborenergy_coeff'] < 0), 'Category1'] = 'Small Negative'\n",
    "\n",
    "# Separate the data based on categories\n",
    "large_positive_coeffs = regression_data[regression_data['Category1'] == 'Large Positive']\n",
    "small_positive_coeffs = regression_data[regression_data['Category1'] == 'Small Positive']\n",
    "large_negative_coeffs = regression_data[regression_data['Category1'] == 'Large Negative']\n",
    "small_negative_coeffs = regression_data[regression_data['Category1'] == 'Small Negative']\n",
    "\n",
    "# Create scatter plots\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(large_positive_coeffs['fips_code'], large_positive_coeffs['gdp_neighborenergy_coeff'], \n",
    "            color='green', marker='o', label='Large Positive')\n",
    "plt.scatter(small_positive_coeffs['fips_code'], small_positive_coeffs['gdp_neighborenergy_coeff'], \n",
    "            color='lightgreen', marker='o', label='Small Positive')\n",
    "plt.scatter(large_negative_coeffs['fips_code'], large_negative_coeffs['gdp_neighborenergy_coeff'], \n",
    "            color='red', marker='x', label='Large Negative')\n",
    "plt.scatter(small_negative_coeffs['fips_code'], small_negative_coeffs['gdp_neighborenergy_coeff'], \n",
    "            color='salmon', marker='x', label='Small Negative')\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='dashed')\n",
    "plt.title('Scatter Plot of Coefficients by County and Category')\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef443e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the count of each category\n",
    "category_counts = regression_data['Category1'].value_counts()\n",
    "\n",
    "# Create a pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "colors = ['green', 'red', 'lightgreen', 'salmon']\n",
    "plt.pie(category_counts, labels=category_counts.index, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Distribution of Coefficient Categories')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba7f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a histogram of coefficient categories\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# category_order = ['Large Positive', 'Small Positive', 'Small Negative', 'Large Negative']\n",
    "# plt.hist(regression_data['Category1'], bins=len(category_order), rwidth=0.8, align='left', color='skyblue', edgecolor='black')\n",
    "# plt.title('Histogram of Coefficient Categories')\n",
    "# plt.xlabel('Coefficient Category')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.xticks(range(len(category_order)), category_order, rotation=45)\n",
    "# plt.grid(axis='y')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501c64d6",
   "metadata": {},
   "source": [
    "GDP vs Neighbors GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885ace92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfaisus_energy = map_gdpgdp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbc550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfaisus_energy=dfaisus_energy.rename(columns={'gdp_neighborgdp_coeff': 'energy_neighborenergy_coeff'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd385d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837e1705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate whether the coefficients are positive or negative\n",
    "dfaisus1['sign_gdpgdp'] = np.where(dfaisus1['gdp_neighborgdp_coeff'] > 0, 'Positive', 'Negative')\n",
    "\n",
    "# Count the occurrences of positive and negative coefficients\n",
    "coeff_counts = dfaisus1['sign_gdpgdp'].value_counts()\n",
    "\n",
    "# Create a pie chart\n",
    "plt.figure(figsize=(12, 12))\n",
    "colors = ['green', 'red']\n",
    "plt.pie(coeff_counts, labels=coeff_counts.index, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "#plt.title('Distribution of Positive and Negative Coefficients')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1d3264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate positive and negative coefficients\n",
    "positive_coeffs = dfaisus1[dfaisus1['gdp_neighborgdp_coeff'] > 0]\n",
    "negative_coeffs = dfaisus1[dfaisus1['gdp_neighborgdp_coeff'] < 0]\n",
    "\n",
    "# Create scatter plots\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(positive_coeffs['fips_code'], positive_coeffs['gdp_neighborgdp_coeff'], \n",
    "            color='green', label='Positive Coefficients')\n",
    "plt.scatter(negative_coeffs['fips_code'], negative_coeffs['gdp_neighborgdp_coeff'], \n",
    "            color='red', label='Negative Coefficients')\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='dashed')\n",
    "plt.title('Scatter Plot of Positive and Negative Coefficients by County')\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Plot positive coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(positive_coeffs['fips_code'], positive_coeffs['gdp_neighborgdp_coeff'], \n",
    "            color='green', label='Positive Coefficients')\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='dashed')\n",
    "plt.title('Positive Regression Coefficients by County')\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Plot negative coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(negative_coeffs['fips_code'], negative_coeffs['gdp_neighborgdp_coeff'], \n",
    "            color='red', label='Negative Coefficients')\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='dashed')\n",
    "plt.title('Negative Regression Coefficients by County')\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the choropleth map of counties within positive coefficients\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "positive_coeffs.plot(ax=ax, edgecolor='black', cmap='coolwarm')\n",
    "ax.set_title('Counties with positive regression coefficients'.format(num_std_devs))\n",
    "ax.set_axis_off()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the choropleth map of counties within positive coefficients\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "negative_coeffs.plot(ax=ax, edgecolor='black', cmap='coolwarm')\n",
    "ax.set_title('Counties with negative regression coefficients'.format(num_std_devs))\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd65b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c85fcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate positive and negative coefficients\n",
    "positive_coeffs = dfaisus1[dfaisus1['gdp_neighborgdp_coeff'] > 0]\n",
    "negative_coeffs = dfaisus1[dfaisus1['gdp_neighborgdp_coeff'] < 0]\n",
    "\n",
    "# Calculate the overall trend line for coefficients\n",
    "coeff_trend_x = np.linspace(min(dfaisus1['fips_code']), max(dfaisus1['fips_code']), 100)\n",
    "coeff_trend_y = np.polyval(np.polyfit(dfaisus1['fips_code'], dfaisus1['gdp_neighborgdp_coeff'], 1), coeff_trend_x)\n",
    "another_trend_y = np.polyval(np.polyfit(dfaisus1['fips_code'], dfaisus1['energy_neighborenergy_coeff'], 1), coeff_trend_x)\n",
    "trend_full = np.polyval(np.polyfit(full_datapoint['fips_code'], full_datapoint['All industry total_y'], 1), coeff_trend_x)\n",
    "\n",
    "# Create scatter plots\n",
    "plt.figure(figsize=(40, 24))\n",
    "\n",
    "# Scatter plot for positive coefficients\n",
    "plt.scatter(positive_coeffs['fips_code'], positive_coeffs['gdp_neighborgdp_coeff'], \n",
    "            color='green', label='Positive Coefficients')\n",
    "\n",
    "# Scatter plot for negative coefficients\n",
    "plt.scatter(negative_coeffs['fips_code'], negative_coeffs['gdp_neighborgdp_coeff'], \n",
    "            color='red', label='Negative Coefficients')\n",
    "\n",
    "# Plot the overall trend line for coefficients\n",
    "plt.plot(coeff_trend_x, coeff_trend_y, color='blue', label='gdp vs gdp Trend', linestyle='-', linewidth=2)\n",
    "\n",
    "# Plot another trend line for energy vs energy column\n",
    "plt.plot(coeff_trend_x, another_trend_y, color='orange', label='energy vs energy Trend', linestyle='-', linewidth=2)\n",
    "\n",
    "# Plot another trend line for full df\n",
    "plt.plot(coeff_trend_x, trend_full, color='purple', label='full data points', linestyle='-', linewidth=2)\n",
    "\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='dashed')\n",
    "plt.title('Scatter Plot and Coefficient Trend by County')\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb3ba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes based on 'fips_code'\n",
    "merged_df = df1.merge(df2, on='fips_code', suffixes=('_df1', '_df2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36800d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_datapoint = energy_df['Diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e339a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_datapoint = full_datapoint.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742d921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_datapoint = full_datapoint.rename(columns={'FIPS_y':'fips_code'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2168056",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfaisus2 = dfaisus1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2b830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_full = full_datapoint.merge(dfaisus2, on='fips_code', suffixes=('full_datapoint', 'dfaisus2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c0bbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_full2 = merge_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31318bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_full2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c33c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_full2['xbeta'] = merge_full2['NeighborGDP'] * merge_full2['gdp_neighborgdp_coeff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ec48bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_full2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168e3ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merge_full['All industry total_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ff3074",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.random.uniform(0, 10, 46438))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0444c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Create scatter plot\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# # Mapping fips_code to a continuous range from 0 to 50\n",
    "# continuous_x = np.linspace(0, 100, len(merge_full['fips_code']))\n",
    "\n",
    "# # Scatter plot for full data GDP\n",
    "# plt.scatter(continuous_x, merge_full['All industry total_y'], color='blue', label='GDP')\n",
    "\n",
    "# # Scatter plot for beta estimates\n",
    "# plt.scatter(continuous_x, merge_full['gdp_neighborenergy_coeff'], color='red', label='Beta estimates')\n",
    "\n",
    "# plt.title('Scatter Plot Comparison between GDP and Neighbor GDP')\n",
    "# plt.xlabel('values')\n",
    "# plt.ylabel('Estimates & GDP')\n",
    "# plt.legend()\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.grid(axis='y')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Sample data - Replace with your actual data\n",
    "# Assume 'x_data' and 'y_data' are the continuous variables\n",
    "x_data = merge_full['energy']#np.random.uniform(0, 50, 2756)  # Continuous variable for x-axis\n",
    "y_data = merge_full['Neighborenergy']#np.random.uniform(0, 100, 2756)  # Continuous variable for y-axis\n",
    "color_data = merge_full['energy_neighborenergy_coeff']  # Numeric values for color\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "# Scatter plot with color reflecting the numeric value of parameter estimate\n",
    "scatter = plt.scatter(x_data, y_data, c=color_data, cmap='viridis', label='Scatter Plot')\n",
    "\n",
    "# Adding a colorbar to indicate the color scale\n",
    "plt.colorbar(scatter, label='Parameter Estimate', vmin=-10, vmax=10)\n",
    "\n",
    "plt.title('Scatter Plot with Color Reflecting Parameter Estimate')\n",
    "plt.xlabel('energy')\n",
    "plt.ylabel('Neighbor energy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a4aafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Sample data - Replace with your actual data\n",
    "x_data = merge_full['energy']\n",
    "y_data = merge_full['Neighborenergy']\n",
    "color_data = merge_full['energy_neighborenergy_coeff']\n",
    "\n",
    "# Define the colormap and normalize the color data\n",
    "cmap = plt.get_cmap('viridis')\n",
    "norm = mcolors.Normalize(vmin=-4, vmax=4)\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "# Scatter plot with color reflecting the numeric value of parameter estimate\n",
    "scatter = plt.scatter(x_data, y_data, c=color_data, cmap=cmap, norm=norm, label='Scatter Plot')\n",
    "\n",
    "# Creating a custom colorbar\n",
    "cbar = plt.colorbar(scatter, label='Parameter Estimate')\n",
    "cbar.set_ticks([-4, 0, 4])  # Set tick positions\n",
    "cbar.set_ticklabels(['-4', '0', '4'])  # Set tick labels\n",
    "\n",
    "plt.title('Scatter Plot with Color Reflecting Parameter Estimate')\n",
    "plt.xlabel('energy')\n",
    "plt.ylabel('Neighbor energy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4470c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data - Replace with your actual data\n",
    "# Assume 'x_data' and 'y_data' are the continuous variables\n",
    "x_data = np.random.uniform(0, 50, 100)  # Continuous variable for x-axis\n",
    "y_data = np.random.uniform(0, 100, 100)  # Continuous variable for y-axis\n",
    "color_data = np.random.uniform(0, 1, 100)  # Numeric values for color\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot with color reflecting the numeric value of parameter estimate\n",
    "scatter = plt.scatter(x_data, y_data, c=color_data, cmap='viridis', label='Scatter Plot')\n",
    "\n",
    "# Adding a colorbar to indicate the color scale\n",
    "plt.colorbar(scatter, label='Parameter Estimate')\n",
    "\n",
    "plt.title('Scatter Plot with Color Reflecting Parameter Estimate')\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa40143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation of coefficients\n",
    "coeff_mean = dfaisus1['gdp_neighborgdp_coeff'].mean()\n",
    "coeff_std = dfaisus1['gdp_neighborgdp_coeff'].std()\n",
    "\n",
    "# Calculate the range of coefficients within some standard deviations\n",
    "num_std_devs = 2  # Change this value as needed\n",
    "lower_bound = coeff_mean - num_std_devs * coeff_std\n",
    "upper_bound = coeff_mean + num_std_devs * coeff_std\n",
    "\n",
    "# Filter coefficients within the specified range\n",
    "# Filter coefficients within and outside the specified range\n",
    "coefficients_within_range = dfaisus1[\n",
    "    (dfaisus1['gdp_neighborgdp_coeff'] >= lower_bound) & (dfaisus1['gdp_neighborgdp_coeff'] <= upper_bound)\n",
    "]\n",
    "coefficients_outside_range = dfaisus1[\n",
    "    (dfaisus1['gdp_neighborgdp_coeff'] < lower_bound) | (dfaisus1['gdp_neighborgdp_coeff'] > upper_bound)\n",
    "]\n",
    "\n",
    "# Plot coefficients within the specified range\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(coefficients_within_range['fips_code'], coefficients_within_range['gdp_neighborgdp_coeff'], \n",
    "            color='blue', label='Within {} Std Dev'.format(num_std_devs))\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='dashed')\n",
    "plt.title('Regression Coefficients within {} Standard Deviations from Mean'.format(num_std_devs))\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Plot coefficients outside the specified range\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(coefficients_outside_range['fips_code'], coefficients_outside_range['gdp_neighborgdp_coeff'], \n",
    "            color='blue', label='Outside {} Std Dev'.format(num_std_devs))\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='dashed')\n",
    "plt.title('Regression Coefficients outside {} Standard Deviations from Mean'.format(num_std_devs))\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bab3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean of coefficients\n",
    "coeff_mean = dfaisus1['gdp_neighborgdp_coeff'].mean()\n",
    "\n",
    "# Plot the distribution of coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(dfaisus1['gdp_neighborgdp_coeff'], bins=10, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.axvline(coeff_mean, color='red', linestyle='dashed', linewidth=2, label='Mean')\n",
    "plt.title('Distribution of Regression Coefficients')\n",
    "plt.xlabel('Coefficient')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# # Plot of the distribution for regression coefficients\n",
    "# plot = plt.hist(dfaisus_energy['energy_neighborenergy_coeff'], bins=20, edgecolor='black')\n",
    "# plt.axvline(np.mean(dfaisus_energy['energy_neighborenergy_coeff']), color='red', linestyle='dashed', linewidth=2)\n",
    "# plt.xlabel('Regression Coefficient')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Distribution of Regression Coefficients')\n",
    "\n",
    "\n",
    "# min_value = np.min(dfaisus_energy['energy_neighborenergy_coeff'])\n",
    "# max_value = np.max(dfaisus_energy['energy_neighborenergy_coeff'])\n",
    "# plt.xlim(min_value, max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5217d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_data = dfaisus1\n",
    "\n",
    "# Calculate mean and standard deviation of coefficients\n",
    "coeff_mean = regression_data['gdp_neighborgdp_coeff'].mean()\n",
    "coeff_std = regression_data['gdp_neighborgdp_coeff'].std()\n",
    "\n",
    "# Define threshold values as 2 standard deviations from the mean\n",
    "large_threshold = coeff_mean + 2 * coeff_std\n",
    "small_threshold = coeff_mean - 2 * coeff_std\n",
    "\n",
    "# Categorize coefficients\n",
    "regression_data['Category2'] = 'Other'\n",
    "regression_data.loc[regression_data['gdp_neighborgdp_coeff'] > large_threshold, 'Category2'] = 'Large Positive'\n",
    "regression_data.loc[(regression_data['gdp_neighborgdp_coeff'] <= large_threshold) & (regression_data['gdp_neighborgdp_coeff'] > 0), 'Category2'] = 'Small Positive'\n",
    "regression_data.loc[regression_data['gdp_neighborgdp_coeff'] < small_threshold, 'Category2'] = 'Large Negative'\n",
    "regression_data.loc[(regression_data['gdp_neighborgdp_coeff'] >= small_threshold) & (regression_data['gdp_neighborgdp_coeff'] < 0), 'Category2'] = 'Small Negative'\n",
    "\n",
    "# Separate the data based on categories\n",
    "large_positive_coeffs = regression_data[regression_data['Category2'] == 'Large Positive']\n",
    "small_positive_coeffs = regression_data[regression_data['Category2'] == 'Small Positive']\n",
    "large_negative_coeffs = regression_data[regression_data['Category2'] == 'Large Negative']\n",
    "small_negative_coeffs = regression_data[regression_data['Category2'] == 'Small Negative']\n",
    "\n",
    "# Create scatter plots\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(large_positive_coeffs['fips_code'], large_positive_coeffs['gdp_neighborgdp_coeff'], \n",
    "            color='green', marker='o', label='Large Positive')\n",
    "plt.scatter(small_positive_coeffs['fips_code'], small_positive_coeffs['gdp_neighborgdp_coeff'], \n",
    "            color='lightgreen', marker='o', label='Small Positive')\n",
    "plt.scatter(large_negative_coeffs['fips_code'], large_negative_coeffs['gdp_neighborgdp_coeff'], \n",
    "            color='red', marker='x', label='Large Negative')\n",
    "plt.scatter(small_negative_coeffs['fips_code'], small_negative_coeffs['gdp_neighborgdp_coeff'], \n",
    "            color='salmon', marker='x', label='Small Negative')\n",
    "plt.axhline(0, color='black', linewidth=0.8, linestyle='dashed')\n",
    "plt.title('Scatter Plot of Coefficients by County and Category')\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af7cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the count of each category\n",
    "category_counts = regression_data['Category2'].value_counts()\n",
    "\n",
    "# Create a pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "colors = ['lightgreen', 'salmon', 'green', 'red']\n",
    "plt.pie(category_counts, labels=category_counts.index, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Distribution of Coefficient Categories')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b7fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a histogram of coefficient categories\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# category_order = ['Large Positive', 'Small Positive', 'Small Negative', 'Large Negative']\n",
    "# plt.hist(regression_data['Category2'], bins=len(category_order), rwidth=0.8, align='left', color='skyblue', edgecolor='black')\n",
    "# plt.title('Histogram of Coefficient Categories')\n",
    "# plt.xlabel('Coefficient Category')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.xticks(range(len(category_order)), category_order, rotation=45)\n",
    "# plt.grid(axis='y')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b363b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4500c74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96608343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bb3b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1412ae65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73838a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12c22a2e",
   "metadata": {},
   "source": [
    "Try looping to create map from a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0f98dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg_df_map = reg_coeff_map.reset_index()\n",
    "\n",
    "# reg_df_map = reg_df_map.rename(columns={'FIPS_y':'fips_code'})\n",
    "\n",
    "# reg_df_map = reg_df_map.set_index('fips_code')\n",
    "\n",
    "# map_data.reset_index().set_index('fips_code', inplace=True)\n",
    "\n",
    "# reg_df_map = pd.merge(map_data, reg_df_map, left_index=True, right_on='fips_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8917489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List of column names\n",
    "# column_names = ['gdp_neighborgdp_coeff', 'gdp_neighborenergy_coeff', 'gdp_neighborenergy_coeff']\n",
    "\n",
    "# # Calculate the maximum absolute value for each column\n",
    "# max_values = reg_df_map[column_names].abs().max()\n",
    "\n",
    "# # Get the overall maximum value\n",
    "# max_value = max_values.max()\n",
    "\n",
    "# # Loop through the columns\n",
    "# for column in column_names:\n",
    "#     fig = px.choropleth(\n",
    "#         reg_df_map,\n",
    "#         geojson=reg_df_map['geometry'],\n",
    "#         locations=reg_df_map.index,\n",
    "#         color=column,\n",
    "#         color_continuous_scale='RdBu',\n",
    "#         color_continuous_midpoint=0,\n",
    "#         range_color=[-max_value, max_value]\n",
    "#     )\n",
    "#     fig.update_geos(fitbounds='locations', visible=False)\n",
    "#     fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62763cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_names = ['gdp_neighborgdp_coeff', 'gdp_neighborenergy_coeff', 'gdp_neighborenergy_coeff']\n",
    "\n",
    "# # Loop through the columns\n",
    "# for column in column_names:\n",
    "#     fig = px.choropleth(reg_df_map, geojson=reg_df_map['geometry'], locations=reg_df_map.index, color=column)\n",
    "#     fig.update_geos(fitbounds='locations', visible=False)\n",
    "#     fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd971b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1880b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4497e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.reset_index(inplace=True)\n",
    "\n",
    "corr_pop.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f878a8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr= corr.rename(columns={'FIPS_y': 'fips_code', 'NeighborGDP_y':'corr_GDP'})\n",
    "\n",
    "corr_pop = corr_pop.rename(columns={'FIPS_y': 'fips_code', 'NeighborGDP_y':'corr_GDP_pop'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d95e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_data.reset_index().set_index('fips_code', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911e1f88",
   "metadata": {},
   "outputs": [],
   "source": [
    " tdf = pd.merge(map_data, corr_pop, left_index=True, right_on='fips_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c55b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (26,16))\n",
    "tdf.plot(column = \"ownGDP_pop\", ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603d639a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b1ef90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438df080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182f1ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e5e0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd4746b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d190522f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e95193b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2973a43a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e526efac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0670a6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd92a606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2778be6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4121ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9e86061",
   "metadata": {},
   "source": [
    "## AI update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282c6bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy().reset_index().set_index(\"TimePeriod\")\n",
    "df1 = df1.join(divisia).reset_index()     \n",
    "df1 = df1.set_index([\"FIPS_y\", \"TimePeriod\"])    \n",
    "df1 = df1.sort_index()\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a48f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_key = ['Agriculture, forestry, fishing and hunting_y',\n",
    " 'Mining, quarrying, and oil and gas extraction_y',\n",
    " 'Utilities_y',\n",
    " \"All industry total_y\", 'NeighborGDP_y', 'GDP_weigh', 'M4', 'M4 Interest Rate']\n",
    "df2 = df1[df2_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bccdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = {}\n",
    "df3[\"Log data\"] = np.log(df2).replace([np.inf, -np.inf], np.nan)\n",
    "df3[\"Diff\"] = df3[\"Log data\"].groupby(\"FIPS_y\").diff().dropna()\n",
    "df3[\"Diff2\"] = df3[\"Diff\"].groupby(\"FIPS_y\").diff() \n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b6c382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092cb61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ips_test(data):\n",
    "    index_name, sub_index_name = data.index.names\n",
    "    index = list(data.reset_index()[index_name].unique())\n",
    "    N = len(index)\n",
    "    t_stats = {}\n",
    "    df_index_dict = {}\n",
    "    for ix in index:\n",
    "        slice_df = data.loc[ix]\n",
    "#         print(slice_df)\n",
    "        t_stats[ix] = {}\n",
    "        for key in slice_df.keys():\n",
    "            try:\n",
    "                t_stat = adfuller(slice_df[key], maxlag = 1, regression = 'c')[0]\n",
    "                t_stats[ix][key] = t_stat\n",
    "            except:\n",
    "                print(\"Error:\", key)\n",
    "    t_stats = pd.DataFrame(t_stats).T\n",
    "\n",
    "    return t_stats.mean()\n",
    "   \n",
    "ips_results = {}\n",
    "for key, val in df3.items():\n",
    "    ips_results[key] = ips_test(val.dropna())\n",
    "pd.DataFrame(ips_results).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04570094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb76a844",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 30})\n",
    "plt.rcParams['axes.xmargin'] = .001\n",
    "plt.rcParams['axes.ymargin'] = .005\n",
    "def full_corr_plot(data, color = \"C0\", pcorr = False):\n",
    "    if pcorr == True:\n",
    "        corr_df = data.pcorr()\n",
    "    elif pcorr == False:\n",
    "        corr_df = data.corr()\n",
    "    keys = list(corr_df.keys())\n",
    "    dim = len(keys)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (30, 30))\n",
    "    a = pd.plotting.scatter_matrix(data, c = color, \n",
    "                                   s = 200, alpha = .1, ax=ax)  \n",
    "    for i in range(len(keys)):\n",
    "        x = keys[i]\n",
    "        for j in range(len(keys)):\n",
    "            y = keys[j]\n",
    "            a[i][j].set_xticklabels([])\n",
    "            a[i][j].set_yticklabels([])\n",
    "            a[i][j].set_title(\"$\\\\rho :\" + str(corr_df.round(2)[x][y])+ \"$\", y = .88, x = 0.01, ha = \"left\")        \n",
    "    plt.suptitle(\"Correlation\\n(Color: y)\",y = .96, fontsize = 80)\n",
    "df4 = df3['Diff2'].dropna()\n",
    "df4.rename(columns = {key:key.replace(\" \", \"\\n\") for key in df4.keys()}, inplace = True)\n",
    "df4_keys = list(df4.keys())\n",
    "full_corr_plot(df4, color = df4[df4_keys[0]], pcorr = True)\n",
    "# y_var = ['Agriculture, forestry, fishing and hunting']\n",
    "# x_vars = ['Mining, quarrying, and oil and gas extraction', 'Utilities', 'Construction', 'Manufacturing']\n",
    "# corr_var = y_var + x_vars\n",
    "# corr_data = log_df[corr_var]\n",
    "# corr_data.corr().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46c537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# . . .\n",
    "def corr_matrix_heatmap(data, pp = False):  \n",
    "    #Create a figure to visualize a corr matrix  \n",
    "    fig, ax = plt.subplots(figsize=(20,20))  \n",
    "    # use ax.imshow() to create a heatmap of correlation values  \n",
    "    # seismic mapping shows negative values as blue and positive values as red  \n",
    "    im = ax.imshow(data, norm = plt.cm.colors.Normalize(-1,1), cmap = \"seismic\")  \n",
    "    # create a list of labels, stacking each word in a label by replacing \" \"  \n",
    "    # with \"\\n\"  \n",
    "    labels = data.keys()  \n",
    "    num_vars = len(labels)  \n",
    "    tick_labels = [lab.replace(\" \", \"\\n\") for lab in labels]  \n",
    "    # adjust font size according to the number of variables visualized  \n",
    "    tick_font_size = 120 / num_vars  \n",
    "    val_font_size = 200 / num_vars  \n",
    "    plt.rcParams.update({'font.size': tick_font_size}) \n",
    "    # prepare space for label of each column  \n",
    "    x_ticks = np.arange(num_vars)  \n",
    "    # select labels and rotate them 90 degrees so that they are vertical  \n",
    "    plt.xticks(x_ticks, tick_labels, fontsize = tick_font_size, rotation = 90)  \n",
    "    # prepare space for label of each row  \n",
    "    y_ticks = np.arange(len(labels))  \n",
    "    # select labels  \n",
    "    plt.yticks(y_ticks, tick_labels, fontsize = tick_font_size)  \n",
    "    # show values in each tile of the heatmap  \n",
    "    for i in range(len(labels)):  \n",
    "        for j in range(len(labels)):  \n",
    "            text = ax.text(i, j, str(round(data.values[i][j],2)),  \n",
    "                           fontsize= val_font_size, ha=\"center\",   \n",
    "                           va=\"center\", color = \"w\")  \n",
    "    #Create title with Times New Roman Font  \n",
    "    title_font = {\"fontname\":\"Times New Roman\"}  \n",
    "    plt.title(\"Correlation\", fontsize = 50, **title_font)  \n",
    "    #Call scale to show value of colors \n",
    "    cbar = fig.colorbar(im)\n",
    "    plt.show()\n",
    "    if pp != False:\n",
    "        pp.savefig(fig, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "#. . . \n",
    "# . . .\n",
    "corr_matrix_heatmap(df4.corr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ee034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.rename(columns = {key:key[:4].replace(\"\\n\", \"\") for key in df4.keys()}, inplace = True)\n",
    "list(df4.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab9a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70674514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import ArrowStyle\n",
    "import copy\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "undirected_graph = {key:[] for key in df4.keys()}\n",
    "for x in undirected_graph:\n",
    "    remaining_vars = [y for y in df4.keys() if y != x]\n",
    "    for y in remaining_vars:\n",
    "        undirected_graph[x].append(y)\n",
    "\n",
    "p_value = .01\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from pgmpy.estimators import PC\n",
    "c = PC(df4)\n",
    "max_cond_vars = len(df4.keys()) - 2\n",
    "\n",
    "model = c.estimate(return_type = 'pdag', variant= 'parallel', significance_level = p_value,\n",
    "                  max_cond_vars = max_cond_vars, ci_test = 'pearsonr')\n",
    "edges = model.edges\n",
    "\n",
    "pp = PdfPages(\"DAGOutputs1.pdf\")\n",
    "\n",
    "def graph_DAG(edges, df, title = \"\"):\n",
    "    graph = nx.Graph()\n",
    "    edge_labels = {}\n",
    "    for edge in edges:\n",
    "        controls = [key for key in df.keys() if key not in edge]\n",
    "        controls = list(set(controls))\n",
    "        keep_controls = []\n",
    "        for control in controls:\n",
    "            control_edges = [ctrl_edge for ctrl_edge in edges if control == ctrl_edge[0]]\n",
    "            if (control, edge[1]) in control_edges:\n",
    "                print('keep control:', control)\n",
    "                keep_controls.append(control)\n",
    "        print(edge, keep_controls)\n",
    "        pcorr = df[[edge[0], edge[1]]+keep_controls].pcorr()\n",
    "        edge_labels[edge] = str(round(pcorr[edge[0]].loc[edge[1]],2))\n",
    "    graph.add_edges_from(edges)\n",
    "    color_map = ['C0' for g in graph]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (20, 12))\n",
    "    graph.nodes()\n",
    "    plt.tight_layout()\n",
    "    pos = nx.spring_layout(graph)\n",
    "    \n",
    "    plt.title(title, fontsize = 30)\n",
    "    nx.draw_networkx(graph, pos, node_color=color_map, node_size=1200, with_labels=True,\n",
    "                    arrows=True, font_color ='k', font_size=26, alpha=1, width = 1,\n",
    "                    edge_color = 'C1',\n",
    "                     arrowstyle=ArrowStyle('Fancy, head_length=3, head_width=1.5, tail_width=.1'), ax = ax)\n",
    "    nx.draw_networkx_edge_labels(graph, pos, edge_labels=edge_labels, font_color='green', font_size=20)\n",
    "    pp.savefig(fig, bbox_inches = \"tight\")\n",
    "\n",
    "graph_DAG(edges, df4, title = 'Directed Acyclic Graph')\n",
    "\n",
    "\n",
    "pp.close()                                                            \n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d81f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = pd.concat([df1, df2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbb51ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_df.loc[year, year_data.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3166a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d3b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = map_data.join(year_data).dropna(subset = [\"All industry total\"])\n",
    "# find_neighbors(test_data)\n",
    "# # year_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58548743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, GeoFips in county_gdf.iterrows():\n",
    "#     neighbors = county_gdf[~county_gdf.geometry.disjoint(GeoFips.geometry)].county_name.tolist()\n",
    "#     neighbor = [name for name in neighbors if GeoFips.county_name != name]\n",
    "#     county_gdf.at[index, \"NEIGHBORS\"] = \", \".join(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e79bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# county_gdf.to_file(\"C:/Users/abiodun.idowu/OneDrive - North Dakota University System/Desktop/PhD/BEA project/notebook_to_start/newfile.shp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c39f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns 9 to 24 \n",
    "# gdf = gdf.drop(gdf.columns[9:24], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb949592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# county_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edd4f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_df1 = pd.merge(plot_df.reset_index(), county_gdf, left_on='GeoFips', right_on='GeoFips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413f3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_df1 = merge_df1.set_index('GeoFips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad7e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f301e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(26,16))\n",
    "# county_gdf.plot(column='NEIGHBORS', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c776613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(county_gdf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e421d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.merge(county_gdf.reset_index(), plot_df, left_on='GeoFips', right_on='GeoFips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5220e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = test_df.set_index('GeoFips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc82b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a2b870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e5427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create a column with the sum of neighboring gdps\n",
    "\n",
    "# for index, GeoFips in gdf.iterrows():\n",
    "#     neighbors = gdf[~gdf.geometry.disjoint(GeoFips.geometry)].county_name.tolist()\n",
    "#     neighbor = [name for name in neighbors if GeoFips.county_name != name]\n",
    "    \n",
    "#     neighboring_GDP = gdf[gdf.county_name.isin(neighbors)][\"All\"].sum()\n",
    "#     gdf.at[index, \"gdp_sum\"] = neighboring_GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1accacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a053bff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_df = full_df.reset_index()\n",
    "# full_df[\"FIPS\"] = full_df[\"GeoFips\"]\n",
    "# full_df = full_df.set_index([\"TimePeriod\",\"GeoFips\"])\n",
    "# full_df.dropna(subset = [\"All industry total\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b06339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f233b46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d958115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # neighbors = map_data.loc[21007,\"NEIGHBORS\"]\n",
    "\n",
    "# full_df[\"NeighborGDP\"] = np.NaN\n",
    "\n",
    "# for year in range(2004,2020):\n",
    "#     year_data = full_df.loc[year]\n",
    "#     year_data = map_data.join(year_data).dropna(subset = [\"All industry total\"])\n",
    "#     find_neighbors(year_data)    \n",
    "# #     year_data = year_data.join(map_data[\"NEIGHBORS\"])\n",
    "# #     year_data[\"NeighborGDP\"]\n",
    "# #     print( year_data[\"All industry total\"].loc[year_data.loc[1001][\"NEIGHBORS\"]].sum())\n",
    "# #     full_df.loc[year, \"All industry total\"] = year_data.apply(lambda row: year_data[\"All industry total\"].loc[row[\"NEIGHBORS\"]].sum() if row[\"NEIGHBORS\"] != np.nan else np.nan, \n",
    "# #                           axis = 1)\n",
    "#     full_df.loc[year, \"All industry total\"] = year_data.apply(lambda row: year_data[\"All industry total\"].loc[row[\"NEIGHBORS\"]].sum() if row[\"NEIGHBORS\"] != np.nan else np.nan, \n",
    "#                           axis = 1)\n",
    "# #     full_df.loc[year, \"NeighborGDP\"] = year_data.apply(lambda row: year_data[\"All industry total\"].loc[row[\"NEIGHBORS\"]].sum() if row[\"NEIGHBORS\"] != np.nan else np.nan, \n",
    "# #                           axis = 1)\n",
    "\n",
    "    \n",
    "#     #     gdf[\"NeighborGDP\"][gdf[\"TimePeriod\"] == year]] = year_data[year_data.county_name.isin(neighbors)][\"All\"].sum()\n",
    "\n",
    "# # for row in year_data.iterrows():\n",
    "# #     print(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd3c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_df[\"All industry total\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f24c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_df[\"NeighborGDP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a46754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_df.dropna(subset = [\"All industry total\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a90154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  map_data.loc[year_data.loc[1001][\"FIPS\"]][\"NEIGHBORS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06bd98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_data.loc[1001][\"NEIGHBORS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a46c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf[\"NeighborGDP\"] = np.NaN\n",
    "# for year in range(2004,2020):\n",
    "#     year_data = gdf[gdf[\"TimePeriod\"] == 2004]\n",
    "#     gdf[\"NeighborGDP\"][gdf[\"TimePeriod\"] == 2004] = year_data[year_data.county_name.isin(neighbors)][\"All\"].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de6b528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pygeos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb98ce4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990415c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summing the gdp for neighbor per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2a6f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33547238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a58e25f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5d7b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d9af1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1ced0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59c29ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d7047f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eff6762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54c1a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb92211f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9e4e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83e3c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37376da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d66c409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3385e445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10bdfe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e2675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe30627",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32c2ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = dfg.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbcba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c8581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg.to_csv('stat_713b.csv')\n",
    "# df_reg2.to_csv('stat_712.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e1b1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8d7ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44cdcf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0991cd5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e98f87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8d0227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985c2721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b729e283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d27d24a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1e1198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88a0f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61899908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e397f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
