{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de80f32",
   "metadata": {},
   "source": [
    "### Problem 1: Simple Linear Regression\n",
    "\n",
    "**Objective:** Analyze the relationship between Smoking status and Functional Effective Volume (FEV) using simple linear regression.\n",
    "\n",
    "**Given Data:** The data set `fev.txt` contains information on FEV and smoking status from an observational study.\n",
    "\n",
    "#### Part (a) Histogram of the Response Variable\n",
    "\n",
    "**Objective:** Determine if the data is appropriate for applying simple linear regression by inspecting the distribution of the response variable (FEV).\n",
    "\n",
    "**Formula:** Not applicable here.\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# Load data\n",
    "fev_data <- read.table('fev.txt', header=TRUE)\n",
    "\n",
    "# Plot histogram\n",
    "hist(fev_data$FEV, main=\"Histogram of FEV\", xlab=\"FEV\", ylab=\"Frequency\", col=\"lightblue\", border=\"black\")\n",
    "```\n",
    "\n",
    "**Interpretation:** \n",
    "- **Explanation:** The histogram will show the distribution of FEV. If the distribution appears approximately normal, this would support the application of simple linear regression.\n",
    "- **Conclusion:** If the histogram is approximately symmetric and bell-shaped, the data may be appropriate for simple linear regression. If there are severe skewness or outliers, this could indicate potential issues.\n",
    "\n",
    "#### Part (b) Boxplot of FEV by Smoking Status\n",
    "\n",
    "**Objective:** Assess whether Smoking status affects FEV using a boxplot.\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# Boxplot of FEV by Smoking status\n",
    "boxplot(FEV ~ Smoke, data=fev_data, main=\"FEV by Smoking Status\",\n",
    "        xlab=\"Smoking Status\", ylab=\"FEV\", col=c(\"lightblue\", \"lightgreen\"))\n",
    "```\n",
    "\n",
    "**Interpretation:** \n",
    "- **Explanation:** The boxplot will compare the distributions of FEV between smokers and non-smokers. If there is a clear difference between the medians and the spread, it might suggest a relationship.\n",
    "- **Conclusion:** If smokers and non-smokers show a significant difference in FEV, it would suggest that smoking status could be a predictor of FEV.\n",
    "\n",
    "#### Part (c) Fit a Linear Regression Model\n",
    "\n",
    "**Objective:** Determine if smoking is significantly associated with FEV.\n",
    "\n",
    "**Formula:** \n",
    "$\n",
    "\\text{FEV} = \\beta_0 + \\beta_1 \\times \\text{Smoke} + \\epsilon\n",
    "$\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# Fit linear regression model\n",
    "model <- lm(FEV ~ Smoke, data=fev_data)\n",
    "\n",
    "# Display summary\n",
    "summary(model)\n",
    "```\n",
    "\n",
    "**Table of Results:**\n",
    "\n",
    "| Coefficient | Estimate | Std. Error | p-value |\n",
    "|-------------|----------|------------|---------|\n",
    "| Intercept   | $\\beta_0$ |  Estimate |  Std. Error  | p-value |\n",
    "| Smoke       | $\\beta_1$ |  Estimate |  Std. Error  | p-value |\n",
    "\n",
    "**Interpretation:** \n",
    "- **Explanation:** The significance of the smoking coefficient $(\\beta_1)$ will determine if there is a statistically significant association between smoking and FEV.\n",
    "\n",
    "#### Part (d) 95% Confidence Interval for the Effect of Smoking\n",
    "\n",
    "**Objective:** Calculate the 95% confidence interval for the effect of smoking on FEV.\n",
    "\n",
    "**Formula:** \n",
    "$\n",
    "\\text{CI} = \\hat{\\beta_1} \\pm t_{\\alpha/2, n-2} \\times SE(\\hat{\\beta_1})\n",
    "$\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# Confidence Interval for Smoking effect\n",
    "confint(model, \"Smoke\", level = 0.95)\n",
    "```\n",
    "\n",
    "**Interpretation:**\n",
    "- **Conclusion:** The interval provides a range of plausible values for the effect of smoking on FEV. If the interval does not include 0, it suggests a significant effect.\n",
    "\n",
    "#### Part (e) Practical Interpretation of the Confidence Interval\n",
    "\n",
    "**Objective:** Provide a practical interpretation of the confidence interval found in Part (d).\n",
    "\n",
    "**Interpretation:** \n",
    "- **Explanation:** The confidence interval represents the range of values within which the true effect of smoking on FEV is likely to fall. For example, if the interval is entirely negative, it suggests that smoking reduces FEV.\n",
    "\n",
    "#### Part (f) 95% Confidence Intervals for Average FEV by Smoking Group\n",
    "\n",
    "**Objective:** Calculate 95% confidence intervals for the average FEV for smokers and non-smokers.\n",
    "\n",
    "**Formula:** \n",
    "$\n",
    "\\text{CI} = \\hat{\\mu} \\pm t_{\\alpha/2, n-2} \\times SE(\\hat{\\mu})\n",
    "$\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# Confidence intervals for the means\n",
    "new_data <- data.frame(Smoke = c(0, 1)) # 0 for non-smokers, 1 for smokers\n",
    "predict(model, newdata = new_data, interval = \"confidence\", level = 0.95)\n",
    "```\n",
    "\n",
    "**Interpretation:** \n",
    "- **Explanation:** These intervals give the range within which the average FEV for each group (smokers and non-smokers) is likely to fall.\n",
    "\n",
    "#### Part (g) Residuals by Fitted Scatterplot\n",
    "\n",
    "**Objective:** Evaluate the assumptions of linear regression using a residuals vs fitted values plot.\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# Residuals by Fitted Values plot\n",
    "plot(model$fitted.values, model$residuals, \n",
    "     main=\"Residuals vs Fitted\", \n",
    "     xlab=\"Fitted Values\", ylab=\"Residuals\", \n",
    "     col=\"blue\")\n",
    "abline(h=0, lty=2)\n",
    "```\n",
    "\n",
    "**Interpretation:** \n",
    "- **Explanation:** Ideally, residuals should be randomly scattered around zero. Patterns or trends might indicate a violation of assumptions like homoscedasticity or linearity.\n",
    "\n",
    "#### Part (h) QQ-Plot of the Standardized Residuals\n",
    "\n",
    "**Objective:** Evaluate the normality assumption using a QQ-plot of the residuals.\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# QQ-plot of standardized residuals\n",
    "qqnorm(model$residuals, main=\"QQ-plot of Residuals\")\n",
    "qqline(model$residuals)\n",
    "```\n",
    "\n",
    "**Interpretation:** \n",
    "- **Explanation:** If the residuals follow a straight line in the QQ-plot, the normality assumption is reasonable. Deviations could indicate issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35509b2",
   "metadata": {},
   "source": [
    "### Problem 2: Multiple Linear Regression\n",
    "\n",
    "**Objective:** Analyze the effect of smoking on FEV while adjusting for height using multiple linear regression.\n",
    "\n",
    "**Given Data:** The data set `fev.txt` contains information on FEV, smoking status, and height.\n",
    "\n",
    "#### Part (a) Scatterplot of Height vs. FEV\n",
    "\n",
    "**Objective:** Visualize the relationship between height and FEV.\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# Scatterplot of Height vs FEV\n",
    "plot(fev_data$Height, fev_data$FEV, \n",
    "     main=\"Scatterplot of Height vs FEV\", \n",
    "     xlab=\"Height (inches)\", ylab=\"FEV\", \n",
    "     col=\"blue\", pch=19)\n",
    "```\n",
    "\n",
    "**Interpretation:** \n",
    "- **Explanation:** The scatterplot will show whether there is a linear relationship between height and FEV. A positive relationship would suggest that taller individuals tend to have higher FEV.\n",
    "\n",
    "#### Part (b) Simple Linear Regression of FEV on Height\n",
    "\n",
    "**Objective:** Determine the effect of height on FEV using simple linear regression.\n",
    "\n",
    "**Formula:** \n",
    "$\n",
    "\\text{FEV} = \\beta_0 + \\beta_1 \\times \\text{Height} + \\epsilon\n",
    "$\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# Fit linear regression model with Height as predictor\n",
    "height_model <- lm(FEV ~ Height, data=fev_data)\n",
    "\n",
    "# Display summary\n",
    "summary(height_model)\n",
    "```\n",
    "\n",
    "**Table of Results:**\n",
    "\n",
    "| Coefficient | Estimate | Std. Error | p-value |\n",
    "|-------------|----------|------------|---------|\n",
    "| Intercept   | $\\beta_0$ |  Estimate |  Std. Error  | p-value |\n",
    "| Height      | $\\beta_1$ |  Estimate |  Std. Error  | p-value |\n",
    "\n",
    "**Interpretation:** \n",
    "- **Explanation:** The significance of the height coefficient $(\\beta_1)$ will show whether height is a significant predictor of FEV.\n",
    "\n",
    "#### Part (c) Assess Linear Regression Assumptions\n",
    "\n",
    "**Objective:** Evaluate whether the data satisfy the four assumptions of linear regression.\n",
    "\n",
    "**Assumptions:**\n",
    "1. **Linearity:** The relationship between predictors and response is linear.\n",
    "2. **Independence:** Observations are independent of each other.\n",
    "3. **Homoscedasticity:** Constant variance of residuals.\n",
    "4. **Normality:** Residuals are normally distributed.\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# Residuals vs Fitted Values plot\n",
    "plot(height_model$fitted.values, height_model$residuals, \n",
    "     main=\"Residuals vs Fitted\", \n",
    "     xlab=\"Fitted Values\", ylab=\"Residuals\", \n",
    "     col=\"blue\")\n",
    "abline(h=0, lty=2)\n",
    "\n",
    "# QQ-plot of standardized residuals\n",
    "qqnorm(height_model$residuals, main=\"QQ-plot of Residuals\")\n",
    "qqline(height_model$residuals)\n",
    "```\n",
    "\n",
    "**Interpretation:** \n",
    "- **Linearity:** Check the scatterplot of residuals vs fitted values for patterns.\n",
    "- **Independence:** Assumed based on study design (not directly assessable from the plots).\n",
    "- **Homoscedasticity:** Look for constant spread in residuals vs fitted values.\n",
    "- **Normality:** Assess with QQ-plot; a straight line suggests normality.\n",
    "\n",
    "#### Part (d) Boxplot of Height by Smoking Status\n",
    "\n",
    "**Objective:** Assess any relationship between height and smoking status.\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# Boxplot of Height by Smoking status\n",
    "boxplot(Height ~ Smoke, data=fev_data, main=\"Height by Smoking Status\",\n",
    "        xlab=\"Smoking Status\", ylab=\"Height (inches)\", col=c(\"lightblue\", \"lightgreen\"))\n",
    "```\n",
    "\n",
    "**Interpretation:** \n",
    "- **Explanation:** This plot will show if there is a significant difference in height between smokers and non-smokers, which might affect the regression analysis.\n",
    "\n",
    "#### Part (e) Multiple Linear Regression of FEV on Smoking and Height\n",
    "\n",
    "**Objective:** Estimate the effect of smoking on FEV while adjusting for height.\n",
    "\n",
    "**Formula:**\n",
    "$\n",
    "\\text{FEV} = \\beta_0 + \\beta_1 \\times \\text{Smoke} + \\beta_2 \\times \\text{Height} + \\epsilon\n",
    "$\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# Fit multiple linear regression model\n",
    "full_model <- lm(FEV ~ Smoke + Height, data=fev_data)\n",
    "\n",
    "# Display summary\n",
    "summary(full_model)\n",
    "```\n",
    "\n",
    "**Table of Results:**\n",
    "\n",
    "| Coefficient | Estimate | Std. Error | p-value |\n",
    "|-------------|----------|------------|---------|\n",
    "| Intercept   | $\\beta_0$ |  Estimate |  Std. Error  | p-value |\n",
    "| Smoke       | $\\beta_1$ |  Estimate |  Std. Error  | p-value |\n",
    "| Height      | $\\beta_2$ |  Estimate |  Std. Error  | p-value |\n",
    "\n",
    "**Interpretation:** \n",
    "- **Explanation:** The coefficients for smoking and height show the effect of each on FEV, adjusting for the other variable.\n",
    "\n",
    "#### Part (f) 95% Confidence Interval for Smoking Adjusted for Height\n",
    "\n",
    "**Objective:** Calculate the 95% confidence interval for the effect of smoking on FEV after adjusting for height.\n",
    "\n",
    "**Formula:** \n",
    "$\n",
    "\\text{CI} = \\hat{\\beta_1} \\pm t_{\\alpha/2, n-3} \\times SE(\\hat{\\beta_1})\n",
    "$\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# Confidence Interval for Smoking effect adjusted for Height\n",
    "confint(full_model, \"Smoke\", level = 0.95)\n",
    "```\n",
    "\n",
    "**Interpretation:**\n",
    "- **Conclusion:** This interval provides a range of values for the effect of smoking on FEV after accounting for height.\n",
    "\n",
    "#### Part (g) Interpretation of Confidence Interval and Comparison\n",
    "\n",
    "**Objective:** Interpret the confidence interval in the context of the study and compare it with the result from Problem 1.\n",
    "\n",
    "**Interpretation:** \n",
    "- **Explanation:** The confidence interval shows the adjusted effect of smoking on FEV. Comparing this with the unadjusted result from Problem 1 can indicate whether height is a confounder.\n",
    "\n",
    "#### Part (h) 95% CI for Difference in FEV for Smokers 1 Inch Taller\n",
    "\n",
    "**Objective:** Calculate the 95% confidence interval for the difference in FEV when comparing smokers who are 1 inch taller than non-smokers.\n",
    "\n",
    "**Formula:** \n",
    "$\n",
    "\\Delta FEV = (\\beta_1 + \\beta_2 \\times 1)\n",
    "$\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# Confidence interval for difference in FEV for smokers 1 inch taller\n",
    "new_data <- data.frame(Smoke = 1, Height = fev_data$Height + 1)\n",
    "predict(full_model, newdata = new_data, interval = \"confidence\", level = 0.95)\n",
    "```\n",
    "\n",
    "**Interpretation:** \n",
    "- **Explanation:** This calculation shows how much FEV differs between smokers and non-smokers when the smoker is 1 inch taller, providing insight into how height influences the smoking effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dbccea",
   "metadata": {},
   "source": [
    "### Problem 3: Simple Linear Regression Model Analysis\n",
    "\n",
    "**Objective:** Explore properties of the simple linear regression model, focusing on unbiasedness, variance, and distribution of estimators.\n",
    "\n",
    "#### Part (a) Show that $\\hat{Y}_h$ is Unbiased for $E[Y | X = X_h]$\n",
    "\n",
    "**Objective:** Prove that the estimated value $(\\hat{Y}_h)$ is an unbiased estimator of the true mean response $(E[Y | X = X_h])$.\n",
    "\n",
    "**Given Data:** \n",
    "- The simple linear regression model is Y = $\\beta_0 + \\beta_1 X + \\epsilon\\$, where $\\epsilon$ is normally distributed with mean 0 and variance $\\sigma^2$.\n",
    "\n",
    "**Proof:**\n",
    "1. The estimator for Y at (X = $X_h$) is:\n",
    "   $\n",
    "   \\hat{Y}_h = \\hat{\\beta_0} + \\hat{\\beta_1} X_h\n",
    "   $\n",
    "   \n",
    "2. The expectation of $\\hat{Y}_h$ is:\n",
    "   $\n",
    "   E[\\hat{Y}_h] = E[\\hat{\\beta_0} + \\hat{\\beta_1} X_h] = E[\\hat{\\beta_0}] + E[\\hat{\\beta_1}] X_h\n",
    "   $\n",
    "   \n",
    "3. From linear regression theory, $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$ are unbiased estimators of $\\beta_0$ and $\\beta_1$:\n",
    "   $\n",
    "   E[\\hat{\\beta_0}] = \\beta_0, \\quad E[\\hat{\\beta_1}] = \\beta_1\n",
    "   $\n",
    "   \n",
    "4. Therefore:\n",
    "   $\n",
    "   E[\\hat{Y}_h] = \\beta_0 + \\beta_1 X_h = E[Y | X = X_h]\n",
    "   $\n",
    "   \n",
    "   $\n",
    "   \\therefore \\hat{Y}_h \\text{ is an unbiased estimator of } E[Y | X = X_h]\n",
    "   $\n",
    "\n",
    "#### Part (b) Formulas for the Variance of $\\hat{\\beta_1}$, $\\hat{\\beta_0}$, and $\\hat{Y}_h$\n",
    "\n",
    "**Objective:** Derive the formulas for the variances of $\\hat{\\beta_1}$, $\\hat{\\beta_0}$, and $\\hat{Y}_h$.\n",
    "\n",
    "**Given Data:** The formulas are derived under the assumption that the errors are normally distributed with zero mean and variance $\\sigma^2$.\n",
    "\n",
    "**Formulas:**\n",
    "\n",
    "1. **Variance of $\\hat{\\beta_1}$:**\n",
    "   $\n",
    "   \\text{Var}(\\hat{\\beta_1}) = \\frac{\\sigma^2}{\\sum (X_i - \\bar{X})^2}\n",
    "   $\n",
    "\n",
    "2. **Variance of $\\hat{\\beta_0}$:**\n",
    "   $\n",
    "   \\text{Var}(\\hat{\\beta_0}) = \\sigma^2 \\left( \\frac{1}{n} + \\frac{\\bar{X}^2}{\\sum (X_i - \\bar{X})^2} \\right)\n",
    "   $\n",
    "\n",
    "3. **Variance of $\\hat{Y}_h$:**\n",
    "   $\n",
    "   \\text{Var}(\\hat{Y}_h) = \\sigma^2 \\left( \\frac{1}{n} + \\frac{(X_h - \\bar{X})^2}{\\sum (X_i - \\bar{X})^2} \\right)\n",
    "   $\n",
    "\n",
    "**Calculation:** The actual calculation would depend on specific data. The above formulas allow for direct computation of the variances given the sum of squares of $X_i - \\bar{X}$ and the variance $\\sigma^2$.\n",
    "\n",
    "#### Part (c) Distribution of $\\hat{Y}_h$\n",
    "\n",
    "**Objective:** Determine the distribution of $\\hat{Y}_h$.\n",
    "\n",
    "**Given Data:**\n",
    "- Since $\\hat{Y}_h$ is a linear combination of normally distributed variables, $\\hat{Y}_h$ itself is normally distributed.\n",
    "\n",
    "**Distribution:**\n",
    "$\n",
    "\\hat{Y}_h \\sim N\\left(E[\\hat{Y}_h], \\text{Var}(\\hat{Y}_h)\\right)\n",
    "$\n",
    "\n",
    "Substituting the unbiased estimate and the variance derived earlier:\n",
    "$\n",
    "\\hat{Y}_h \\sim N\\left(\\beta_0 + \\beta_1 X_h, \\sigma^2 \\left( \\frac{1}{n} + \\frac{(X_h - \\bar{X})^2}{\\sum (X_i - \\bar{X})^2} \\right)\\right)\n",
    "$\n",
    "\n",
    "#### Part (d) Uncertainty as the Difference between $X_h$ and $\\bar{X}$ Increases\n",
    "\n",
    "**Objective:** Discuss how the uncertainty of $\\hat{Y}_h$ changes as $X_h$ deviates from $\\bar{X}$.\n",
    "\n",
    "**Interpretation:** \n",
    "- The term $\\frac{(X_h - \\bar{X})^2}{\\sum (X_i - \\bar{X})^2}$ increases as $X_h$ moves further from $\\bar{X}$, leading to an increase in the variance of $\\hat{Y}_h$.\n",
    "- **Conclusion:** The further $X_h$ is from the mean $\\bar{X}$, the greater the uncertainty (variance) of the prediction $\\hat{Y}_h$.\n",
    "\n",
    "#### Part (e) Distribution of $\\hat{Y}_h$ when Y is estimated by $\\hat{Y}_h$\n",
    "\n",
    "**Objective:** Derive the distribution for $\\hat{Y}_h - E[Y | X = X_h]$.\n",
    "\n",
    "**Given Data:** \n",
    "- Recall that $\\hat{Y}_h$ is unbiased, so:\n",
    "$\n",
    "\\hat{Y}_h - E[Y | X = X_h] \\sim N\\left(0, \\text{Var}(\\hat{Y}_h)\\right)\n",
    "$\n",
    "\n",
    "**Distribution:**\n",
    "$\n",
    "\\hat{Y}_h - E[Y | X = X_h] \\sim N\\left(0, \\sigma^2 \\left( \\frac{1}{n} + \\frac{(X_h - \\bar{X})^2}{\\sum (X_i - \\bar{X})^2} \\right)\\right)\n",
    "$\n",
    "\n",
    "#### Part (f) Prediction Interval for $Y_{\\text{new}}$\n",
    "\n",
    "**Objective:** Calculate the prediction interval for a new observation $Y_{\\text{new}}$ at covariate value $X_{\\text{new}}$.\n",
    "\n",
    "**Formula:** \n",
    "$\n",
    "\\text{Prediction Interval} = \\hat{Y}_{\\text{new}} \\pm t_{\\alpha/2, n-2} \\times \\sqrt{\\text{Var}(\\hat{Y}_{\\text{new}}) + \\sigma^2}\n",
    "$\n",
    "\n",
    "**Interpretation:** \n",
    "- This interval accounts for both the variance of the prediction $\\hat{Y}_{\\text{new}}$ and the inherent variability in the new observation.\n",
    "\n",
    "#### Part (g) Difference between Prediction Interval and Confidence Interval\n",
    "\n",
    "**Objective:** Explain why the prediction interval for $Y_{\\text{new}}$ is different from the confidence interval for $\\hat{Y}_h$.\n",
    "\n",
    "**Interpretation:**\n",
    "- **Explanation:** The confidence interval for $\\hat{Y}_h$ only accounts for the uncertainty in estimating the mean response at $X_h$. In contrast, the prediction interval for $Y_{\\text{new}}$ also includes the additional uncertainty due to the variability of individual observations around the mean response.\n",
    "- **Conclusion:** The prediction interval is wider because it incorporates more sources of uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3672130",
   "metadata": {},
   "source": [
    "### Problem 4: Simulating and Analyzing Data from an Exponential Model\n",
    "\n",
    "**Objective:** Generate data from an exponential model, fit a linear regression model, and analyze the assumptions of the regression model.\n",
    "\n",
    "#### Part (a) Simulate Data and Scatterplot of Y vs. X\n",
    "\n",
    "**Objective:** Use R to simulate data from an exponential model and create a scatterplot.\n",
    "\n",
    "**Given Data:**\n",
    "- The model is Y $\\sim \\text{Exp}(\\mu)$ where $\\mu = 0.05 / X.\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "set.seed(123)\n",
    "\n",
    "n <- 500\n",
    "X <- rnorm(n, 3, 1)\n",
    "Y <- rexp(n, rate = 0.05 / X)\n",
    "\n",
    "# Scatterplot of Y vs X\n",
    "plot(X, Y, main=\"Scatterplot of Y vs X\", xlab=\"X\", ylab=\"Y\", pch=19, col=\"blue\")\n",
    "```\n",
    "\n",
    "**Interpretation:**\n",
    "- **Explanation:** The scatterplot will show the relationship between Y and X. Given that Y is exponentially distributed, we expect to see a non-linear relationship with X.\n",
    "\n",
    "#### Part (b) Fit a Linear Regression Model and Assess Assumptions\n",
    "\n",
    "**Objective:** Fit the model Y = $\\beta_0 + \\beta_1 X + \\epsilon$ and assess the linear regression assumptions using residual plots.\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# Fit linear regression model\n",
    "model <- lm(Y ~ X)\n",
    "\n",
    "# Scatterplot with best fit line\n",
    "plot(X, Y, main=\"Scatterplot of Y vs X with Regression Line\", xlab=\"X\", ylab=\"Y\", pch=19, col=\"blue\")\n",
    "abline(model, col=\"red\", lwd=2)\n",
    "\n",
    "# Residuals vs Fitted Values plot\n",
    "plot(model$fitted.values, model$residuals, \n",
    "     main=\"Residuals vs Fitted\", \n",
    "     xlab=\"Fitted Values\", ylab=\"Residuals\", \n",
    "     col=\"blue\")\n",
    "abline(h=0, lty=2)\n",
    "```\n",
    "\n",
    "**Interpretation:**\n",
    "- **Explanation:** \n",
    "  - **Scatterplot:** The red line represents the fitted linear model. The model might not fit well due to the exponential relationship.\n",
    "  - **Residuals vs Fitted:** If there is a pattern in this plot (e.g., funnel shape), it suggests heteroscedasticity, violating one of the linear regression assumptions.\n",
    "\n",
    "**Conclusion:** The linear regression assumptions, particularly linearity and homoscedasticity, might be violated because of the non-linear relationship between Y and X.\n",
    "\n",
    "#### Part (c) Derive the Variance Stabilizing Transformation for Y\n",
    "\n",
    "**Objective:** Derive the transformation that stabilizes the variance for an exponential distribution.\n",
    "\n",
    "**Derivation:**\n",
    "1. **Given:** Y $\\sim \\text{Exp}(\\mu)$ with $\\mu$ = 0.05 / X.\n",
    "2. **Variance Stabilizing Transformation:** For an exponential distribution, the standard variance stabilizing transformation is the square root transformation:\n",
    "   $\n",
    "   Z = \\sqrt{Y}\n",
    "   $\n",
    "   \n",
    "   This transformation aims to stabilize the variance, making it more appropriate for linear regression.\n",
    "\n",
    "#### Part (d) Apply the Transformation and Refit the Model\n",
    "\n",
    "**Objective:** Apply the variance stabilizing transformation to the data and refit the linear regression model.\n",
    "\n",
    "**R Code:**\n",
    "```r\n",
    "# Apply variance stabilizing transformation\n",
    "Z <- sqrt(Y)\n",
    "\n",
    "# Fit linear regression model on transformed data\n",
    "transformed_model <- lm(Z ~ X)\n",
    "\n",
    "# Scatterplot of transformed data with best fit line\n",
    "plot(X, Z, main=\"Scatterplot of Transformed Z vs X with Regression Line\", \n",
    "     xlab=\"X\", ylab=\"Transformed Z\", pch=19, col=\"blue\")\n",
    "abline(transformed_model, col=\"red\", lwd=2)\n",
    "\n",
    "# Residuals vs Fitted Values plot for transformed model\n",
    "plot(transformed_model$fitted.values, transformed_model$residuals, \n",
    "     main=\"Residuals vs Fitted for Transformed Model\", \n",
    "     xlab=\"Fitted Values\", ylab=\"Residuals\", \n",
    "     col=\"blue\")\n",
    "abline(h=0, lty=2)\n",
    "```\n",
    "\n",
    "**Interpretation:**\n",
    "- **Explanation:** \n",
    "  - **Scatterplot with Transformation:** The scatterplot and fitted line should now better capture the relationship between the transformed response variable (Z) and the predictor (X).\n",
    "  - **Residuals vs Fitted for Transformed Model:** The residuals should now appear more random and homoscedastic, indicating that the variance stabilizing transformation was effective.\n",
    "\n",
    "**Conclusion:** The transformation should improve the linearity and homoscedasticity, making the assumptions of linear regression more reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7395e5b3",
   "metadata": {},
   "source": [
    "### Problem 5: Multiple Linear Regression Model Analysis\n",
    "\n",
    "**Objective:** Explore the interpretation, matrix form, likelihood, and distributional properties of the multiple linear regression model.\n",
    "\n",
    "#### Part (a) Interpretation of $\\beta_1$\n",
    "\n",
    "**Objective:** Interpret the coefficient $(\\beta_1)$ in the context of a multiple linear regression model.\n",
    "\n",
    "**Given Data:**\n",
    "- The multiple linear regression model is given by:\n",
    "  $\n",
    "  Y_i = \\beta_0 + \\beta_1 X_{i1} + \\beta_2 X_{i2} + \\dots + \\beta_{p-1} X_{i,p-1} + \\epsilon_i\n",
    "  $\n",
    "  \n",
    "  where $\\epsilon_i \\sim N(0, \\sigma^2)$.\n",
    "\n",
    "**Interpretation:**\n",
    "- **Explanation:** \n",
    "  - The coefficient $\\beta_1$ represents the expected change in the response variable Y for a one-unit increase in the predictor $(X_{i1})$, holding all other predictors $((X_{i2}, \\dots, X_{i,p-1}))$ constant.\n",
    "  - **Conclusion:** It measures the partial effect of $X_{i1}$ on Y, controlling for the other variables.\n",
    "\n",
    "#### Part (b) Matrix Form of the Model\n",
    "\n",
    "**Objective:** Write the multiple linear regression model in matrix form, labeling the response vector, design matrix, coefficient vector, and error vector.\n",
    "\n",
    "**Matrix Form:**\n",
    "$\n",
    "\\mathbf{Y} = \\mathbf{X} \\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n",
    "$\n",
    "\n",
    "**Labels and Dimensions:**\n",
    "\n",
    "1. **Response Vector $\\mathbf{Y}$:**\n",
    "   $\n",
    "   \\mathbf{Y} = \\begin{pmatrix} Y_1 \\\\ Y_2 \\\\ \\vdots \\\\ Y_n \\end{pmatrix}, \\quad n \\times 1\n",
    "   $\n",
    "\n",
    "2. **Design Matrix $\\mathbf{X}$:**\n",
    "   $\n",
    "   \\mathbf{X} = \\begin{pmatrix} 1 & X_{11} & X_{12} & \\dots & X_{1,p-1} \\\\ 1 & X_{21} & X_{22} & \\dots & X_{2,p-1} \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & X_{n1} & X_{n2} & \\dots & X_{n,p-1} \\end{pmatrix}, \\quad n \\times p\n",
    "   $\n",
    "\n",
    "3. **Coefficient Vector $\\boldsymbol{\\beta}$:**\n",
    "   $\n",
    "   \\boldsymbol{\\beta} = \\begin{pmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\vdots \\\\ \\beta_{p-1} \\end{pmatrix}, \\quad p \\times 1\n",
    "   $\n",
    "\n",
    "4. **Error Vector $\\boldsymbol{\\epsilon}$:**\n",
    "   $\n",
    "   \\boldsymbol{\\epsilon} = \\begin{pmatrix} \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{pmatrix}, \\quad n \\times 1\n",
    "   $\n",
    "\n",
    "**Interpretation:**\n",
    "- The matrix form allows for compact representation and facilitates operations like estimation using linear algebra techniques.\n",
    "\n",
    "#### Part (c) Likelihood and Log-Likelihood of $\\boldsymbol{\\theta} = (\\boldsymbol{\\beta}, \\sigma^2)$\n",
    "\n",
    "**Objective:** Write the likelihood and log-likelihood functions for the parameters $\\boldsymbol{\\theta} = (\\boldsymbol{\\beta}, \\sigma^2)$ in the multiple linear regression model.\n",
    "\n",
    "**Likelihood Function:**\n",
    "- **Given Data:** The errors $\\epsilon_i$ are normally distributed, so the response vector ($\\mathbf{Y}$) is multivariate normal:\n",
    "  $\n",
    "  \\mathbf{Y} \\sim N(\\mathbf{X} \\boldsymbol{\\beta}, \\sigma^2 \\mathbf{I})\n",
    "  $\n",
    "  \n",
    "  The likelihood function is:\n",
    "  $\n",
    "  L(\\boldsymbol{\\theta}) = (2\\pi\\sigma^2)^{-\\frac{n}{2}} \\exp\\left(-\\frac{1}{2\\sigma^2} (\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})^\\top (\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta}) \\right)\n",
    "  $\n",
    "\n",
    "**Log-Likelihood Function:**\n",
    "- Taking the natural logarithm of the likelihood function:\n",
    "  $\n",
    "  \\ell(\\boldsymbol{\\theta}) = -\\frac{n}{2} \\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} (\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})^\\top (\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})\n",
    "  $\n",
    "\n",
    "#### Part (d) Partial Derivative of the Log-Likelihood with Respect to $\\boldsymbol{\\beta}$\n",
    "\n",
    "**Objective:** Find the partial derivative of the log-likelihood function with respect to the coefficient vector $\\boldsymbol{\\beta}$.\n",
    "\n",
    "**Calculation:**\n",
    "- The log-likelihood function is:\n",
    "  $\n",
    "  \\ell(\\boldsymbol{\\theta}) = -\\frac{n}{2} \\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} (\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})^\\top (\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})\n",
    "  $\n",
    "  \n",
    "- Taking the derivative with respect to $\\boldsymbol{\\beta}$:\n",
    "  $\n",
    "  \\frac{\\partial \\ell(\\boldsymbol{\\theta})}{\\partial \\boldsymbol{\\beta}} = \\frac{1}{\\sigma^2} \\mathbf{X}^\\top (\\mathbf{Y} - \\mathbf{X} \\boldsymbol{\\beta})\n",
    "  $\n",
    "\n",
    "#### Part (e) Solve for $\\hat{\\boldsymbol{\\beta}}$, the MLE of the Coefficient Vector\n",
    "\n",
    "**Objective:** Solve for the maximum likelihood estimate (MLE) of $\\boldsymbol{\\beta}$.\n",
    "\n",
    "**Solution:**\n",
    "- Setting the derivative from Part (d) equal to zero to find the MLE:\n",
    "  $\n",
    "  \\mathbf{X}^\\top (\\mathbf{Y} - \\mathbf{X} \\hat{\\boldsymbol{\\beta}}) = 0\n",
    "  $\n",
    "  \n",
    "  Solving for $\\hat{\\boldsymbol{\\beta}}$:\n",
    "  $\n",
    "  \\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{Y}\n",
    "  $\n",
    "  \n",
    "- This is the ordinary least squares (OLS) estimator for the coefficient vector in multiple linear regression.\n",
    "\n",
    "#### Part (f) Calculate $\\text{Var}(\\hat{\\boldsymbol{\\beta}})$\n",
    "\n",
    "**Objective:** Derive the variance-covariance matrix of the MLE $\\hat{\\boldsymbol{\\beta}}$.\n",
    "\n",
    "**Formula:**\n",
    "- The variance-covariance matrix of $\\hat{\\boldsymbol{\\beta}}$ is given by:\n",
    "  $\n",
    "  \\text{Var}(\\hat{\\boldsymbol{\\beta}}) = \\sigma^2 (\\mathbf{X}^\\top \\mathbf{X})^{-1}\n",
    "  $\n",
    "\n",
    "#### Part (g) Distribution of $\\hat{\\boldsymbol{\\beta}}$\n",
    "\n",
    "**Objective:** Determine the distribution of the MLE $\\hat{\\boldsymbol{\\beta}}$.\n",
    "\n",
    "**Distribution:**\n",
    "- Given that $\\mathbf{Y} \\sim N(\\mathbf{X} \\boldsymbol{\\beta}, \\sigma^2 \\mathbf{I})$, the MLE $\\hat{\\boldsymbol{\\beta}}$ follows a multivariate normal distribution:\n",
    "  $\n",
    "  \\hat{\\boldsymbol{\\beta}} \\sim N\\left(\\boldsymbol{\\beta}, \\sigma^2 (\\mathbf{X}^\\top \\mathbf{X})^{-1}\\right)\n",
    "  $\n",
    "\n",
    "#### Part (h) Distribution of $\\hat{Y}_h$ at a New Covariate Value $X_h$\n",
    "\n",
    "**Objective:** Derive the distribution of the predicted response $(\\hat{Y}_h)$ at a new covariate value ($X_h$).\n",
    "\n",
    "**Distribution:**\n",
    "- The predicted response at a new covariate value ($X_h$) is:\n",
    "  $\n",
    "  \\hat{Y}_h = \\mathbf{X}_h^\\top \\hat{\\boldsymbol{\\beta}}\n",
    "  $\n",
    "  \n",
    "  Given the distribution of $\\hat{\\boldsymbol{\\beta}}$, the distribution of $\\hat{Y}_h$ is:\n",
    "  $\n",
    "  \\hat{Y}_h \\sim N\\left(\\mathbf{X}_h^\\top \\boldsymbol{\\beta}, \\sigma^2 \\mathbf{X}_h^\\top (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}_h\\right)\n",
    "  $\n",
    "  \n",
    "**Conclusion:** This part covers the distribution and variance of the prediction at a new covariate value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
