{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a77c696b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting abiFunctions.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile abiFunctions.py\n",
    "\n",
    "import os\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import ArrowStyle\n",
    "import copy\n",
    "from pgmpy.estimators import PC\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2\n",
    "import numpy as np\n",
    "from linearmodels.panel import PanelOLS\n",
    "from itertools import combinations\n",
    "import pingouin as pg\n",
    "import statsmodels.api as sm\n",
    "import geopandas\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from linearmodels.panel import PooledOLS    \n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "# Function to calculate AIC\n",
    "def calculate_aic(n, rss, k):\n",
    "    return n * np.log(rss / n) + 2 * k\n",
    "\n",
    "# Function to calculate BIC\n",
    "def calculate_bic(n, rss, k):\n",
    "    return n * np.log(rss / n) + k * np.log(n)\n",
    "\n",
    "# Function to calculate HQIC\n",
    "def calculate_hqic(n, rss, k):\n",
    "    return n * np.log(rss / n) + 2 * k * np.log(np.log(n))\n",
    "\n",
    "# Function for forward stepwise selection\n",
    "def forward_stepwise_selection(df, dependent_var, fixed_predictors, potential_predictors):\n",
    "    initial_formula = f'{dependent_var} ~ ' + ' + '.join(fixed_predictors)\n",
    "    best_model = initial_formula\n",
    "    best_aic = float('inf')\n",
    "\n",
    "    # DataFrame to store results\n",
    "    results_df = pd.DataFrame(columns=['Formula', 'AIC'])\n",
    "\n",
    "    # Fit the initial model\n",
    "    model = PanelOLS.from_formula(initial_formula, df, drop_absorbed=True, check_rank=False)\n",
    "    results = model.fit()\n",
    "    n = results.nobs\n",
    "    rss = np.sum(results.resids ** 2)\n",
    "    num_params = results.params.shape[0]\n",
    "    best_aic = calculate_aic(n, rss, num_params)\n",
    "    results_df = results_df.append({'Formula': initial_formula, 'AIC': best_aic}, ignore_index=True)\n",
    "\n",
    "    # Forward stepwise selection\n",
    "    for k in range(1, len(potential_predictors) + 1):\n",
    "        for subset in combinations(potential_predictors, k):\n",
    "            formula = f'{dependent_var} ~ ' + ' + '.join(fixed_predictors + list(subset))\n",
    "            model = PanelOLS.from_formula(formula, df, drop_absorbed=True, check_rank=False)\n",
    "            results = model.fit()\n",
    "            n = results.nobs\n",
    "            rss = np.sum(results.resids ** 2)\n",
    "            num_params = results.params.shape[0]\n",
    "            aic = calculate_aic(n, rss, num_params)\n",
    "            results_df = results_df.append({'Formula': formula, 'AIC': aic}, ignore_index=True)\n",
    "            if aic < best_aic:\n",
    "                best_aic = aic\n",
    "                best_model = formula\n",
    "\n",
    "    results_df = results_df.sort_values(by='AIC', ascending=True).reset_index(drop=True)\n",
    "    return best_model, best_aic, results_df\n",
    "\n",
    "\n",
    "# Function to perform backward stepwise selection\n",
    "def backward_stepwise_selection(df, dependent_var, fixed_predictors, potential_predictors):\n",
    "    initial_predictors = fixed_predictors + potential_predictors\n",
    "    initial_formula = f'{dependent_var} ~ ' + ' + '.join(initial_predictors)\n",
    "    best_model = initial_formula\n",
    "    best_aic = float('inf')\n",
    "\n",
    "    # DataFrame to store results\n",
    "    results_df = pd.DataFrame(columns=['Formula', 'AIC'])\n",
    "\n",
    "    # Fit the initial model\n",
    "    model = PanelOLS.from_formula(initial_formula, df, drop_absorbed=True, check_rank=False)\n",
    "    results = model.fit()\n",
    "    n = results.nobs\n",
    "    rss = np.sum(results.resids ** 2)\n",
    "    num_params = results.params.shape[0]\n",
    "    best_aic = calculate_aic(n, rss, num_params)\n",
    "    results_df = results_df.append({'Formula': initial_formula, 'AIC': best_aic}, ignore_index=True)\n",
    "\n",
    "    current_predictors = initial_predictors\n",
    "\n",
    "    # Backward stepwise selection\n",
    "    improved = True\n",
    "    while improved and len(current_predictors) > len(fixed_predictors):\n",
    "        improved = False\n",
    "        for predictor in current_predictors:\n",
    "            if predictor not in fixed_predictors:\n",
    "                candidate_predictors = [p for p in current_predictors if p != predictor]\n",
    "                candidate_formula = f'{dependent_var} ~ ' + ' + '.join(candidate_predictors)\n",
    "                model = PanelOLS.from_formula(candidate_formula, df, drop_absorbed=True, check_rank=False)\n",
    "                results = model.fit()\n",
    "                n = results.nobs\n",
    "                rss = np.sum(results.resids ** 2)\n",
    "                num_params = results.params.shape[0]\n",
    "                aic = calculate_aic(n, rss, num_params)\n",
    "                results_df = results_df.append({'Formula': candidate_formula, 'AIC': aic}, ignore_index=True)\n",
    "                if aic < best_aic:\n",
    "                    best_aic = aic\n",
    "                    best_model = candidate_formula\n",
    "                    current_predictors = candidate_predictors\n",
    "                    improved = True\n",
    "\n",
    "    results_df = results_df.sort_values(by='AIC', ascending=True).reset_index(drop=True)\n",
    "    return best_model, best_aic, results_df\n",
    "\n",
    "\n",
    "# def get_model_summary(formula, df):\n",
    "#     model = PanelOLS.from_formula(formula, df, drop_absorbed=True, check_rank=False)\n",
    "#     results = model.fit()\n",
    "#     return results\n",
    "\n",
    "\n",
    "# Function to plot residuals vs predicted values\n",
    "def plot_residuals_vs_predicted(results, df):\n",
    "    predicted_values = results.fitted_values\n",
    "    residuals = results.resids\n",
    "    \n",
    "    # Plot the histogram of the residuals\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    residuals.plot.hist(bins=100, ax=ax)\n",
    "    plt.title(\"Residuals Histogram\")\n",
    "    plt.show()\n",
    "#     plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(predicted_values, residuals)\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title('Residuals vs Predicted Values')\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "# Function to plot residuals vs independent variables\n",
    "def plot_residuals_vs_independent_vars(results, df, fixed_predictors, potential_predictors):\n",
    "    residuals = results.resids\n",
    "    residuals = residuals[~residuals.index.duplicated(keep='first')]  # Remove duplicates from the index\n",
    "    df['Residuals'] = residuals\n",
    "\n",
    "    for predictor in fixed_predictors + potential_predictors:\n",
    "        if predictor in df.columns:\n",
    "            aligned_residuals = residuals.reindex(df.index)\n",
    "            corr = df.corr().round(3)[predictor][\"Residuals\"]\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.scatter(df[predictor], aligned_residuals)\n",
    "            plt.xlabel(predictor)\n",
    "            plt.ylabel('Residuals')\n",
    "            plt.title(f'Residuals vs {predictor}, Corr: {corr}')\n",
    "            plt.axhline(y=0, color='r', linestyle='--')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "# Function to plot residuals vs dependent variable\n",
    "def plot_residuals_vs_dependent_var(results, df, dependent_var='unem', title=\"Residuals vs Dependent Variable\"):\n",
    "    residuals = results.resids\n",
    "    residuals = residuals[~residuals.index.duplicated(keep='first')]  # Remove duplicates from the index\n",
    "    df['Residuals'] = residuals\n",
    "\n",
    "    aligned_residuals = residuals.reindex(df.index)\n",
    "    corr = df.corr().round(3)[dependent_var][\"Residuals\"]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(df[dependent_var], aligned_residuals)\n",
    "    plt.xlabel(f'Dependent Variable ({dependent_var})')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title(f'{title}({dependent_var}), Corr: {corr}')\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# Function to get model summary using PanelOLS\n",
    "def get_model_summary(formula, df, model_type):\n",
    "    if model_type == \"PanelOLS\":\n",
    "        model = PanelOLS.from_formula(formula, df, drop_absorbed=True, check_rank=False)\n",
    "    elif model_type == \"PooledOLS\":\n",
    "        model = PooledOLS.from_formula(formula, df, check_rank=False)\n",
    "    results = model.fit()\n",
    "    return results\n",
    "\n",
    "\n",
    "# Function to calculate average squared correlations\n",
    "def calculate_avg_squared_correlations(results, df, independent_vars):\n",
    "    residuals = results.resids\n",
    "    squared_correlations = []\n",
    "    for var in independent_vars:\n",
    "        correlation = np.corrcoef(residuals, df[var])[0, 1]\n",
    "        squared_correlation = correlation ** 2\n",
    "        squared_correlations.append(squared_correlation)\n",
    "    avg_squared_correlation = np.mean(squared_correlations)\n",
    "    return avg_squared_correlation, squared_correlations\n",
    "\n",
    "\n",
    "# Function to build skeleton for undirected DAG\n",
    "def build_skeleton(df, undirected_graph, p_val = 0.005):    \n",
    "    def check_remaining_controls(control_vars, undirected_graph, x, y, controls_used):\n",
    "        for c_var in control_vars:\n",
    "            c_used = copy.copy(controls_used)\n",
    "            if y in undirected_graph[x]:\n",
    "                c_used.append(c_var)\n",
    "                test = pg.partial_corr(data=df, x=x, y=y, covar=c_used, method=\"pearson\")\n",
    "                if test[\"p-val\"].values[0] > p_val:\n",
    "                    undirected_graph[x].remove(y)\n",
    "                    break\n",
    "                else:\n",
    "                    remaining_controls = copy.copy(control_vars)\n",
    "                    remaining_controls.remove(c_var)\n",
    "                    check_remaining_controls(remaining_controls, undirected_graph, x, y, c_used)\n",
    "\n",
    "    for x in df.columns:\n",
    "        ys = undirected_graph[x]\n",
    "        for y in ys[:]:  # Use a slice copy to avoid modifying the list during iteration\n",
    "            if x != y:\n",
    "                test = pg.partial_corr(data=df, x=x, y=y, covar=None, method=\"pearson\")\n",
    "                if test[\"p-val\"].values[0] > p_val:\n",
    "                    undirected_graph[x].remove(y)\n",
    "                else:\n",
    "                    control_vars = [z for z in df.columns if z != y and z != x]\n",
    "                    check_remaining_controls(control_vars, undirected_graph, x, y, [])\n",
    "    return undirected_graph\n",
    "\n",
    "# Function to plot undirected DAG\n",
    "def graph_undirected_DAG(undirected_graph, df, title=\"DAG Structure\"):\n",
    "    graph = nx.DiGraph()\n",
    "    edges = []\n",
    "    edge_labels = {}\n",
    "    \n",
    "    for key in undirected_graph:\n",
    "        for key2 in undirected_graph[key]:\n",
    "            if (key2, key) not in edges:\n",
    "                edge = (key.replace(\" \", \"\\n\"), key2.replace(\" \", \"\\n\"))\n",
    "                edges.append(edge)\n",
    "\n",
    "    graph.add_edges_from(edges)\n",
    "    color_map = [\"C0\" for _ in graph]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, 12))\n",
    "    plt.tight_layout()\n",
    "    pos = graphviz_layout(graph)\n",
    "\n",
    "    plt.title(title, fontsize=30)\n",
    "    nx.draw_networkx(graph, pos, node_color=color_map, node_size=1500,\n",
    "                     with_labels=True, arrows=False, font_size=20,\n",
    "                     alpha=1, font_color=\"white\", ax=ax)\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\"g1.png\", format=\"PNG\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# Function to get residuals \n",
    "residuals = {}\n",
    "def get_residuals(df, weights):\n",
    "    for y_var in df.columns:\n",
    "        X_vars = list(df.columns)\n",
    "        X_vars.remove(y_var)\n",
    "        X = df[X_vars].copy()\n",
    "        # Initial estimate should include constant\n",
    "        X[\"Constant\"] = 0\n",
    "        y = df[[y_var]]\n",
    "        model = sm.WLS(y, X, weights=weights)\n",
    "        results = model.fit()\n",
    "        residuals[\"$\\\\epsilon_{\" + y_var + \"}$\"] = results.resid\n",
    "    return pd.DataFrame(residuals)\n",
    "\n",
    "\n",
    "# Function to import geographical data\n",
    "def import_geo_data(filename, index_col = \"Date\", FIPS_name = \"FIPS\"):\n",
    "    # import county level shapefile\n",
    "    map_data = geopandas.read_file(filename = filename,                                   \n",
    "                                   index_col = index_col)\n",
    "    # rename fips code to match variable name in COVID-19 data\n",
    "    map_data.rename(columns={\"State\":\"state\"},\n",
    "                    inplace = True)\n",
    "    # Combine statefips and county fips to create a single fips value\n",
    "    # that identifies each particular county without referencing the \n",
    "    # state separately\n",
    "    map_data[FIPS_name] = map_data[\"STATEFP\"].astype(str) + \\\n",
    "        map_data[\"COUNTYFP\"].astype(str)\n",
    "    map_data[FIPS_name] = map_data[FIPS_name].astype(np.int64)\n",
    "    # set FIPS as index\n",
    "    map_data.set_index(FIPS_name, inplace=True)\n",
    "    \n",
    "    return map_data\n",
    "\n",
    "\n",
    "# Function to Analyse and compare wls and pooled regressions from a dictionary of dataframes\n",
    "def analyze_wls_pooled_models(data_cluster_dict, dependent_var, k=5, shuffle=True, random_state=None, check_rank=False, num_iterations=10):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    mse_results = []\n",
    "    model_attributes = []\n",
    "\n",
    "    for key, df in data_cluster_dict.items():\n",
    "        df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "        county_unem = df.groupby('FIPS')[dependent_var].var()\n",
    "        df['weight'] = df['FIPS'].map(lambda x: 1 / county_unem.get(x, np.nan))\n",
    "        df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=['weight'])\n",
    "\n",
    "        y = df[dependent_var]\n",
    "        X = df.drop(columns=[dependent_var, 'FIPS', 'weight', 'TimePeriod'])\n",
    "        weights = df['weight']\n",
    "\n",
    "        for use_clusters in [True, False]:\n",
    "            X_filtered = X.drop(columns=[col for col in X.columns if 'cluster' in col]) if not use_clusters else X\n",
    "\n",
    "            # Ensure X_filtered contains only numeric data\n",
    "            X_filtered = X_filtered.select_dtypes(include=[np.number])            \n",
    "            \n",
    "            if 'Nominal rates' in key:\n",
    "                X_filtered = sm.add_constant(X_filtered)\n",
    "                \n",
    "            vif_data = pd.DataFrame()\n",
    "            vif_data[\"feature\"] = X_filtered.columns\n",
    "            vif_data[\"VIF\"] = [variance_inflation_factor(X_filtered.dropna().values, i) for i in range(len(X_filtered.columns))]\n",
    "\n",
    "            avg_beta_coefficients = []\n",
    "\n",
    "            for _ in range(num_iterations):\n",
    "                kf = KFold(n_splits=k, shuffle=shuffle, random_state=random_state)\n",
    "                mse_folds = []\n",
    "\n",
    "                for train_index, test_index in kf.split(df):\n",
    "                    X_train, X_test = X_filtered.iloc[train_index], X_filtered.iloc[test_index]\n",
    "                    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "                    weights_train, weights_test = weights.iloc[train_index], weights.iloc[test_index]\n",
    "\n",
    "                    model = sm.WLS(y_train, X_train, weights=weights_train).fit()\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    mse_folds.append(mean_squared_error(y_test, y_pred))\n",
    "                    avg_beta_coefficients.append(model.params.values)\n",
    "\n",
    "                avg_mse = np.mean(mse_folds)\n",
    "                mse_results.append({'Dataset': key, 'Clusters': use_clusters, 'Model': 'WLS', 'Avg MSE': avg_mse, 'MSE Folds': mse_folds, 'R^2': model.rsquared})\n",
    "\n",
    "            avg_beta_coefficients = np.mean(avg_beta_coefficients, axis=0)\n",
    "            model_attributes.append({'Dataset': key, 'Clusters': use_clusters, 'Model': 'WLS', 'Beta Estimates': pd.Series(avg_beta_coefficients, index=model.params.index), 'R^2': model.rsquared})\n",
    "\n",
    "            y_train_pooled = y_train.reset_index()\n",
    "            y_train_pooled['TimePeriod'] = df.iloc[train_index]['TimePeriod'].values\n",
    "            y_train_pooled.set_index(['index', 'TimePeriod'], inplace=True)\n",
    "            y_train_pooled = y_train_pooled[dependent_var]\n",
    "\n",
    "            y_test_pooled = y_test.reset_index()\n",
    "            y_test_pooled['TimePeriod'] = df.iloc[test_index]['TimePeriod'].values\n",
    "            y_test_pooled.set_index(['index', 'TimePeriod'], inplace=True)\n",
    "            y_test_pooled = y_test_pooled[dependent_var]\n",
    "\n",
    "            X_train_pooled = X_train.reset_index()\n",
    "            X_train_pooled['TimePeriod'] = df.iloc[train_index]['TimePeriod'].values\n",
    "            X_train_pooled.set_index(['index', 'TimePeriod'], inplace=True)\n",
    "\n",
    "            X_test_pooled = X_test.reset_index()\n",
    "            X_test_pooled['TimePeriod'] = df.iloc[test_index]['TimePeriod'].values\n",
    "            X_test_pooled.set_index(['index', 'TimePeriod'], inplace=True)\n",
    "\n",
    "            avg_pooled_beta_coefficients = []\n",
    "\n",
    "            for _ in range(num_iterations):\n",
    "                pooled_model = PooledOLS(y_train_pooled, X_train_pooled, check_rank=check_rank).fit()\n",
    "                y_pred_pooled = pooled_model.predict(X_test_pooled)\n",
    "                mse_pooled = mean_squared_error(y_test_pooled, y_pred_pooled)\n",
    "                mse_results.append({'Dataset': key, 'Clusters': use_clusters, 'Model': 'PooledOLS', 'Avg MSE': mse_pooled, 'MSE Folds': mse_folds, 'R^2': pooled_model.rsquared})\n",
    "                avg_pooled_beta_coefficients.append(pooled_model.params.values)\n",
    "\n",
    "            avg_pooled_beta_coefficients = np.mean(avg_pooled_beta_coefficients, axis=0)\n",
    "            model_attributes.append({'Dataset': key, 'Clusters': use_clusters, 'Model': 'PooledOLS', 'Beta Estimates': pd.Series(avg_pooled_beta_coefficients, index=pooled_model.params.index), 'R^2': pooled_model.rsquared})\n",
    "\n",
    "    # Accessing results as a list\n",
    "    results_list = []\n",
    "    for attributes in model_attributes:\n",
    "        results_list.append({\n",
    "            'Dataset': attributes['Dataset'],\n",
    "            'Clusters': attributes['Clusters'],\n",
    "            'Model': attributes['Model'],\n",
    "            'Beta Estimates': attributes['Beta Estimates'].values.tolist(),\n",
    "#             'Avg MSE': attributes['Avg MSE'],\n",
    "            'R^2': attributes['R^2']\n",
    "        })\n",
    "\n",
    "    \n",
    "    \n",
    "    result_df = pd.DataFrame()\n",
    "    for attributes in model_attributes:\n",
    "        dataset_name = attributes['Dataset']\n",
    "        clusters = attributes['Clusters']\n",
    "        model_name = attributes['Model']\n",
    "        beta_estimates = attributes['Beta Estimates']\n",
    "        avg_mse = next(result['Avg MSE'] for result in mse_results if result['Dataset'] == dataset_name and result['Clusters'] == clusters and result['Model'] == model_name)\n",
    "        mse_folds = next(result['MSE Folds'] for result in mse_results if result['Dataset'] == dataset_name and result['Clusters'] == clusters and result['Model'] == model_name)\n",
    "        r_squared = attributes['R^2']\n",
    "        mse_series = pd.Series([r_squared, avg_mse] + mse_folds, index=[\"$R^2$\", \"Avg MSE\"] + [f\"MSE Fold {i+1}\" for i in range(len(mse_folds))])\n",
    "        combined_series = pd.concat([beta_estimates, mse_series], axis=0)\n",
    "        result_df = pd.concat([result_df, combined_series], axis=1)\n",
    "        result_df.rename(columns={result_df.columns[-1]: f\"{dataset_name} - {clusters} - {model_name}\"}, inplace=True)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "# Function to run wls and pooledOLS without k-fold\n",
    "def wls_pooled_model_analysis(data_cluster_dict, dependent_var, random_state=None, check_rank=False):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    mse_results = []\n",
    "    model_attributes = []\n",
    "\n",
    "    for key, df in data_cluster_dict.items():\n",
    "        df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "        county_unem = df.groupby('FIPS')[dependent_var].var()\n",
    "        df['weight'] = df['FIPS'].map(lambda x: 1 / county_unem.get(x, np.nan))\n",
    "        df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=['weight'])\n",
    "\n",
    "        y = df[dependent_var]\n",
    "        X = df.drop(columns=[dependent_var, 'FIPS', 'weight', 'TimePeriod'])\n",
    "        weights = df['weight']\n",
    "\n",
    "        for use_clusters in [True, False]:\n",
    "            X_filtered = X.drop(columns=[col for col in X.columns if 'cluster' in col]) if not use_clusters else X\n",
    "\n",
    "            # Ensure X_filtered contains only numeric data\n",
    "            X_filtered = X_filtered.select_dtypes(include=[np.number])            \n",
    "            \n",
    "            if 'Nominal rates' in key:\n",
    "                X_filtered = sm.add_constant(X_filtered)\n",
    "                \n",
    "            vif_data = pd.DataFrame()\n",
    "            vif_data[\"feature\"] = X_filtered.columns\n",
    "            vif_data[\"VIF\"] = [variance_inflation_factor(X_filtered.dropna().values, i) for i in range(len(X_filtered.columns))]\n",
    "\n",
    "            model = sm.WLS(y, X_filtered, weights=weights).fit()\n",
    "            model_attributes.append({'Dataset': key, 'Clusters': use_clusters, 'Model': 'WLS', 'Beta Estimates': model.params, 'R^2': model.rsquared})\n",
    "\n",
    "            y_pooled = y.reset_index()\n",
    "            y_pooled['TimePeriod'] = df['TimePeriod'].values\n",
    "            y_pooled.set_index(['index', 'TimePeriod'], inplace=True)\n",
    "            y_pooled = y_pooled[dependent_var]\n",
    "\n",
    "            X_pooled = X_filtered.reset_index()\n",
    "            X_pooled['TimePeriod'] = df['TimePeriod'].values\n",
    "            X_pooled.set_index(['index', 'TimePeriod'], inplace=True)\n",
    "\n",
    "            pooled_model = PooledOLS(y_pooled, X_pooled, check_rank=check_rank).fit()\n",
    "            model_attributes.append({'Dataset': key, 'Clusters': use_clusters, 'Model': 'PooledOLS', 'Beta Estimates': pooled_model.params, 'R^2': pooled_model.rsquared})\n",
    "\n",
    "            \n",
    "    # Accessing results as a list\n",
    "    results_list = []\n",
    "    for attributes in model_attributes:\n",
    "        results_list.append({\n",
    "            'Dataset': attributes['Dataset'],\n",
    "            'Clusters': attributes['Clusters'],\n",
    "            'Model': attributes['Model'],\n",
    "            'Beta Estimates': attributes['Beta Estimates'].values.tolist(),\n",
    "            'R^2': attributes['R^2']\n",
    "        })\n",
    "        \n",
    "            \n",
    "    result_df = pd.DataFrame()\n",
    "    for attributes in model_attributes:\n",
    "        dataset_name = attributes['Dataset']\n",
    "        clusters = attributes['Clusters']\n",
    "        model_name = attributes['Model']\n",
    "        beta_estimates = attributes['Beta Estimates']\n",
    "        r_squared = attributes['R^2']\n",
    "        combined_series = pd.concat([beta_estimates, pd.Series(r_squared, index=[\"$R^2$\"])], axis=0)\n",
    "        result_df = pd.concat([result_df, combined_series], axis=1)\n",
    "        result_df.rename(columns={result_df.columns[-1]: f\"{dataset_name} - {clusters} - {model_name}\"}, inplace=True)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "# Function to perform k-fold on wls and pooledOLS and report all mse's\n",
    "def analyze_wls_pooled_models_all_mse(data_cluster_dict, dependent_var, k=5, shuffle=True, random_state=None, check_rank=False, num_iterations=10):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    mse_results = []\n",
    "    model_attributes = []\n",
    "\n",
    "    for key, df in data_cluster_dict.items():\n",
    "        df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "        county_unem = df.groupby('FIPS')[dependent_var].var()\n",
    "        df['weight'] = df['FIPS'].map(lambda x: 1 / county_unem.get(x, np.nan))\n",
    "        df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=['weight'])\n",
    "\n",
    "        y = df[dependent_var]\n",
    "        X = df.drop(columns=[dependent_var, 'FIPS', 'weight', 'TimePeriod'])\n",
    "        weights = df['weight']\n",
    "\n",
    "        for use_clusters in [True, False]:\n",
    "            X_filtered = X.drop(columns=[col for col in X.columns if 'cluster' in col]) if not use_clusters else X\n",
    "\n",
    "            # Ensure X_filtered contains only numeric data\n",
    "            X_filtered = X_filtered.select_dtypes(include=[np.number])            \n",
    "            \n",
    "            if 'Nominal rates' in key:\n",
    "                X_filtered = sm.add_constant(X_filtered)\n",
    "                \n",
    "            vif_data = pd.DataFrame()\n",
    "            vif_data[\"feature\"] = X_filtered.columns\n",
    "            vif_data[\"VIF\"] = [variance_inflation_factor(X_filtered.dropna().values, i) for i in range(len(X_filtered.columns))]\n",
    "\n",
    "            avg_beta_coefficients = []\n",
    "            mse_folds = []\n",
    "\n",
    "            for _ in range(num_iterations):\n",
    "                kf = KFold(n_splits=k, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "                for train_index, test_index in kf.split(df):\n",
    "                    X_train, X_test = X_filtered.iloc[train_index], X_filtered.iloc[test_index]\n",
    "                    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "                    weights_train, weights_test = weights.iloc[train_index], weights.iloc[test_index]\n",
    "\n",
    "                    # WLS model\n",
    "                    model = sm.WLS(y_train, X_train, weights=weights_train).fit()\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    mse_folds.append(mean_squared_error(y_test, y_pred))\n",
    "                    avg_beta_coefficients.append(model.params.values)\n",
    "\n",
    "                avg_mse = np.mean(mse_folds)\n",
    "                mse_results.append({'Dataset': key, 'Clusters': use_clusters, 'Model': 'WLS', 'Avg MSE': avg_mse, 'MSE Folds': mse_folds, 'R^2': model.rsquared})\n",
    "\n",
    "            avg_beta_coefficients = np.mean(avg_beta_coefficients, axis=0)\n",
    "            model_attributes.append({'Dataset': key, 'Clusters': use_clusters, 'Model': 'WLS', 'Beta Estimates': pd.Series(avg_beta_coefficients, index=model.params.index), 'R^2': model.rsquared})\n",
    "\n",
    "            avg_pooled_beta_coefficients = []\n",
    "            mse_folds_pooled = []\n",
    "\n",
    "            for _ in range(num_iterations):\n",
    "                kf = KFold(n_splits=k, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "                for train_index, test_index in kf.split(df):\n",
    "                    y_train_pooled = y.iloc[train_index].reset_index()\n",
    "                    y_train_pooled['TimePeriod'] = df.iloc[train_index]['TimePeriod'].values\n",
    "                    y_train_pooled.set_index(['index', 'TimePeriod'], inplace=True)\n",
    "                    y_train_pooled = y_train_pooled[dependent_var]\n",
    "\n",
    "                    y_test_pooled = y.iloc[test_index].reset_index()\n",
    "                    y_test_pooled['TimePeriod'] = df.iloc[test_index]['TimePeriod'].values\n",
    "                    y_test_pooled.set_index(['index', 'TimePeriod'], inplace=True)\n",
    "                    y_test_pooled = y_test_pooled[dependent_var]\n",
    "\n",
    "                    X_train_pooled = X_filtered.iloc[train_index].reset_index()\n",
    "                    X_train_pooled['TimePeriod'] = df.iloc[train_index]['TimePeriod'].values\n",
    "                    X_train_pooled.set_index(['index', 'TimePeriod'], inplace=True)\n",
    "\n",
    "                    X_test_pooled = X_filtered.iloc[test_index].reset_index()\n",
    "                    X_test_pooled['TimePeriod'] = df.iloc[test_index]['TimePeriod'].values\n",
    "                    X_test_pooled.set_index(['index', 'TimePeriod'], inplace=True)\n",
    "\n",
    "                    pooled_model = PooledOLS(y_train_pooled, X_train_pooled, check_rank=check_rank).fit()\n",
    "                    y_pred_pooled = pooled_model.predict(X_test_pooled)\n",
    "                    mse_folds_pooled.append(mean_squared_error(y_test_pooled, y_pred_pooled))\n",
    "                    avg_pooled_beta_coefficients.append(pooled_model.params.values)\n",
    "\n",
    "                avg_mse_pooled = np.mean(mse_folds_pooled)\n",
    "                mse_results.append({'Dataset': key, 'Clusters': use_clusters, 'Model': 'PooledOLS', 'Avg MSE': avg_mse_pooled, 'MSE Folds': mse_folds_pooled, 'R^2': pooled_model.rsquared})\n",
    "\n",
    "            avg_pooled_beta_coefficients = np.mean(avg_pooled_beta_coefficients, axis=0)\n",
    "            model_attributes.append({'Dataset': key, 'Clusters': use_clusters, 'Model': 'PooledOLS', 'Beta Estimates': pd.Series(avg_pooled_beta_coefficients, index=pooled_model.params.index), 'R^2': pooled_model.rsquared})\n",
    "\n",
    "    # Accessing results as a list\n",
    "    results_list = []\n",
    "    for attributes in model_attributes:\n",
    "        results_list.append({\n",
    "            'Dataset': attributes['Dataset'],\n",
    "            'Clusters': attributes['Clusters'],\n",
    "            'Model': attributes['Model'],\n",
    "            'Beta Estimates': attributes['Beta Estimates'].values.tolist(),\n",
    "#             'Avg MSE': attributes['Avg MSE'],\n",
    "            'R^2': attributes['R^2']\n",
    "        })\n",
    "\n",
    "    \n",
    "    \n",
    "    result_df = pd.DataFrame()\n",
    "    for attributes in model_attributes:\n",
    "        dataset_name = attributes['Dataset']\n",
    "        clusters = attributes['Clusters']\n",
    "        model_name = attributes['Model']\n",
    "        beta_estimates = attributes['Beta Estimates']\n",
    "        avg_mse = next(result['Avg MSE'] for result in mse_results if result['Dataset'] == dataset_name and result['Clusters'] == clusters and result['Model'] == model_name)\n",
    "        mse_folds = next(result['MSE Folds'] for result in mse_results if result['Dataset'] == dataset_name and result['Clusters'] == clusters and result['Model'] == model_name)\n",
    "        r_squared = attributes['R^2']\n",
    "        mse_series = pd.Series([r_squared, avg_mse] + mse_folds, index=[\"$R^2$\", \"Avg MSE\"] + [f\"MSE Fold {i+1}\" for i in range(len(mse_folds))])\n",
    "        combined_series = pd.concat([beta_estimates, mse_series], axis=0)\n",
    "        result_df = pd.concat([result_df, combined_series], axis=1)\n",
    "        result_df.rename(columns={result_df.columns[-1]: f\"{dataset_name} - {clusters} - {model_name}\"}, inplace=True)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# Function to perform k-fold on wls and pooledOLS and report the least mse\n",
    "def analyze_wls_pooled_models_least_mse(data_cluster_dict, dependent_var, k=5, shuffle=True, random_state=None, check_rank=False, num_iterations=10):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    model_attributes = []\n",
    "\n",
    "    for key, df in data_cluster_dict.items():\n",
    "        df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "        county_unem = df.groupby('FIPS')[dependent_var].var()\n",
    "        df['weight'] = df['FIPS'].map(lambda x: 1 / county_unem.get(x, np.nan))\n",
    "        df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=['weight'])\n",
    "\n",
    "        y = df[dependent_var]\n",
    "        X = df.drop(columns=[dependent_var, 'FIPS', 'weight', 'TimePeriod'])\n",
    "        weights = df['weight']\n",
    "\n",
    "        for use_clusters in [True, False]:\n",
    "            X_filtered = X.drop(columns=[col for col in X.columns if 'cluster' in col]) if not use_clusters else X\n",
    "\n",
    "            # Ensure X_filtered contains only numeric data\n",
    "            X_filtered = X_filtered.select_dtypes(include=[np.number])            \n",
    "            \n",
    "            if 'Nominal rates' in key:\n",
    "                X_filtered = sm.add_constant(X_filtered)\n",
    "                \n",
    "            all_mse_folds = []\n",
    "            all_beta_coefficients = []\n",
    "\n",
    "            for _ in range(num_iterations):\n",
    "                kf = KFold(n_splits=k, shuffle=shuffle, random_state=random_state)\n",
    "                for train_index, test_index in kf.split(df):\n",
    "                    X_train, X_test = X_filtered.iloc[train_index], X_filtered.iloc[test_index]\n",
    "                    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "                    weights_train, weights_test = weights.iloc[train_index], weights.iloc[test_index]\n",
    "\n",
    "                    # WLS model\n",
    "                    model = sm.WLS(y_train, X_train, weights=weights_train).fit()\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    mse = mean_squared_error(y_test, y_pred)\n",
    "                    all_mse_folds.append(mse)\n",
    "                    all_beta_coefficients.append(model.params.values)\n",
    "\n",
    "            # Select the least MSE across all iterations and folds\n",
    "            least_mse_index = np.argmin(all_mse_folds)\n",
    "            least_mse = all_mse_folds[least_mse_index]\n",
    "            least_beta_coefficients = all_beta_coefficients[least_mse_index]\n",
    "\n",
    "            model_attributes.append({\n",
    "                'Dataset': key, 'Clusters': use_clusters, 'Model': 'WLS', \n",
    "                'Beta Estimates': pd.Series(least_beta_coefficients, index=model.params.index),\n",
    "                'Least MSE': least_mse,\n",
    "                'R^2': model.rsquared\n",
    "            })\n",
    "\n",
    "            all_pooled_mse_folds = []\n",
    "            all_pooled_beta_coefficients = []\n",
    "\n",
    "            for _ in range(num_iterations):\n",
    "                kf = KFold(n_splits=k, shuffle=shuffle, random_state=random_state)\n",
    "                for train_index, test_index in kf.split(df):\n",
    "                    y_train_pooled = y.iloc[train_index].reset_index()\n",
    "                    y_train_pooled['TimePeriod'] = df.iloc[train_index]['TimePeriod'].values\n",
    "                    y_train_pooled.set_index(['index', 'TimePeriod'], inplace=True)\n",
    "                    y_train_pooled = y_train_pooled[dependent_var]\n",
    "\n",
    "                    y_test_pooled = y.iloc[test_index].reset_index()\n",
    "                    y_test_pooled['TimePeriod'] = df.iloc[test_index]['TimePeriod'].values\n",
    "                    y_test_pooled.set_index(['index', 'TimePeriod'], inplace=True)\n",
    "                    y_test_pooled = y_test_pooled[dependent_var]\n",
    "\n",
    "                    X_train_pooled = X_filtered.iloc[train_index].reset_index()\n",
    "                    X_train_pooled['TimePeriod'] = df.iloc[train_index]['TimePeriod'].values\n",
    "                    X_train_pooled.set_index(['index', 'TimePeriod'], inplace=True)\n",
    "\n",
    "                    X_test_pooled = X_filtered.iloc[test_index].reset_index()\n",
    "                    X_test_pooled['TimePeriod'] = df.iloc[test_index]['TimePeriod'].values\n",
    "                    X_test_pooled.set_index(['index', 'TimePeriod'], inplace=True)\n",
    "\n",
    "                    pooled_model = PooledOLS(y_train_pooled, X_train_pooled, check_rank=check_rank).fit()\n",
    "                    y_pred_pooled = pooled_model.predict(X_test_pooled)\n",
    "                    mse_pooled = mean_squared_error(y_test_pooled, y_pred_pooled)\n",
    "                    all_pooled_mse_folds.append(mse_pooled)\n",
    "                    all_pooled_beta_coefficients.append(pooled_model.params.values)\n",
    "\n",
    "            # Select the least MSE across all iterations and folds for PooledOLS\n",
    "            least_mse_index_pooled = np.argmin(all_pooled_mse_folds)\n",
    "            least_mse_pooled = all_pooled_mse_folds[least_mse_index_pooled]\n",
    "            least_beta_coefficients_pooled = all_pooled_beta_coefficients[least_mse_index_pooled]\n",
    "\n",
    "            model_attributes.append({\n",
    "                'Dataset': key, 'Clusters': use_clusters, 'Model': 'PooledOLS', \n",
    "                'Beta Estimates': pd.Series(least_beta_coefficients_pooled, index=pooled_model.params.index),\n",
    "                'Least MSE': least_mse_pooled,\n",
    "                'R^2': pooled_model.rsquared\n",
    "            })\n",
    "            \n",
    "    # Accessing results as a list\n",
    "    results_list = []\n",
    "    for attributes in model_attributes:\n",
    "        results_list.append({\n",
    "            'Dataset': attributes['Dataset'],\n",
    "            'Clusters': attributes['Clusters'],\n",
    "            'Model': attributes['Model'],\n",
    "            'Beta Estimates': attributes['Beta Estimates'].values.tolist(),\n",
    "            'Least MSE': attributes['Least MSE'],\n",
    "            'R^2': attributes['R^2']\n",
    "        })\n",
    "        \n",
    "\n",
    "    result_df = pd.DataFrame()\n",
    "    for attributes in model_attributes:\n",
    "        dataset_name = attributes['Dataset']\n",
    "        clusters = attributes['Clusters']\n",
    "        model_name = attributes['Model']\n",
    "        beta_estimates = attributes['Beta Estimates']\n",
    "        least_mse = attributes['Least MSE']\n",
    "        r_squared = attributes['R^2']\n",
    "        mse_series = pd.Series([r_squared, least_mse], index=[\"$R^2$\", \"Least MSE\"])\n",
    "        combined_series = pd.concat([beta_estimates, mse_series], axis=0)\n",
    "        result_df = pd.concat([result_df, combined_series], axis=1)\n",
    "        result_df.rename(columns={result_df.columns[-1]: f\"{dataset_name} - {clusters} - {model_name}\"}, inplace=True)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "# Function to perform k-fold on wls and OLS and report the least mse\n",
    "def analyze_wls_ols_models_least_mse(data_cluster_dict, dependent_var, k=5, shuffle=True, random_state=None, check_rank=True, num_iterations=10):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    model_attributes = []\n",
    "\n",
    "    for key, df in data_cluster_dict.items():\n",
    "        df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "        county_unem = df.groupby('FIPS')[dependent_var].var()\n",
    "        df['weight'] = df['FIPS'].map(lambda x: 1 / county_unem.get(x, np.nan))\n",
    "        df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=['weight'])\n",
    "\n",
    "        y = df[dependent_var]\n",
    "        X = df.drop(columns=[dependent_var, 'FIPS', 'weight', 'TimePeriod'])\n",
    "        weights = df['weight']\n",
    "\n",
    "        for use_clusters in [True, False]:\n",
    "            X_filtered = X.drop(columns=[col for col in X.columns if 'cluster' in col]) if not use_clusters else X\n",
    "\n",
    "            # Ensure X_filtered contains only numeric data\n",
    "            X_filtered = X_filtered.select_dtypes(include=[np.number])            \n",
    "            \n",
    "            if 'Nominal rates' in key:\n",
    "                X_filtered = sm.add_constant(X_filtered)\n",
    "                \n",
    "            all_mse_folds = []\n",
    "            all_beta_coefficients = []\n",
    "\n",
    "            for _ in range(num_iterations):\n",
    "                kf = KFold(n_splits=k, shuffle=shuffle, random_state=random_state)\n",
    "                for train_index, test_index in kf.split(df):\n",
    "                    X_train, X_test = X_filtered.iloc[train_index], X_filtered.iloc[test_index]\n",
    "                    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "                    weights_train, weights_test = weights.iloc[train_index], weights.iloc[test_index]\n",
    "\n",
    "                    # WLS model\n",
    "                    model = sm.WLS(y_train, X_train, weights=weights_train).fit()\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    mse = mean_squared_error(y_test, y_pred)\n",
    "                    all_mse_folds.append(mse)\n",
    "                    all_beta_coefficients.append(model.params.values)\n",
    "\n",
    "            # Select the least MSE across all iterations and folds\n",
    "            least_mse_index = np.argmin(all_mse_folds)\n",
    "            least_mse = all_mse_folds[least_mse_index]\n",
    "            least_beta_coefficients = all_beta_coefficients[least_mse_index]\n",
    "\n",
    "            model_attributes.append({\n",
    "                'Dataset': key, 'Clusters': use_clusters, 'Model': 'WLS', \n",
    "                'Beta Estimates': pd.Series(least_beta_coefficients, index=model.params.index),\n",
    "                'Least MSE': least_mse,\n",
    "                'R^2': model.rsquared,\n",
    "                'Residuals': model.resid  # Add residuals to the model attributes\n",
    "            })\n",
    "\n",
    "            all_ols_mse_folds = []\n",
    "            all_ols_beta_coefficients = []\n",
    "\n",
    "            for _ in range(num_iterations):\n",
    "                kf = KFold(n_splits=k, shuffle=shuffle, random_state=random_state)\n",
    "                for train_index, test_index in kf.split(df):\n",
    "                    X_train_ols, X_test_ols = X_filtered.iloc[train_index], X_filtered.iloc[test_index]\n",
    "                    y_train_ols, y_test_ols = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "                    ols_model = sm.OLS(y_train_ols, X_train_ols).fit()\n",
    "                    y_pred_ols = ols_model.predict(X_test_ols)\n",
    "                    mse_ols = mean_squared_error(y_test_ols, y_pred_ols)\n",
    "                    all_ols_mse_folds.append(mse_ols)\n",
    "                    all_ols_beta_coefficients.append(ols_model.params.values)\n",
    "\n",
    "            # Select the least MSE across all iterations and folds for OLS\n",
    "            least_mse_index_ols = np.argmin(all_ols_mse_folds)\n",
    "            least_mse_ols = all_ols_mse_folds[least_mse_index_ols]\n",
    "            least_beta_coefficients_ols = all_ols_beta_coefficients[least_mse_index_ols]\n",
    "\n",
    "            model_attributes.append({\n",
    "                'Dataset': key, 'Clusters': use_clusters, 'Model': 'OLS', \n",
    "                'Beta Estimates': pd.Series(least_beta_coefficients_ols, index=ols_model.params.index),\n",
    "                'Least MSE': least_mse_ols,\n",
    "                'R^2': ols_model.rsquared,\n",
    "                'Residuals': ols_model.resid  # Add residuals to the model attributes\n",
    "            })\n",
    "            \n",
    "    return model_attributes\n",
    "\n",
    "# Function to analyse olw and wls with varying k-folds\n",
    "def analyze_wls_ols_models_with_varying_folds(data_cluster_dict, dependent_var, start_k=5, max_k=10, shuffle=True, random_state=None, num_iterations=10):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    for key, df in data_cluster_dict.items():\n",
    "        model_attributes = []\n",
    "\n",
    "        df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "        county_unem = df.groupby('FIPS')[dependent_var].var()\n",
    "        df['weight'] = df['FIPS'].map(lambda x: 1 / county_unem.get(x, np.nan))\n",
    "        df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=['weight'])\n",
    "\n",
    "        y = df[dependent_var]\n",
    "        X = df.drop(columns=[dependent_var, 'FIPS', 'weight', 'TimePeriod'])\n",
    "        weights = df['weight']\n",
    "\n",
    "        for use_clusters in [True, False]:\n",
    "            X_filtered = X.drop(columns=[col for col in X.columns if 'cluster' in col]) if not use_clusters else X\n",
    "\n",
    "            # Ensure X_filtered contains only numeric data\n",
    "            X_filtered = X_filtered.select_dtypes(include=[np.number])            \n",
    "            \n",
    "            if 'Nominal rates' in key:\n",
    "                X_filtered = sm.add_constant(X_filtered)\n",
    "\n",
    "            all_mse_folds = []\n",
    "            all_beta_coefficients = []\n",
    "\n",
    "            for k in range(start_k, max_k + 1):\n",
    "                for _ in range(num_iterations):\n",
    "                    kf = KFold(n_splits=k, shuffle=shuffle, random_state=random_state)\n",
    "                    for train_index, test_index in kf.split(df):\n",
    "                        X_train, X_test = X_filtered.iloc[train_index], X_filtered.iloc[test_index]\n",
    "                        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "                        weights_train, weights_test = weights.iloc[train_index], weights.iloc[test_index]\n",
    "\n",
    "                        # WLS model\n",
    "                        model = sm.WLS(y_train, X_train, weights=weights_train).fit()\n",
    "                        y_pred = model.predict(X_test)\n",
    "                        mse = mean_squared_error(y_test, y_pred)\n",
    "                        all_mse_folds.append(mse)\n",
    "                        all_beta_coefficients.append(model.params.values)\n",
    "\n",
    "                # Select the least 3 MSEs across all iterations and folds\n",
    "                top_3_indices = np.argsort(all_mse_folds)[:3]\n",
    "                top_3_mse = [all_mse_folds[i] for i in top_3_indices]\n",
    "                avg_top_3_mse = np.mean(top_3_mse)\n",
    "                top_3_betas = [all_beta_coefficients[i] for i in top_3_indices]\n",
    "                avg_top_3_betas = np.mean(top_3_betas, axis=0)\n",
    "\n",
    "                model_attributes.append({\n",
    "                    'Dataset': key, 'Clusters': use_clusters, 'Model': 'WLS', 'K': k, \n",
    "                    'Avg Beta Estimates': pd.Series(avg_top_3_betas, index=model.params.index),\n",
    "                    'Avg Top 3 MSE': avg_top_3_mse,\n",
    "                    'R^2': model.rsquared,\n",
    "                    'Residuals': model.resid\n",
    "                })\n",
    "\n",
    "                all_ols_mse_folds = []\n",
    "                all_ols_beta_coefficients = []\n",
    "\n",
    "                for _ in range(num_iterations):\n",
    "                    kf = KFold(n_splits=k, shuffle=shuffle, random_state=random_state)\n",
    "                    for train_index, test_index in kf.split(df):\n",
    "                        X_train_ols, X_test_ols = X_filtered.iloc[train_index], X_filtered.iloc[test_index]\n",
    "                        y_train_ols, y_test_ols = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "                        ols_model = sm.OLS(y_train_ols, X_train_ols).fit()\n",
    "                        y_pred_ols = ols_model.predict(X_test_ols)\n",
    "                        mse_ols = mean_squared_error(y_test_ols, y_pred_ols)\n",
    "                        all_ols_mse_folds.append(mse_ols)\n",
    "                        all_ols_beta_coefficients.append(ols_model.params.values)\n",
    "\n",
    "                # Select the least 3 MSEs across all iterations and folds for OLS\n",
    "                top_3_indices_ols = np.argsort(all_ols_mse_folds)[:3]\n",
    "                top_3_mse_ols = [all_ols_mse_folds[i] for i in top_3_indices_ols]\n",
    "                avg_top_3_mse_ols = np.mean(top_3_mse_ols)\n",
    "                top_3_betas_ols = [all_ols_beta_coefficients[i] for i in top_3_indices_ols]\n",
    "                avg_top_3_betas_ols = np.mean(top_3_betas_ols, axis=0)\n",
    "\n",
    "                model_attributes.append({\n",
    "                    'Dataset': key, 'Clusters': use_clusters, 'Model': 'OLS', 'K': k, \n",
    "                    'Avg Beta Estimates': pd.Series(avg_top_3_betas_ols, index=ols_model.params.index),\n",
    "                    'Avg Top 3 MSE': avg_top_3_mse_ols,\n",
    "                    'R^2': ols_model.rsquared,\n",
    "                    'Residuals': ols_model.resid\n",
    "                })\n",
    "        \n",
    "        results[key] = model_attributes\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# Function to plot wls and ols caomparisons (bar charts)\n",
    "def plot_model_comparisons(df, title_suffix):\n",
    "    # Initialize colors for 'WLS' and 'OLS' models\n",
    "    color_wls = 'skyblue'\n",
    "    color_ols = 'salmon'\n",
    "\n",
    "    # Extract variables and K values from the dataframe\n",
    "    variables = set()\n",
    "    k_values = set()\n",
    "    for entry in df:\n",
    "        if 'Avg Beta Estimates' in entry:\n",
    "            variables.update(entry['Avg Beta Estimates'].keys())\n",
    "        k_values.add(entry['K'])\n",
    "    \n",
    "    variables = sorted(variables)\n",
    "    k_values = sorted(k_values)\n",
    "    \n",
    "    # Initialize a figure with subplots\n",
    "    fig, axes = plt.subplots(2 * (len(variables) + 2), 1, figsize=(12, 12 * (len(variables) + 2)), sharex=True)\n",
    "    \n",
    "    for idx, var in enumerate(variables):\n",
    "        for cluster_status in [True, False]:\n",
    "            for model_idx, model in enumerate(['WLS', 'OLS']):\n",
    "                var_values = []\n",
    "                for entry in df:\n",
    "                    if entry['Clusters'] == cluster_status and entry['Model'] == model:\n",
    "                        k = entry['K']\n",
    "                        if var in entry['Avg Beta Estimates']:\n",
    "                            var_values.append(entry['Avg Beta Estimates'][var])\n",
    "                        else:\n",
    "                            var_values.append(0)  # Handle missing variable case\n",
    "                if model == 'WLS':\n",
    "                    axes[2 * idx + cluster_status].bar(np.arange(len(k_values)) + model_idx * 0.4, var_values, color=color_wls, width=0.4, alpha=0.7, label=model)\n",
    "                elif model == 'OLS':\n",
    "                    axes[2 * idx + cluster_status].bar(np.arange(len(k_values)) + model_idx * 0.4, var_values, color=color_ols, width=0.4, alpha=0.7, label=model)\n",
    "            axes[2 * idx + cluster_status].set_xlabel('K values')\n",
    "            axes[2 * idx + cluster_status].set_ylabel(f'Values')\n",
    "            axes[2 * idx + cluster_status].set_title(f'{var} ({title_suffix}, Clusters={cluster_status})')\n",
    "            axes[2 * idx + cluster_status].set_xticks(np.arange(len(k_values)) + 0.2)\n",
    "            axes[2 * idx + cluster_status].set_xticklabels([f'K={k}' for k in k_values])  # Set the x-axis labels to include K values\n",
    "            axes[2 * idx + cluster_status].grid(axis='y')\n",
    "            axes[2 * idx + cluster_status].legend()\n",
    "    \n",
    "    # Include R^2 and Avg Top 3 MSE in the plot\n",
    "    for cluster_status in [True, False]:\n",
    "        for model_idx, model in enumerate(['WLS', 'OLS']):\n",
    "            r_squared_values = [entry['R^2'] for entry in df if entry['Clusters'] == cluster_status and entry['Model'] == model]\n",
    "            avg_top3_mse_values = [entry['Avg Top 3 MSE'] for entry in df if entry['Clusters'] == cluster_status and entry['Model'] == model]\n",
    "            if model == 'WLS':\n",
    "                axes[2 * len(variables) + cluster_status].bar(np.arange(len(k_values)) + model_idx * 0.4, r_squared_values, color=color_wls, width=0.4, alpha=0.7, label=model)\n",
    "                axes[2 * len(variables) + 2 + cluster_status].bar(np.arange(len(k_values)) + model_idx * 0.4, avg_top3_mse_values, color=color_wls, width=0.4, alpha=0.7, label=model)\n",
    "            elif model == 'OLS':\n",
    "                axes[2 * len(variables) + cluster_status].bar(np.arange(len(k_values)) + model_idx * 0.4, r_squared_values, color=color_ols, width=0.4, alpha=0.7, label=model)\n",
    "                axes[2 * len(variables) + 2 + cluster_status].bar(np.arange(len(k_values)) + model_idx * 0.4, avg_top3_mse_values, color=color_ols, width=0.4, alpha=0.7, label=model)\n",
    "            \n",
    "            axes[2 * len(variables) + cluster_status].set_xlabel('K values')\n",
    "            axes[2 * len(variables) + cluster_status].set_ylabel('$R^2$')\n",
    "            axes[2 * len(variables) + cluster_status].set_title(f'$R^2$ ({title_suffix}, Clusters={cluster_status})')\n",
    "            axes[2 * len(variables) + cluster_status].set_xticks(np.arange(len(k_values)) + 0.2)\n",
    "            axes[2 * len(variables) + cluster_status].set_xticklabels([f'K={k}' for k in k_values])  # Set the x-axis labels to include K values\n",
    "            axes[2 * len(variables) + cluster_status].grid(axis='y')\n",
    "            axes[2 * len(variables) + cluster_status].legend()\n",
    "            \n",
    "            axes[2 * len(variables) + 2 + cluster_status].set_xlabel('K values')\n",
    "            axes[2 * len(variables) + 2 + cluster_status].set_ylabel('Avg Top 3 MSE')\n",
    "            axes[2 * len(variables) + 2 + cluster_status].set_title(f'Avg Top 3 MSE ({title_suffix}, Clusters={cluster_status})')\n",
    "            axes[2 * len(variables) + 2 + cluster_status].set_xticks(np.arange(len(k_values)) + 0.2)\n",
    "            axes[2 * len(variables) + 2 + cluster_status].set_xticklabels([f'K={k}' for k in k_values])  # Set the x-axis labels to include K values\n",
    "            axes[2 * len(variables) + 2 + cluster_status].grid(axis='y')\n",
    "            axes[2 * len(variables) + 2 + cluster_status].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "# Function to plot dynamic line plots \n",
    "def plot_model_comparisons_with_dropdowns(results_dict):\n",
    "    variables = set()\n",
    "    k_values = set()\n",
    "    for entry in results_dict['Nominal rates with clusters']:\n",
    "        if 'Avg Beta Estimates' in entry:\n",
    "            variables.update(entry['Avg Beta Estimates'].keys())\n",
    "        k_values.add(entry['K'])\n",
    "    \n",
    "    variables = sorted(variables)\n",
    "    k_values = sorted(k_values)\n",
    "\n",
    "    # Create subplots: 3 rows, 2 columns\n",
    "    fig = make_subplots(rows=3, cols=2, subplot_titles=[\n",
    "        'Beta Estimates (OLS)', 'Beta Estimates (WLS)',\n",
    "        'Avg Top 3 MSE (OLS)', 'Avg Top 3 MSE (WLS)',\n",
    "        '$R^2 (OLS)$', '$R^2 (WLS)$'\n",
    "    ], vertical_spacing=0.1, horizontal_spacing=0.1)\n",
    "\n",
    "    def add_traces_to_fig(df, title_suffix):\n",
    "        for var in variables:\n",
    "            for cluster_status in [True, False]:\n",
    "                for model in ['WLS', 'OLS']:\n",
    "                    var_values = []\n",
    "                    for entry in df:\n",
    "                        if entry['Clusters'] == cluster_status and entry['Model'] == model:\n",
    "                            k = entry['K']\n",
    "                            if var in entry['Avg Beta Estimates']:\n",
    "                                var_values.append(entry['Avg Beta Estimates'][var])\n",
    "                            else:\n",
    "                                var_values.append(0)  # Handle missing variable case\n",
    "\n",
    "                    line_style = dict(dash='dash') if not cluster_status else dict()  # Dotted lines for Clusters=False\n",
    "                    cluster_text = \"Clusters=True\" if cluster_status else \"Clusters=False\"\n",
    "                    row, col = (1, 1) if model == 'OLS' else (1, 2)\n",
    "                    fig.add_trace(go.Scatter(x=k_values, y=var_values, mode='lines+markers', name=f'{var} ({model}, {cluster_text}, {title_suffix})', line=line_style, visible=False), row=row, col=col)\n",
    "\n",
    "        for cluster_status in [True, False]:\n",
    "            for model in ['WLS', 'OLS']:\n",
    "                r_squared_values = [entry['R^2'] for entry in df if entry['Clusters'] == cluster_status and entry['Model'] == model]\n",
    "                avg_top3_mse_values = [entry['Avg Top 3 MSE'] for entry in df if entry['Clusters'] == cluster_status and entry['Model'] == model]\n",
    "                \n",
    "                line_style = dict(dash='dash') if not cluster_status else dict()  # Dotted lines for Clusters=False\n",
    "                cluster_text = \"Clusters=True\" if cluster_status else \"Clusters=False\"\n",
    "                row_r2, col_r2 = (3, 1) if model == 'OLS' else (3, 2)\n",
    "                row_mse, col_mse = (2, 1) if model == 'OLS' else (2, 2)\n",
    "                \n",
    "                fig.add_trace(go.Scatter(x=k_values, y=avg_top3_mse_values, mode='lines+markers', name=f'Avg Top 3 MSE ({model}, {cluster_text}, {title_suffix})', line=line_style, visible=False), row=row_mse, col=col_mse)\n",
    "                fig.add_trace(go.Scatter(x=k_values, y=r_squared_values, mode='lines+markers', name=f'R^2 ({model}, {cluster_text}, {title_suffix})', line=line_style, visible=False), row=row_r2, col=col_r2)\n",
    "\n",
    "    add_traces_to_fig(results_dict['Nominal rates with clusters'], 'Nominal rates')\n",
    "    add_traces_to_fig(results_dict['Nominal diff rates with clusters'], 'Nominal diff rates')\n",
    "\n",
    "    # Update layout with dropdown and legend button\n",
    "    fig.update_layout(\n",
    "        title='Model Comparisons',\n",
    "        showlegend=False,\n",
    "        height=900, width=1400,  # Increase plot size\n",
    "        updatemenus=[\n",
    "            {\n",
    "                'buttons': [\n",
    "                    {\n",
    "                        'label': 'Nominal rates',\n",
    "                        'method': 'update',\n",
    "                        'args': [\n",
    "                            {'visible': [i < len(fig.data) // 2 for i in range(len(fig.data))]},\n",
    "                            {'title': 'Model Comparisons for Nominal rates'}\n",
    "                        ]\n",
    "                    },\n",
    "                    {\n",
    "                        'label': 'Nominal diff rates',\n",
    "                        'method': 'update',\n",
    "                        'args': [\n",
    "                            {'visible': [i >= len(fig.data) // 2 for i in range(len(fig.data))]},\n",
    "                            {'title': 'Model Comparisons for Nominal diff rates'}\n",
    "                        ]\n",
    "                    },\n",
    "                    {\n",
    "                        'label': 'Both',\n",
    "                        'method': 'update',\n",
    "                        'args': [\n",
    "                            {'visible': [True for _ in range(len(fig.data))]},\n",
    "                            {'title': 'Model Comparisons for Nominal rates and Nominal diff rates'}\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "                'direction': 'down',\n",
    "                'showactive': True,\n",
    "                'x': 0.17,\n",
    "                'xanchor': 'left',\n",
    "                'y': 1.15,\n",
    "                'yanchor': 'top'\n",
    "            },\n",
    "            {\n",
    "                'buttons': [\n",
    "                    {\n",
    "                        'label': 'Show Legend',\n",
    "                        'method': 'relayout',\n",
    "                        'args': [{'showlegend': True}]\n",
    "                    },\n",
    "                    {\n",
    "                        'label': 'Hide Legend',\n",
    "                        'method': 'relayout',\n",
    "                        'args': [{'showlegend': False}]\n",
    "                    }\n",
    "                ],\n",
    "                'direction': 'down',\n",
    "                'showactive': True,\n",
    "                'x': 0.3,\n",
    "                'xanchor': 'left',\n",
    "                'y': 1.15,\n",
    "                'yanchor': 'top'\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Initialize the plot with 'Nominal rates' visible\n",
    "    for i in range(len(fig.data) // 2):\n",
    "        fig.data[i].visible = True\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea32bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
